{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6a55e20c-a011-4a15-9908-c2c6132d64f0",
      "metadata": {
        "id": "6a55e20c-a011-4a15-9908-c2c6132d64f0"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Human = 0, AI = 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "A7t5CJixLWiq",
        "outputId": "b51ca588-5d52-4377-df70-72e9b31f9673"
      },
      "id": "A7t5CJixLWiq",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.21.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              },
              "id": "0f2163a6468d494395a4f2ef49c7678b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "WbhBijTxIfea",
      "metadata": {
        "id": "WbhBijTxIfea"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tokenizers import Tokenizer, pre_tokenizers, trainers\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "import os\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW, RobertaModel\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "88wSW1aAPKev",
      "metadata": {
        "id": "88wSW1aAPKev"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Initialize the Tokenizer\n",
        "tokenizer = Tokenizer(num_words=50000)  # Adjust num_words as needed\n",
        "\n",
        "# Fit the tokenizer on the text data\n",
        "tokenizer.fit_on_texts(df['cleaned_text'])\n",
        "\n",
        "# Get the word counts\n",
        "word_counts = tokenizer.word_counts\n",
        "\n",
        "# Sort the word counts\n",
        "sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Example of printing the most common words\n",
        "print(sorted_word_counts[:10])  # Print the top 10 most frequent words\n",
        "\n",
        "# To visualize the distribution\n",
        "import matplotlib.pyplot as plt\n",
        "counts = [count for word, count in sorted_word_counts]\n",
        "plt.plot(counts)\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.title('Word Frequency Distribution')\n",
        "plt.xlabel('Rank of word (log scale)')\n",
        "plt.ylabel('Frequency of word (log scale)')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "lqS2Wj_FWYqE",
        "outputId": "196d95a1-c3ee-435d-e0b3-28d85098858c"
      },
      "id": "lqS2Wj_FWYqE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('also', 485349), ('one', 485146), ('people', 476903), ('time', 366518), ('would', 326951), ('new', 307031), ('company', 278152), ('life', 268262), ('work', 261125), ('student', 256983)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer(num_words=15000) #between 10000 and 20000\n",
        "tokenizer.fit_on_texts(df['cleaned_text'])\n",
        "X = tokenizer.texts_to_sequences(df['cleaned_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "5emzh_CnYFod",
        "outputId": "e9e6d01e-4692-40b6-ffc0-dcfdd0ff38ba"
      },
      "id": "5emzh_CnYFod",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d0b58db5b83c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check if GPU is available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Num GPUs Available: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Tokenize the text data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calculate the lengths of all sequences\n",
        "sequence_lengths = [len(seq) for seq in X]\n",
        "\n",
        "# Define the bins\n",
        "bins = np.arange(0, 5001, 100)  # Bins from 0 to 5000 with a step of 100\n",
        "\n",
        "# Calculate the histogram\n",
        "hist, bin_edges = np.histogram(sequence_lengths, bins=bins)\n",
        "\n",
        "# Print the distribution\n",
        "print(\"Distribution of Sequence Lengths:\")\n",
        "for i in range(len(hist)):\n",
        "    print(f\"Length {bin_edges[i]} to {bin_edges[i+1]}: {hist[i]} sequences\")\n",
        "\n",
        "# Plot the distribution of sequence lengths\n",
        "plt.hist(sequence_lengths, bins=50)\n",
        "plt.xlim(0, 5000)  # Set the x-axis limit to 5000\n",
        "plt.xlabel('Sequence Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Sequence Lengths')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QKNMKu0AYAic",
        "outputId": "c7c27b4b-7b15-4ac5-9de9-3599c0efe866"
      },
      "id": "QKNMKu0AYAic",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution of Sequence Lengths:\n",
            "Length 0 to 100: 131605 sequences\n",
            "Length 100 to 200: 64369 sequences\n",
            "Length 200 to 300: 49711 sequences\n",
            "Length 300 to 400: 45779 sequences\n",
            "Length 400 to 500: 19440 sequences\n",
            "Length 500 to 600: 10097 sequences\n",
            "Length 600 to 700: 6523 sequences\n",
            "Length 700 to 800: 4670 sequences\n",
            "Length 800 to 900: 3729 sequences\n",
            "Length 900 to 1000: 2737 sequences\n",
            "Length 1000 to 1100: 2158 sequences\n",
            "Length 1100 to 1200: 1948 sequences\n",
            "Length 1200 to 1300: 1692 sequences\n",
            "Length 1300 to 1400: 1358 sequences\n",
            "Length 1400 to 1500: 1165 sequences\n",
            "Length 1500 to 1600: 1059 sequences\n",
            "Length 1600 to 1700: 939 sequences\n",
            "Length 1700 to 1800: 751 sequences\n",
            "Length 1800 to 1900: 547 sequences\n",
            "Length 1900 to 2000: 430 sequences\n",
            "Length 2000 to 2100: 364 sequences\n",
            "Length 2100 to 2200: 275 sequences\n",
            "Length 2200 to 2300: 245 sequences\n",
            "Length 2300 to 2400: 222 sequences\n",
            "Length 2400 to 2500: 181 sequences\n",
            "Length 2500 to 2600: 134 sequences\n",
            "Length 2600 to 2700: 115 sequences\n",
            "Length 2700 to 2800: 93 sequences\n",
            "Length 2800 to 2900: 92 sequences\n",
            "Length 2900 to 3000: 81 sequences\n",
            "Length 3000 to 3100: 93 sequences\n",
            "Length 3100 to 3200: 62 sequences\n",
            "Length 3200 to 3300: 48 sequences\n",
            "Length 3300 to 3400: 45 sequences\n",
            "Length 3400 to 3500: 23 sequences\n",
            "Length 3500 to 3600: 25 sequences\n",
            "Length 3600 to 3700: 28 sequences\n",
            "Length 3700 to 3800: 23 sequences\n",
            "Length 3800 to 3900: 18 sequences\n",
            "Length 3900 to 4000: 22 sequences\n",
            "Length 4000 to 4100: 18 sequences\n",
            "Length 4100 to 4200: 15 sequences\n",
            "Length 4200 to 4300: 8 sequences\n",
            "Length 4300 to 4400: 11 sequences\n",
            "Length 4400 to 4500: 20 sequences\n",
            "Length 4500 to 4600: 7 sequences\n",
            "Length 4600 to 4700: 9 sequences\n",
            "Length 4700 to 4800: 9 sequences\n",
            "Length 4800 to 4900: 11 sequences\n",
            "Length 4900 to 5000: 5 sequences\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from kerastuner import RandomSearch\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout, Bidirectional, Conv1D, GlobalMaxPooling1D, Reshape\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer(num_words=15000)  # Use 15000 words in the tokenizer\n",
        "tokenizer.fit_on_texts(df['cleaned_text'])\n",
        "X = tokenizer.texts_to_sequences(df['cleaned_text'])\n",
        "\n",
        "# Pad sequences to ensure uniform input size\n",
        "X = pad_sequences(X, maxlen=500)\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'])\n",
        "\n",
        "# Step 4: Split the data into training, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "yZFmcwkqU7KI"
      },
      "id": "yZFmcwkqU7KI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Embedding layer (input_dim updated to 15000 to match the tokenizer)\n",
        "    model.add(Embedding(input_dim=15000,\n",
        "                        output_dim=hp.Int('embedding_dim', min_value=32, max_value=512, step=32)))\n",
        "\n",
        "    # Convolutional layer (Optional)\n",
        "    if hp.Choice('use_conv1d', [True, False]):\n",
        "        model.add(Conv1D(filters=hp.Int('conv_filters', min_value=32, max_value=256, step=32),\n",
        "                         kernel_size=hp.Choice('kernel_size', [3, 5, 7]),\n",
        "                         activation='relu'))\n",
        "        model.add(GlobalMaxPooling1D())\n",
        "\n",
        "    # Recurrent layer\n",
        "    if hp.Choice('recurrent_layer', ['LSTM', 'GRU']) == 'LSTM':\n",
        "        model.add(LSTM(units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
        "                       return_sequences=hp.Choice('return_sequences', [True, False]),\n",
        "                       dropout=hp.Float('dropout_lstm', 0, 0.5, step=0.1)))\n",
        "    else:\n",
        "        model.add(GRU(units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
        "                      return_sequences=hp.Choice('return_sequences', [True, False]),\n",
        "                      dropout=hp.Float('dropout_gru', 0, 0.5, step=0.1)))\n",
        "\n",
        "    # Ensure 3D input for Bidirectional layer, regardless of previous layer choices\n",
        "    model.add(Reshape((-1, 1)))\n",
        "\n",
        "    # Optional Bidirectional Layer\n",
        "    if hp.Choice('bidirectional', [True, False]):\n",
        "        model.add(Bidirectional(LSTM(units=hp.Int('units_bidirectional', min_value=32, max_value=512, step=32),\n",
        "                                     dropout=hp.Float('dropout_bidirectional', 0, 0.5, step=0.1))))\n",
        "\n",
        "    # Additional Dense Layers (Optional)\n",
        "    for i in range(hp.Int('num_dense_layers', 1, 3)):\n",
        "        model.add(Dense(units=hp.Int(f'dense_units_{i}', min_value=32, max_value=512, step=32), activation='relu'))\n",
        "        model.add(Dropout(rate=hp.Float(f'dropout_dense_{i}', 0, 0.5, step=0.1)))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer=hp.Choice('optimizer', ['adam', 'rmsprop', 'sgd']),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "ivChBcO3dqTD"
      },
      "id": "ivChBcO3dqTD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from kerastuner import RandomSearch\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Assuming df['text'] contains your text data and df['label'] contains labels\n",
        "\n",
        "# Convert the text data to TF-IDF features\n",
        "tfidf = TfidfVectorizer(max_features=5000)  # Adjust the max_features as needed\n",
        "X = tfidf.fit_transform(df['cleaned_text']).toarray()\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(df['label'])\n",
        "y_encoded = to_categorical(y_encoded)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Define the model building function for Keras Tuner\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # First Dense Layer\n",
        "    model.add(Dense(units=hp.Int('units', min_value=64, max_value=512, step=32),\n",
        "                    activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    model.add(Dropout(rate=hp.Float('dropout', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Additional Dense Layers (Optional)\n",
        "    for i in range(hp.Int('num_layers', 1, 3)):\n",
        "        model.add(Dense(units=hp.Int(f'units_{i}', min_value=64, max_value=512, step=32), activation='relu'))\n",
        "        model.add(Dropout(rate=hp.Float(f'dropout_{i}', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(units=y_encoded.shape[1], activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', [0.001, 0.0005, 0.0001])),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Step 6: Setup Keras Tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=100,  # Increase the number of trials for a broader search\n",
        "    executions_per_trial=2,  # Average results of each trial to reduce variance\n",
        "    directory='my_dir',\n",
        "    project_name='tfidf_text_classification'\n",
        ")\n",
        "\n",
        "# Step 7: Early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Step 8: Perform the hyperparameter search\n",
        "tuner.search(X_train, y_train,\n",
        "             epochs=30,\n",
        "             validation_split=0.2,  # Use a validation split within the training set\n",
        "             callbacks=[early_stopping])\n",
        "\n",
        "# Step 9: Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Step 10: Evaluate the best model on the test set\n",
        "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Step 11: Get the best hyperparameters\n",
        "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Step 12: Print the best hyperparameters\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "for key, value in best_hyperparameters.values.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "# Evaluate the model on test data and print metrics\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(classification_report(y_test_classes, y_pred_classes))\n",
        "print(confusion_matrix(y_test_classes, y_pred_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdftBXoJeGCE",
        "outputId": "f5e43481-9490-4dfa-f253-9a4decaf0152"
      },
      "id": "NdftBXoJeGCE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 44 Complete [00h 03m 32s]\n",
            "val_accuracy: 0.9070230424404144\n",
            "\n",
            "Best val_accuracy So Far: 0.9075981080532074\n",
            "Total elapsed time: 02h 55m 58s\n",
            "\n",
            "Search: Running Trial #45\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "320               |512               |units\n",
            "0.5               |0.4               |dropout\n",
            "3                 |3                 |num_layers\n",
            "224               |96                |units_0\n",
            "0.2               |0.2               |dropout_0\n",
            "0.001             |0.001             |learning_rate\n",
            "512               |352               |units_1\n",
            "0.1               |0.1               |dropout_1\n",
            "448               |512               |units_2\n",
            "0.5               |0.2               |dropout_2\n",
            "\n",
            "Epoch 1/30\n",
            "\u001b[1m7065/7065\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4ms/step - accuracy: 0.8188 - loss: 0.3595 - val_accuracy: 0.8815 - val_loss: 0.2596\n",
            "Epoch 2/30\n",
            "\u001b[1m7065/7065\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.9031 - loss: 0.2216 - val_accuracy: 0.8906 - val_loss: 0.2474\n",
            "Epoch 3/30\n",
            "\u001b[1m7065/7065\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.9315 - loss: 0.1646 - val_accuracy: 0.8970 - val_loss: 0.2285\n",
            "Epoch 4/30\n",
            "\u001b[1m7065/7065\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9517 - loss: 0.1233 - val_accuracy: 0.9000 - val_loss: 0.2371\n",
            "Epoch 5/30\n",
            "\u001b[1m7065/7065\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0974 - val_accuracy: 0.9016 - val_loss: 0.2866\n",
            "Epoch 6/30\n",
            "\u001b[1m7065/7065\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.9708 - loss: 0.0808 - val_accuracy: 0.9031 - val_loss: 0.2577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PDEVOXoHTTvj",
      "metadata": {
        "id": "PDEVOXoHTTvj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "a4f997dd-c89e-4a98-a410-1bf450dc11de"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch_xla'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-cc4977763263>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_xla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_xla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Set the TPU device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_xla'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import torch\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "\n",
        "# Set the TPU device\n",
        "device = xm.xla_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8LlrZbf3PQvN",
      "metadata": {
        "id": "8LlrZbf3PQvN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "kew2zpA-TIEW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kew2zpA-TIEW",
        "outputId": "7c19086f-eafe-4107-c9d4-7b2dd4daf560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "031d41a0-30b5-4b0c-a0ed-e635a4e40ea1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "031d41a0-30b5-4b0c-a0ed-e635a4e40ea1",
        "outputId": "f792c801-25f6-487c-dc93-74813ed194b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label  \\\n",
              "0  Communication Theories From Socrates’ Dialogue...      0   \n",
              "1  Dear TEACHER_NAME,\\n\\nI think that if you kids...      0   \n",
              "2  To my understanding, Common Core is a set of s...      1   \n",
              "3  Zomato has acquired the Indian operations of U...      1   \n",
              "4  Chloroplasts have their own DNA, often abbrevi...      1   \n",
              "\n",
              "                                        cleaned_text  \n",
              "0  communication theory socrates dialogue essay c...  \n",
              "1  dear teachername think kid use phone school li...  \n",
              "2  understanding common core set standard skill s...  \n",
              "3  zomato acquired indian operation uber eats aro...  \n",
              "4  chloroplast dna often abbreviated ctdna cpdna ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19124576-fe1c-4417-85c5-36b4cd98a7fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Communication Theories From Socrates’ Dialogue...</td>\n",
              "      <td>0</td>\n",
              "      <td>communication theory socrates dialogue essay c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dear TEACHER_NAME,\\n\\nI think that if you kids...</td>\n",
              "      <td>0</td>\n",
              "      <td>dear teachername think kid use phone school li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>To my understanding, Common Core is a set of s...</td>\n",
              "      <td>1</td>\n",
              "      <td>understanding common core set standard skill s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Zomato has acquired the Indian operations of U...</td>\n",
              "      <td>1</td>\n",
              "      <td>zomato acquired indian operation uber eats aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Chloroplasts have their own DNA, often abbrevi...</td>\n",
              "      <td>1</td>\n",
              "      <td>chloroplast dna often abbreviated ctdna cpdna ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19124576-fe1c-4417-85c5-36b4cd98a7fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-19124576-fe1c-4417-85c5-36b4cd98a7fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-19124576-fe1c-4417-85c5-36b4cd98a7fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-12c5084f-0489-4d10-80c0-29bdad514311\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-12c5084f-0489-4d10-80c0-29bdad514311')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-12c5084f-0489-4d10-80c0-29bdad514311 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/drive/MyDrive/balanced_dataset.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a8ae659b-6d81-46d5-ac4a-fc5e62950505",
      "metadata": {
        "id": "a8ae659b-6d81-46d5-ac4a-fc5e62950505"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ad2a0e58",
      "metadata": {
        "id": "ad2a0e58"
      },
      "outputs": [],
      "source": [
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8oL-g9LilwNt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8oL-g9LilwNt",
        "outputId": "f3070be3-32c4-41ba-f5d4-685e66e82d53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label  \\\n",
              "0  Communication Theories From Socrates’ Dialogue...      0   \n",
              "1  Dear TEACHER_NAME,\\n\\nI think that if you kids...      0   \n",
              "2  To my understanding, Common Core is a set of s...      1   \n",
              "3  Zomato has acquired the Indian operations of U...      1   \n",
              "4  Chloroplasts have their own DNA, often abbrevi...      1   \n",
              "\n",
              "                                        cleaned_text  \n",
              "0  communication theory socrates dialogue essay c...  \n",
              "1  dear teachername think kid use phone school li...  \n",
              "2  understanding common core set standard skill s...  \n",
              "3  zomato acquired indian operation uber eats aro...  \n",
              "4  chloroplast dna often abbreviated ctdna cpdna ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09d2186c-f31a-478f-a153-2a52ce5b71be\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Communication Theories From Socrates’ Dialogue...</td>\n",
              "      <td>0</td>\n",
              "      <td>communication theory socrates dialogue essay c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dear TEACHER_NAME,\\n\\nI think that if you kids...</td>\n",
              "      <td>0</td>\n",
              "      <td>dear teachername think kid use phone school li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>To my understanding, Common Core is a set of s...</td>\n",
              "      <td>1</td>\n",
              "      <td>understanding common core set standard skill s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Zomato has acquired the Indian operations of U...</td>\n",
              "      <td>1</td>\n",
              "      <td>zomato acquired indian operation uber eats aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Chloroplasts have their own DNA, often abbrevi...</td>\n",
              "      <td>1</td>\n",
              "      <td>chloroplast dna often abbreviated ctdna cpdna ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09d2186c-f31a-478f-a153-2a52ce5b71be')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-09d2186c-f31a-478f-a153-2a52ce5b71be button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-09d2186c-f31a-478f-a153-2a52ce5b71be');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ac4eaba6-699a-4e7b-b8c0-533896573664\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ac4eaba6-699a-4e7b-b8c0-533896573664')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ac4eaba6-699a-4e7b-b8c0-533896573664 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch transformers datasets sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnI21Gomy2D6",
        "outputId": "c7fd32df-b3ba-4048-f6e1-1740cbb54cc1"
      },
      "id": "vnI21Gomy2D6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "On-ykI66lbPP",
      "metadata": {
        "id": "On-ykI66lbPP"
      },
      "outputs": [],
      "source": [
        "processed_texts = df['cleaned_text'].apply(lambda x: x.split()).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2wXcstgGl3V2",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2wXcstgGl3V2"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Train Word2Vec model on the preprocessed text data using CPU\n",
        "word2vec_model = Word2Vec(sentences=processed_texts, vector_size=300, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Save the model if needed\n",
        "word2vec_model.save(\"word2vec.model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9D3JGExomnrm",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9D3JGExomnrm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def text_to_vector(text, model):\n",
        "    vector = np.mean([model.wv[word] for word in text if word in model.wv], axis=0)\n",
        "    return vector if vector is not None else np.zeros(model.vector_size)\n",
        "\n",
        "# Convert all texts to vectors\n",
        "X = np.array([text_to_vector(text, word2vec_model) for text in processed_texts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KhYxpXmVq3eo",
      "metadata": {
        "id": "KhYxpXmVq3eo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you already have the labels in df['label']\n",
        "labels = df['label'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the classifier using CPU\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ssoJQVrDLFW",
      "metadata": {
        "id": "9ssoJQVrDLFW"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split the dataset into train and test sets\n",
        "train_df1, test_df1 = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Optionally reset the indices of the DataFrames\n",
        "train_df_main = train_df1.reset_index(drop=True)\n",
        "test_df_main = test_df1.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Cjk1VcbclHWT",
      "metadata": {
        "id": "Cjk1VcbclHWT"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Train Word2Vec model\n",
        "word2vec_model = Word2Vec(sentences=processed_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Save the model for later use\n",
        "word2vec_model.save(\"word2vec.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dAe-YT6HDVN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "8dAe-YT6HDVN",
        "outputId": "f335eb14-35ef-4823-fb74-ce172335d763"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_balanced_sample\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50000,\n        \"samples\": [\n          \"I adjusted my mic. \\\"Ooookay, let's get this show on the road,\\\" I announced, grabbing the script I had been graciously given by my bosses. Thank them, honestly, for this great opportunity to work with someone like Tom Cruise - and who doesn't love a little bit of PR? Chapter Four: The First Date (Backstage) J ust miles outside Los Angeles' Westwood neighborhood is one classy joint after another and you could literally eat your way around town at every restaurant from Crate Barrel or Pottery Barn if so inclined while staying within walking distance most places in Beverly Hills proper! So it was off we went into that elegant high-end retail district along Wilshire Boulevard where everybody knows their place even though they're all trying very hard not too look outraged when somebody cuts anyone else but themselves some major unasked -for side glances because hey - what are neighbors going do about such things anyway besides complain later?! We passed up an array 'n more designer shops until finally settling upon Prada as our destination which thankfully also happened be only three blocks over past Montage Hotel down Dohenney Drive toward Santa Monica Beach - really nice hotel just above Promenade Deck overlooking beachfront walkway near Olympic Tower right below Staples Center perched atop hillside. It seemed fitting since here were no less than half dozen stars including Brooke Shields next door having lunch pool court style yet everyone pretty much still looked cool enough despite hot LA afternoon sun beating against me during dinner hour; celebrity life obviously has its benefits especially looking good always being number two priority alongside keeping rich husbands happy whenever possible HaHa!!! Really glad starlets have fun doing exactly everything people don't want girls back home allowed wanting putting millions away behind closed doors before letting same slip through fingers !! And speaking engagements should come first followed closely thereafter making sure men didn' t throw tantrums demanding attention any time soon unless otherwise stated! Maybe then maybe someday gonna happen??? Ain'ttu lying huhcow -\",\n          \"Classical decision theory models behaviour in terms of utility maximisation where utilities represent rational preference relations over outcomes. However, empirical evidence and theoretical considerations suggest that we need to go beyond this framework. We propose to represent goals by higher-order functions or operators that take other functions as arguments where the max and arg max operators are special cases. Our higher-order functions take a context function as their argument where a context represents a process from actions to outcomes. By that we can define goals being dependent on the actions and the process in addition to outcomes only. This formulation generalises outcome based preferences to context-dependent goals. We show how to uniformly represent within our higher-order framework classical utility maximisation but also various other extensions that have been debated in economics.\",\n          \"Quality in News: BP Deep-Water Horizon Oil Rig Case Study\\n\\nOn the 14th of September 2011, an article appearing in the New York Times highlighted the case of the Gulf of Mexico oil spill. The quality issue in the article was mainly procedural non-compliance as it noted that in a bid to make up for weeks behind schedule and budget overboard, the company adopted shortcuts aimed at speeding up the process (Broider, 2011).\\n\\nProposed quality management tools\\n\\n  * Check sheet: In a case where the procedure is of critical importance, it is important to develop a check sheet to help ensure that every recommended procedure is followed.\\n  * Brainstorming: Brainstorming is important in helping identify various possibilities and challenges the project is likely to face.\\n  * Pareto diagram: It is important to note that more often not few problems result in grave consequences and hence addressing them can save the project lots of trouble.\\n\\n3 steps to take in investigating the problem\\n\\nUndertake a careful review of the procedural guidelines relating to the project and relate the same to the procedures employed by the corporation.\\n\\nIdentify possible consequences of every case of non-compliance recorded.\\n\\nNarrow down analysis to focus on the defects observed and hence find the precise causes of the defects recorded.\\n\\nReferences\\n\\nBroider, J.M. (2011). BP Shortcuts Led to Gulf Oil Spill, Report Says. New York Times, p. 8.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49991,\n        \"samples\": [\n          \"given graph g v e v integer k l l path packing problem asks find k vertexdisjoint path length l first vertex last vertex path path packing problem solved using graph search algorithm depthfirst search dfs breadthfirst search bfs algorithm start given vertex explores possible path length l valid path found added set path algorithm search another valid path process repeated k path found ensure path vertexdisjoint vertex already visited previous path explored\",\n          \"newsflash opensource app let anyone create virtual army hackintoshes new opensource app released allows user create virtual army hackintoshes machine run macos nonapple hardware app called hackvm used create multiple virtual machine running macos single computer hackintoshes around year always required significant amount technical expertise set maintain hackvm aim simplify process make accessible anyone using hackvm user quickly create many virtual machine need running separate instance macos incredibly useful developer need test software multiple version macos want try latest version macos without purchasing new computer app opensource meaning anyone contribute development available download free github hackvm possibility creating testing hackintoshes endless\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_balanced_sample"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-35ecf2c5-6b05-41c0-8db6-d2e3ac77cbb0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>But the annual Easter School at St Mary's Univ...</td>\n",
              "      <td>0</td>\n",
              "      <td>annual easter school st mary university colleg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Some people would say they get used to it. Oth...</td>\n",
              "      <td>0</td>\n",
              "      <td>people would say get used others say havent kn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The topic of driveless cars is very controvers...</td>\n",
              "      <td>0</td>\n",
              "      <td>topic driveless car controversial people say d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what classes do i take next semester?  i ...</td>\n",
              "      <td>0</td>\n",
              "      <td>class take next semester need plan rest colleg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>We consider the k -server problem on trees and...</td>\n",
              "      <td>0</td>\n",
              "      <td>consider k server problem tree hsts give algor...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35ecf2c5-6b05-41c0-8db6-d2e3ac77cbb0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-35ecf2c5-6b05-41c0-8db6-d2e3ac77cbb0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-35ecf2c5-6b05-41c0-8db6-d2e3ac77cbb0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-20e4248b-2523-4bbc-b56c-7099c085fc43\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-20e4248b-2523-4bbc-b56c-7099c085fc43')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-20e4248b-2523-4bbc-b56c-7099c085fc43 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text  label  \\\n",
              "0  But the annual Easter School at St Mary's Univ...      0   \n",
              "1  Some people would say they get used to it. Oth...      0   \n",
              "2  The topic of driveless cars is very controvers...      0   \n",
              "3       what classes do i take next semester?  i ...      0   \n",
              "4  We consider the k -server problem on trees and...      0   \n",
              "\n",
              "                                        cleaned_text  \n",
              "0  annual easter school st mary university colleg...  \n",
              "1  people would say get used others say havent kn...  \n",
              "2  topic driveless car controversial people say d...  \n",
              "3  class take next semester need plan rest colleg...  \n",
              "4  consider k server problem tree hsts give algor...  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'label' is the column with the categories\n",
        "# Each category will have an equal number of samples in the final dataset\n",
        "\n",
        "# Determine the number of samples per category\n",
        "n_per_category = 25000  # Since you want 50,000 entries total, divide by 2\n",
        "\n",
        "# Perform stratified sampling\n",
        "df_balanced_sample = df.groupby('label').apply(lambda x: x.sample(n=n_per_category, random_state=42)).reset_index(drop=True)\n",
        "\n",
        "# Display the first few rows of the balanced sample\n",
        "df_balanced_sample.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tuJF9XrsDiK4",
      "metadata": {
        "id": "tuJF9XrsDiK4"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "MAX_LEN = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZWAKdUrWDmU9",
      "metadata": {
        "id": "ZWAKdUrWDmU9"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "import numpy as np\n",
        "from tokenizers import Tokenizer, pre_tokenizers, trainers\n",
        "from functools import partial\n",
        "\n",
        "start = time.time()\n",
        "# Example vocab size\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "\n",
        "def tokenize_and_pad(sentence, tokenizer, max_length):\n",
        "    encoded = tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors='np'\n",
        "    )\n",
        "    return {\"input_ids\": encoded['input_ids'].squeeze(),\n",
        "           \"attention_masks\": encoded[\"attention_mask\"].squeeze()}\n",
        "\n",
        "# Function for parallel processing\n",
        "def tokenize_and_pad_parallel(data, tokenizer, max_length):\n",
        "    with multiprocessing.Pool() as pool:\n",
        "        tokenized = pool.map(partial(tokenize_and_pad, tokenizer=tokenizer, max_length=max_length), data)\n",
        "    return tokenized\n",
        "\n",
        "# Apply tokenization and padding to all sentences in parallel\n",
        "train_df_main['tokens'] = tokenize_and_pad_parallel(train_df_main['cleaned_text'], tokenizer, MAX_LEN)\n",
        "\n",
        "print(train_df_main['tokens'][0])\n",
        "print(train_df_main['label'][:4])\n",
        "\n",
        "end = time.time()\n",
        "print(f\"time taken: {end-start}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XmWkzW9IDcvt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmWkzW9IDcvt",
        "outputId": "02fa723d-62ed-4601-9a8e-b46495a603cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         index                                               text  label  \\\n",
            "0       211007  [substeps] Children are notorious for being \" ...      1   \n",
            "1       222696  Southern California contains a Mediterranean c...      1   \n",
            "2       127925  Community service is super important to the co...      1   \n",
            "3       244246  Cam came online at 2140. Blasted lands, flat a...      0   \n",
            "4       196313  Many times we as humans study things that have...      0   \n",
            "...        ...                                                ...    ...   \n",
            "254304  119879  I am a very vocal and outspoken person. I had ...      0   \n",
            "254305  259178  When Steven Gerrard stepped out onto the field...      1   \n",
            "254306  131932  HATE Nothing. DISLIKE Only location is far awa...      0   \n",
            "254307  146867  Background of Nursing Practices Essay\\n\\nSumma...      0   \n",
            "254308  121958  A first generation Tesla Model S was caught on...      0   \n",
            "\n",
            "                                             cleaned_text  \\\n",
            "0       substeps child notorious picky eater child sim...   \n",
            "1       southern california contains mediterranean cli...   \n",
            "2       community service super important community li...   \n",
            "3       cam came online blasted land flat scattered th...   \n",
            "4       many time human study thing studied hundred ti...   \n",
            "...                                                   ...   \n",
            "254304  vocal outspoken person never one sit back watc...   \n",
            "254305  steven gerrard stepped onto field face afc wim...   \n",
            "254306  hate nothing dislike location far away live it...   \n",
            "254307  background nursing practice essay summary nurs...   \n",
            "254308  first generation tesla model caught camera bur...   \n",
            "\n",
            "                                                   tokens  \n",
            "0       {'input_ids': [0, 10936, 27091, 920, 13940, 13...  \n",
            "1       {'input_ids': [0, 29, 45846, 13011, 1594, 4305...  \n",
            "2       {'input_ids': [0, 28746, 544, 2422, 505, 435, ...  \n",
            "3       {'input_ids': [0, 16767, 376, 804, 14248, 1212...  \n",
            "4       {'input_ids': [0, 19827, 86, 1050, 892, 631, 8...  \n",
            "...                                                   ...  \n",
            "254304  {'input_ids': [0, 705, 21103, 16120, 621, 393,...  \n",
            "254305  {'input_ids': [0, 6526, 2987, 821, 14385, 1120...  \n",
            "254306  {'input_ids': [0, 33990, 1085, 28101, 2259, 44...  \n",
            "254307  {'input_ids': [0, 46776, 8701, 1524, 14700, 48...  \n",
            "254308  {'input_ids': [0, 9502, 2706, 326, 293, 2560, ...  \n",
            "\n",
            "[254309 rows x 5 columns]\n",
            "        index                                               text  label  \\\n",
            "0      267294  The Universe is a vast and intricate tapestry ...      1   \n",
            "1       15817  Martha had a day off from work. She wanted to ...      1   \n",
            "2       24146  Asthma Investigation: Symptoms and Treatment E...      0   \n",
            "3      281210  Great gardens! I honestly can't wait until I g...      0   \n",
            "4      152128  Lessons to Learn: “Twelve Years a Slave” by So...      0   \n",
            "...       ...                                                ...    ...   \n",
            "28252    5255  To the Principle\\n\\nMany students at our schoo...      0   \n",
            "28253  206184  The Development of Feudalism and Manorialism i...      0   \n",
            "28254  131166  The weight of boilers and condensers generally...      0   \n",
            "28255  177992  On a sunny day with clear skies, I passed by a...      0   \n",
            "28256  255992  Chain of Command in Design of Constructional O...      0   \n",
            "\n",
            "                                            cleaned_text  \\\n",
            "0      universe vast intricate tapestry galaxy star p...   \n",
            "1      martha day work wanted watch reality televisio...   \n",
            "2      asthma investigation symptom treatment essay p...   \n",
            "3      great garden honestly cant wait go room divide...   \n",
            "4      lesson learn twelve year slave solomon northup...   \n",
            "...                                                  ...   \n",
            "28252  principle many student school disagree fact co...   \n",
            "28253  development feudalism manorialism middle age e...   \n",
            "28254  weight boiler condenser generally make powerto...   \n",
            "28255  sunny day clear sky passed park saw child fath...   \n",
            "28256  chain command design constructional organizati...   \n",
            "\n",
            "                                                  tokens  \n",
            "0      {'input_ids': [0, 879, 32273, 4714, 25210, 579...  \n",
            "1      {'input_ids': [0, 3916, 12037, 183, 173, 770, ...  \n",
            "2      {'input_ids': [0, 281, 212, 1916, 803, 28667, ...  \n",
            "3      {'input_ids': [0, 12338, 5671, 10728, 17672, 2...  \n",
            "4      {'input_ids': [0, 1672, 261, 1532, 11971, 76, ...  \n",
            "...                                                  ...  \n",
            "28252  {'input_ids': [0, 4862, 3976, 42420, 171, 1294...  \n",
            "28253  {'input_ids': [0, 27013, 44507, 1809, 313, 177...  \n",
            "28254  {'input_ids': [0, 4301, 33750, 10022, 43897, 3...  \n",
            "28255  {'input_ids': [0, 29, 40485, 183, 699, 6360, 1...  \n",
            "28256  {'input_ids': [0, 26149, 5936, 1521, 1663, 337...  \n",
            "\n",
            "[28257 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = train_df_main['tokens'].values.tolist()\n",
        "Y = train_df_main['label'].values\n",
        "\n",
        "train_df_model, test_df_model = train_test_split(train_df_main, test_size=0.1, shuffle=True, random_state = 42)\n",
        "train_df2 = train_df_model.reset_index()\n",
        "test_df2 = test_df_model.reset_index()\n",
        "print(train_df2)\n",
        "print(test_df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZCjDRETcHMPF",
      "metadata": {
        "id": "ZCjDRETcHMPF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def set_seed(seed=123):\n",
        "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
        "    This is for REPRODUCIBILITY.'''\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8_Le2-R4Hhh9",
      "metadata": {
        "id": "8_Le2-R4Hhh9"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from sklearn import preprocessing\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Nn2aemlnH33u",
      "metadata": {
        "id": "Nn2aemlnH33u"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "MAX_LEN = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tUY2EoUGIoVE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUY2EoUGIoVE",
        "outputId": "5ec35482-3e13-49aa-eed4-e0d6053eb5f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50265\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "vocab = tokenizer.get_vocab()\n",
        "VOCAB_SIZE = len(vocab)\n",
        "print(VOCAB_SIZE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WYIRAeP2I9gW",
      "metadata": {
        "id": "WYIRAeP2I9gW"
      },
      "outputs": [],
      "source": [
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.labels = dataframe['label'].values\n",
        "        self.tokens = dataframe['tokens'].values\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {}\n",
        "        item['input_ids'] = torch.tensor(self.tokens[idx]['input_ids'])\n",
        "        item['attention_masks'] = torch.tensor(self.tokens[idx]['attention_masks'])\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z11NYQdbY8Bq",
      "metadata": {
        "id": "Z11NYQdbY8Bq"
      },
      "outputs": [],
      "source": [
        "train_dataset = TextDataset(train_df2)\n",
        "test_dataset = TextDataset(test_df2)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE * torch.cuda.device_count(), shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rpv5FC5sIjbs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919,
          "referenced_widgets": [
            "e8dc96676f604976bd45e6aaa23ab334",
            "07c1bc524fd84f5aa80202f68dc24e1c",
            "707b1a211d344f0c99755d0a9f3d2b08",
            "f720ec05054b4f5f8363599332a2d2ad",
            "cd03c56de1a9426890be497bc8ccfa8a",
            "80d6679d2eef4e388f68ae5bdf4fec7b",
            "9ed334a3727743b39d0bdeeb30ffe087",
            "bab332da551d4af696e8c342414d61a0",
            "7b6e7eb388fd477abfa8dd28666513b6",
            "4bb7ed1d5b6547c5b8afadddac6b45d3",
            "3179c5bfaabb4b2bb4731af9f7e36b0f",
            "1c6413db129149e5a2f644b240391b84",
            "5b468f44e1f34f47b8ad3e60036bc211",
            "be5ac41050b94bd989a3dd9535f6d43f",
            "95e1d3e39ccc4a4d98803aa7247ee3f7",
            "a77cf6ad00604f1a96f2b3fa8bb00e4b",
            "3d9608da2643435dba42011e07778e1b",
            "4da251e8e1834c18a6c400c688ffcd10",
            "56d7d9603f974139855337ad10bec443",
            "34315f95134e474b8da02e1d77c0d3f8",
            "29472bd9db614cd9906722f822c9e564",
            "3793226a04b1400abbe6c60787b41077"
          ]
        },
        "id": "rpv5FC5sIjbs",
        "outputId": "19da3e2f-9fe3-4777-fb88-293354be1e0d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8dc96676f604976bd45e6aaa23ab334",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c6413db129149e5a2f644b240391b84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RobertaForSequenceClassification(\n",
            "  (roberta): RobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-5): 6 x RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (classifier): RobertaClassificationHead(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "device = ('cuda'\n",
        "          if torch.cuda.is_available()\n",
        "          else \"mps\"\n",
        "          if torch.backends.mps.is_available()\n",
        "          else \"cpu\"\n",
        "          )\n",
        "\n",
        "model = RobertaForSequenceClassification.from_pretrained('distilroberta-base', num_labels=1)\n",
        "# model = nn.DataParallel(model)\n",
        "model = model.to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kNz0gvu4Ytrr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNz0gvu4Ytrr",
        "outputId": "9dffc757-d48a-4ed9-d612-1058826f8bf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "246.95818519592285\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "start = time.time()\n",
        "with torch.no_grad():\n",
        "        for batch, data in enumerate(train_loader):\n",
        "            inputs = data['input_ids'].pin_memory().to(device, non_blocking=True)\n",
        "            attention_masks = data['attention_masks'].pin_memory().to(device, non_blocking=True)\n",
        "            labels = data['labels'].pin_memory().to(device, non_blocking=True)\n",
        "            pred = model(inputs, attention_mask = attention_masks)\n",
        "            if batch == 1000:\n",
        "                break\n",
        "end = time.time()\n",
        "print(end-start)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KzVtWbnRblmY",
      "metadata": {
        "id": "KzVtWbnRblmY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "loss_func = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0x_7DjpubnRM",
      "metadata": {
        "id": "0x_7DjpubnRM"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(pred,label):\n",
        "    pred = (pred > 0.5).long()\n",
        "    return torch.sum(pred == label).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S7CLp9Anbuje",
      "metadata": {
        "id": "S7CLp9Anbuje"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer, train_losses, train_acc):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    loss_sum = 0\n",
        "    accuracy = 0\n",
        "    num_batches = len(dataloader)\n",
        "    start = time.time()\n",
        "\n",
        "    for batch, data in enumerate(dataloader):\n",
        "        inputs = data['input_ids'].pin_memory().to(device, non_blocking=True)\n",
        "        attention_masks = data['attention_masks'].pin_memory().to(device, non_blocking=True)\n",
        "        labels = data['labels'].pin_memory().to(device, non_blocking=True)\n",
        "\n",
        "        y = labels.float()  # Convert labels to float\n",
        "\n",
        "        pred = model(inputs, attention_mask=attention_masks)\n",
        "        pred = nn.Sigmoid()(pred.logits).squeeze(-1)  # Remove the extra dimension\n",
        "\n",
        "        # Check shapes of pred and y\n",
        "        #print(f\"Batch {batch} - pred shape: {pred.shape}, y shape: {y.shape}\")\n",
        "\n",
        "        loss = loss_fn(pred, y)  # Now pred and y should have the same shape\n",
        "        loss_sum += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        accuracy += get_accuracy(pred, y)\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            end = time.time()\n",
        "            loss, current = loss.item(), (batch + 1) * len(inputs)\n",
        "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\" + \"                \" + f\"time taken: {(end-start):>5f} \")\n",
        "\n",
        "    mean_loss = loss_sum / num_batches\n",
        "    accuracy /= size\n",
        "    train_losses.append(mean_loss)\n",
        "    train_acc.append(accuracy)\n",
        "    print(f\"Training loss: {mean_loss:>7f}\")\n",
        "    print(f\"Training accuracy: {(accuracy*100):>7f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-GMNkQmoCcDI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GMNkQmoCcDI",
        "outputId": "d2567130-9d62-4fbd-ff0a-fd46efdc0ae4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to model.pth\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Define the path where you want to save the model\n",
        "model_save_path = \"model.pth\"\n",
        "\n",
        "# Save the model state dictionary\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "print(f\"Model saved to {model_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tOp-cnDjb0D9",
      "metadata": {
        "id": "tOp-cnDjb0D9"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn, test_losses, test_acc):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch, data in enumerate(dataloader):\n",
        "            inputs = data['input_ids'].pin_memory().to(device, non_blocking=True)\n",
        "            attention_masks = data['attention_masks'].pin_memory().to(device, non_blocking=True)\n",
        "            labels = data['labels'].pin_memory().to(device, non_blocking=True)\n",
        "\n",
        "            y = labels.float()\n",
        "            pred = model(inputs, attention_mask=attention_masks)\n",
        "            pred = nn.Sigmoid()(pred.logits).squeeze(-1)  # Ensure pred has the correct shape\n",
        "\n",
        "\n",
        "\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += get_accuracy(pred, y)\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    test_losses.append(test_loss)\n",
        "    test_acc.append(correct)\n",
        "    print(f\"Test loss: {test_loss:>7f}\")\n",
        "    print(f\"Test accuracy: {(correct*100):>7f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9ipz27W0iPy",
      "metadata": {
        "id": "a9ipz27W0iPy"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8CFtgqm7qtx1",
      "metadata": {
        "id": "8CFtgqm7qtx1"
      },
      "source": [
        "# END DISTILBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ROdFjJT9Bwgt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "ROdFjJT9Bwgt",
        "outputId": "8db31989-541f-4c90-e070-db77f0a08d9d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(test_losses, label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4N9E59aBB0n_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "4N9E59aBB0n_",
        "outputId": "6a750022-6a01-4a3b-f008-8df9df77761e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_acc, label='Training accuracy')\n",
        "plt.plot(test_acc, label='Val accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Training and Validation accuracy Over Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vV-tcNYeb2XY",
      "metadata": {
        "id": "vV-tcNYeb2XY"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-WuakjnEik7Z",
      "metadata": {
        "id": "-WuakjnEik7Z"
      },
      "source": [
        "# RUNNING RIGTH NOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7sNlzMZuddqn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sNlzMZuddqn",
        "outputId": "42b047a0-e62d-4dfb-a61e-d4fe76e38b89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 -----------------------------------\n",
            "loss: 0.084927 [   16/254309]                time taken: 0.787538 \n",
            "loss: 0.148794 [ 1616/254309]                time taken: 77.319064 \n",
            "loss: 0.073661 [ 3216/254309]                time taken: 153.548938 \n",
            "loss: 0.051604 [ 4816/254309]                time taken: 229.406287 \n",
            "loss: 0.122065 [ 6416/254309]                time taken: 305.349400 \n",
            "loss: 0.337236 [ 8016/254309]                time taken: 381.529362 \n",
            "loss: 0.055433 [ 9616/254309]                time taken: 457.804757 \n",
            "loss: 0.029273 [11216/254309]                time taken: 533.841517 \n",
            "loss: 0.074577 [12816/254309]                time taken: 609.800714 \n",
            "loss: 0.090911 [14416/254309]                time taken: 685.645843 \n",
            "loss: 0.103310 [16016/254309]                time taken: 761.770169 \n",
            "loss: 0.084136 [17616/254309]                time taken: 837.869365 \n",
            "loss: 0.088958 [19216/254309]                time taken: 914.053502 \n",
            "loss: 0.038266 [20816/254309]                time taken: 990.311188 \n",
            "loss: 0.196382 [22416/254309]                time taken: 1066.451083 \n",
            "loss: 0.099382 [24016/254309]                time taken: 1142.701660 \n",
            "loss: 0.290292 [25616/254309]                time taken: 1218.886702 \n",
            "loss: 0.100886 [27216/254309]                time taken: 1294.994672 \n",
            "loss: 0.005494 [28816/254309]                time taken: 1371.162375 \n",
            "loss: 0.045353 [30416/254309]                time taken: 1447.310651 \n",
            "loss: 0.392177 [32016/254309]                time taken: 1523.494749 \n",
            "loss: 0.056419 [33616/254309]                time taken: 1599.448837 \n",
            "loss: 0.144533 [35216/254309]                time taken: 1675.358438 \n",
            "loss: 0.084543 [36816/254309]                time taken: 1751.508840 \n",
            "loss: 0.049334 [38416/254309]                time taken: 1827.690500 \n",
            "loss: 0.037363 [40016/254309]                time taken: 1903.763413 \n",
            "loss: 0.149782 [41616/254309]                time taken: 1979.750180 \n",
            "loss: 0.114829 [43216/254309]                time taken: 2055.918631 \n",
            "loss: 0.515733 [44816/254309]                time taken: 2132.028669 \n",
            "loss: 0.029388 [46416/254309]                time taken: 2208.001739 \n",
            "loss: 0.212549 [48016/254309]                time taken: 2284.116225 \n",
            "loss: 0.074946 [49616/254309]                time taken: 2360.475385 \n",
            "loss: 0.237388 [51216/254309]                time taken: 2436.761558 \n",
            "loss: 0.027139 [52816/254309]                time taken: 2512.988314 \n",
            "loss: 0.039330 [54416/254309]                time taken: 2588.875023 \n",
            "loss: 0.116346 [56016/254309]                time taken: 2664.925603 \n",
            "loss: 0.055966 [57616/254309]                time taken: 2740.893153 \n",
            "loss: 0.146534 [59216/254309]                time taken: 2816.706795 \n",
            "loss: 0.203227 [60816/254309]                time taken: 2892.882402 \n",
            "loss: 0.016339 [62416/254309]                time taken: 2969.027881 \n",
            "loss: 0.014819 [64016/254309]                time taken: 3045.008505 \n",
            "loss: 0.003257 [65616/254309]                time taken: 3121.087109 \n",
            "loss: 0.174491 [67216/254309]                time taken: 3197.125321 \n",
            "loss: 0.165675 [68816/254309]                time taken: 3273.246287 \n",
            "loss: 0.120634 [70416/254309]                time taken: 3349.247410 \n",
            "loss: 0.138421 [72016/254309]                time taken: 3425.112858 \n",
            "loss: 0.138001 [73616/254309]                time taken: 3501.184326 \n",
            "loss: 0.131774 [75216/254309]                time taken: 3577.346071 \n",
            "loss: 0.164664 [76816/254309]                time taken: 3653.327504 \n",
            "loss: 0.447786 [78416/254309]                time taken: 3729.494679 \n",
            "loss: 0.243066 [80016/254309]                time taken: 3805.604302 \n",
            "loss: 0.004598 [81616/254309]                time taken: 3881.697146 \n",
            "loss: 0.167087 [83216/254309]                time taken: 3957.868244 \n",
            "loss: 0.198482 [84816/254309]                time taken: 4034.103148 \n",
            "loss: 0.103336 [86416/254309]                time taken: 4110.248405 \n",
            "loss: 0.099359 [88016/254309]                time taken: 4186.480392 \n",
            "loss: 0.043991 [89616/254309]                time taken: 4262.858489 \n",
            "loss: 0.057137 [91216/254309]                time taken: 4338.947420 \n",
            "loss: 0.175285 [92816/254309]                time taken: 4415.007626 \n",
            "loss: 0.039275 [94416/254309]                time taken: 4491.053653 \n",
            "loss: 0.010413 [96016/254309]                time taken: 4566.998345 \n",
            "loss: 0.110724 [97616/254309]                time taken: 4643.106972 \n",
            "loss: 0.128435 [99216/254309]                time taken: 4719.182584 \n",
            "loss: 0.013687 [100816/254309]                time taken: 4795.369008 \n",
            "loss: 0.026906 [102416/254309]                time taken: 4871.415628 \n",
            "loss: 0.068684 [104016/254309]                time taken: 4947.426748 \n",
            "loss: 0.104731 [105616/254309]                time taken: 5023.164617 \n",
            "loss: 0.294797 [107216/254309]                time taken: 5099.336111 \n",
            "loss: 0.025331 [108816/254309]                time taken: 5175.531505 \n",
            "loss: 0.200601 [110416/254309]                time taken: 5251.649360 \n",
            "loss: 0.042008 [112016/254309]                time taken: 5327.579387 \n",
            "loss: 0.071697 [113616/254309]                time taken: 5403.717015 \n",
            "loss: 0.146105 [115216/254309]                time taken: 5479.752626 \n",
            "loss: 0.004357 [116816/254309]                time taken: 5555.797586 \n",
            "loss: 0.087323 [118416/254309]                time taken: 5632.152414 \n",
            "loss: 0.061135 [120016/254309]                time taken: 5708.331647 \n",
            "loss: 0.000809 [121616/254309]                time taken: 5784.119429 \n",
            "loss: 0.055562 [123216/254309]                time taken: 5860.299791 \n",
            "loss: 0.458453 [124816/254309]                time taken: 5936.499758 \n",
            "loss: 0.181101 [126416/254309]                time taken: 6012.717425 \n",
            "loss: 0.024994 [128016/254309]                time taken: 6089.051936 \n",
            "loss: 0.010220 [129616/254309]                time taken: 6165.291378 \n",
            "loss: 0.003882 [131216/254309]                time taken: 6241.372916 \n",
            "loss: 0.016673 [132816/254309]                time taken: 6317.666576 \n",
            "loss: 0.131352 [134416/254309]                time taken: 6393.683930 \n",
            "loss: 0.122472 [136016/254309]                time taken: 6469.791359 \n",
            "loss: 0.099120 [137616/254309]                time taken: 6545.919131 \n",
            "loss: 0.018506 [139216/254309]                time taken: 6622.041093 \n",
            "loss: 0.108507 [140816/254309]                time taken: 6698.112689 \n",
            "loss: 0.007379 [142416/254309]                time taken: 6774.226201 \n",
            "loss: 0.312929 [144016/254309]                time taken: 6850.414626 \n",
            "loss: 0.346263 [145616/254309]                time taken: 6926.550956 \n",
            "loss: 0.012919 [147216/254309]                time taken: 7002.692121 \n",
            "loss: 0.148821 [148816/254309]                time taken: 7078.911138 \n",
            "loss: 0.121150 [150416/254309]                time taken: 7155.096095 \n",
            "loss: 0.103001 [152016/254309]                time taken: 7231.129150 \n",
            "loss: 0.209534 [153616/254309]                time taken: 7307.240925 \n",
            "loss: 0.391001 [155216/254309]                time taken: 7383.377353 \n",
            "loss: 0.077951 [156816/254309]                time taken: 7459.402786 \n",
            "loss: 0.007343 [158416/254309]                time taken: 7535.652128 \n",
            "loss: 0.183046 [160016/254309]                time taken: 7611.723753 \n",
            "loss: 0.079309 [161616/254309]                time taken: 7688.032595 \n",
            "loss: 0.116589 [163216/254309]                time taken: 7764.043321 \n",
            "loss: 0.064455 [164816/254309]                time taken: 7840.120125 \n",
            "loss: 0.003719 [166416/254309]                time taken: 7916.334935 \n",
            "loss: 0.023359 [168016/254309]                time taken: 7992.384882 \n",
            "loss: 0.165349 [169616/254309]                time taken: 8068.286717 \n",
            "loss: 0.112942 [171216/254309]                time taken: 8144.199172 \n",
            "loss: 0.075883 [172816/254309]                time taken: 8220.213798 \n",
            "loss: 0.398092 [174416/254309]                time taken: 8296.452462 \n",
            "loss: 0.042580 [176016/254309]                time taken: 8372.287244 \n",
            "loss: 0.266732 [177616/254309]                time taken: 8448.290711 \n",
            "loss: 0.052602 [179216/254309]                time taken: 8524.438944 \n",
            "loss: 0.025471 [180816/254309]                time taken: 8600.705884 \n",
            "loss: 0.027827 [182416/254309]                time taken: 8676.866943 \n",
            "loss: 0.039630 [184016/254309]                time taken: 8752.957769 \n",
            "loss: 0.529960 [185616/254309]                time taken: 8829.113632 \n",
            "loss: 0.007799 [187216/254309]                time taken: 8905.157717 \n",
            "loss: 0.023061 [188816/254309]                time taken: 8981.254557 \n",
            "loss: 0.043844 [190416/254309]                time taken: 9057.422299 \n",
            "loss: 0.021150 [192016/254309]                time taken: 9133.518847 \n",
            "loss: 0.019750 [193616/254309]                time taken: 9209.553914 \n",
            "loss: 0.165048 [195216/254309]                time taken: 9285.620013 \n",
            "loss: 0.051890 [196816/254309]                time taken: 9361.873989 \n",
            "loss: 0.066243 [198416/254309]                time taken: 9438.088399 \n",
            "loss: 0.039137 [200016/254309]                time taken: 9514.305797 \n",
            "loss: 0.053682 [201616/254309]                time taken: 9590.522480 \n",
            "loss: 0.149823 [203216/254309]                time taken: 9666.722979 \n",
            "loss: 0.020963 [204816/254309]                time taken: 9742.769425 \n",
            "loss: 0.058743 [206416/254309]                time taken: 9819.093455 \n",
            "loss: 0.088428 [208016/254309]                time taken: 9895.218407 \n",
            "loss: 0.077947 [209616/254309]                time taken: 9971.358728 \n",
            "loss: 0.005899 [211216/254309]                time taken: 10047.471437 \n",
            "loss: 0.012662 [212816/254309]                time taken: 10123.578620 \n",
            "loss: 0.165781 [214416/254309]                time taken: 10199.676318 \n",
            "loss: 0.043587 [216016/254309]                time taken: 10275.700314 \n",
            "loss: 0.081219 [217616/254309]                time taken: 10351.827560 \n",
            "loss: 0.006265 [219216/254309]                time taken: 10427.897408 \n",
            "loss: 0.018772 [220816/254309]                time taken: 10504.003675 \n",
            "loss: 0.004667 [222416/254309]                time taken: 10580.155826 \n",
            "loss: 0.135584 [224016/254309]                time taken: 10656.179473 \n",
            "loss: 0.070785 [225616/254309]                time taken: 10732.251868 \n",
            "loss: 0.114982 [227216/254309]                time taken: 10808.374943 \n",
            "loss: 0.252558 [228816/254309]                time taken: 10884.522808 \n",
            "loss: 0.110585 [230416/254309]                time taken: 10960.545489 \n",
            "loss: 0.000693 [232016/254309]                time taken: 11036.671956 \n",
            "loss: 0.081251 [233616/254309]                time taken: 11112.722616 \n",
            "loss: 0.019372 [235216/254309]                time taken: 11188.820711 \n",
            "loss: 0.035722 [236816/254309]                time taken: 11264.935877 \n",
            "loss: 0.144100 [238416/254309]                time taken: 11341.180373 \n",
            "loss: 0.008549 [240016/254309]                time taken: 11417.184395 \n",
            "loss: 0.057227 [241616/254309]                time taken: 11493.086630 \n",
            "loss: 0.067474 [243216/254309]                time taken: 11569.155963 \n",
            "loss: 0.307534 [244816/254309]                time taken: 11645.340857 \n",
            "loss: 0.212065 [246416/254309]                time taken: 11721.647441 \n",
            "loss: 0.275402 [248016/254309]                time taken: 11797.685681 \n",
            "loss: 0.015701 [249616/254309]                time taken: 11873.919880 \n",
            "loss: 0.039167 [251216/254309]                time taken: 11949.967124 \n",
            "loss: 0.089311 [252816/254309]                time taken: 12026.318439 \n",
            "Training loss: 0.095051\n",
            "Training accuracy: 95.989918\n",
            "Test loss: 0.164064\n",
            "Test accuracy: 93.835156\n",
            "Epoch 2 -----------------------------------\n",
            "loss: 0.011124 [   16/254309]                time taken: 0.767483 \n",
            "loss: 0.056823 [ 1616/254309]                time taken: 76.867054 \n",
            "loss: 0.047804 [ 3216/254309]                time taken: 152.960003 \n",
            "loss: 0.090895 [ 4816/254309]                time taken: 229.008226 \n",
            "loss: 0.010005 [ 6416/254309]                time taken: 304.927661 \n",
            "loss: 0.010608 [ 8016/254309]                time taken: 381.282683 \n",
            "loss: 0.001363 [ 9616/254309]                time taken: 457.356066 \n",
            "loss: 0.026643 [11216/254309]                time taken: 533.654882 \n",
            "loss: 0.003363 [12816/254309]                time taken: 609.914174 \n",
            "loss: 0.165714 [14416/254309]                time taken: 686.251664 \n",
            "loss: 0.001450 [16016/254309]                time taken: 762.551884 \n",
            "loss: 0.039867 [17616/254309]                time taken: 838.642128 \n",
            "loss: 0.016447 [19216/254309]                time taken: 914.631675 \n",
            "loss: 0.047381 [20816/254309]                time taken: 990.655316 \n",
            "loss: 0.016855 [22416/254309]                time taken: 1066.882854 \n",
            "loss: 0.093654 [24016/254309]                time taken: 1143.061756 \n",
            "loss: 0.066926 [25616/254309]                time taken: 1218.945926 \n",
            "loss: 0.039624 [27216/254309]                time taken: 1294.835195 \n",
            "loss: 0.073543 [28816/254309]                time taken: 1371.024234 \n",
            "loss: 0.006560 [30416/254309]                time taken: 1447.130468 \n",
            "loss: 0.035210 [32016/254309]                time taken: 1523.165794 \n",
            "loss: 0.253362 [33616/254309]                time taken: 1599.089561 \n",
            "loss: 0.000957 [35216/254309]                time taken: 1675.258912 \n",
            "loss: 0.054711 [36816/254309]                time taken: 1751.311376 \n",
            "loss: 0.014322 [38416/254309]                time taken: 1827.326265 \n",
            "loss: 0.149174 [40016/254309]                time taken: 1903.692311 \n",
            "loss: 0.069813 [41616/254309]                time taken: 1979.890994 \n",
            "loss: 0.012514 [43216/254309]                time taken: 2055.988624 \n",
            "loss: 0.034348 [44816/254309]                time taken: 2131.961540 \n",
            "loss: 0.177469 [46416/254309]                time taken: 2208.198378 \n",
            "loss: 0.009574 [48016/254309]                time taken: 2284.524542 \n",
            "loss: 0.019926 [49616/254309]                time taken: 2360.691970 \n",
            "loss: 0.013996 [51216/254309]                time taken: 2436.786842 \n",
            "loss: 0.248621 [52816/254309]                time taken: 2512.775877 \n",
            "loss: 0.113403 [54416/254309]                time taken: 2588.974624 \n",
            "loss: 0.159410 [56016/254309]                time taken: 2664.988006 \n",
            "loss: 0.126968 [57616/254309]                time taken: 2741.053942 \n",
            "loss: 0.152237 [59216/254309]                time taken: 2817.124785 \n",
            "loss: 0.114114 [60816/254309]                time taken: 2893.400214 \n",
            "loss: 0.067061 [62416/254309]                time taken: 2969.466108 \n",
            "loss: 0.019951 [64016/254309]                time taken: 3045.836841 \n",
            "loss: 0.099640 [65616/254309]                time taken: 3121.755318 \n",
            "loss: 0.031153 [67216/254309]                time taken: 3197.856445 \n",
            "loss: 0.005819 [68816/254309]                time taken: 3274.192730 \n",
            "loss: 0.256680 [70416/254309]                time taken: 3350.330268 \n",
            "loss: 0.012499 [72016/254309]                time taken: 3426.381060 \n",
            "loss: 0.051778 [73616/254309]                time taken: 3502.712771 \n",
            "loss: 0.110416 [75216/254309]                time taken: 3578.726964 \n",
            "loss: 0.077270 [76816/254309]                time taken: 3654.716866 \n",
            "loss: 0.026115 [78416/254309]                time taken: 3730.980655 \n",
            "loss: 0.002554 [80016/254309]                time taken: 3807.543466 \n",
            "loss: 0.200854 [81616/254309]                time taken: 3883.757396 \n",
            "loss: 0.247096 [83216/254309]                time taken: 3959.792853 \n",
            "loss: 0.121648 [84816/254309]                time taken: 4035.864436 \n",
            "loss: 0.090846 [86416/254309]                time taken: 4112.097105 \n",
            "loss: 0.002863 [88016/254309]                time taken: 4188.301446 \n",
            "loss: 0.133116 [89616/254309]                time taken: 4264.539402 \n",
            "loss: 0.020556 [91216/254309]                time taken: 4340.539178 \n",
            "loss: 0.000457 [92816/254309]                time taken: 4416.487643 \n",
            "loss: 0.296440 [94416/254309]                time taken: 4492.562272 \n",
            "loss: 0.102189 [96016/254309]                time taken: 4568.437533 \n",
            "loss: 0.061316 [97616/254309]                time taken: 4644.512505 \n",
            "loss: 0.062424 [99216/254309]                time taken: 4720.447921 \n",
            "loss: 0.001968 [100816/254309]                time taken: 4796.630182 \n",
            "loss: 0.066220 [102416/254309]                time taken: 4872.696362 \n",
            "loss: 0.109166 [104016/254309]                time taken: 4948.776269 \n",
            "loss: 0.010519 [105616/254309]                time taken: 5024.741462 \n",
            "loss: 0.057012 [107216/254309]                time taken: 5100.889565 \n",
            "loss: 0.271830 [108816/254309]                time taken: 5176.913177 \n",
            "loss: 0.002093 [110416/254309]                time taken: 5253.100142 \n",
            "loss: 0.016144 [112016/254309]                time taken: 5329.328119 \n",
            "loss: 0.018241 [113616/254309]                time taken: 5405.348542 \n",
            "loss: 0.011180 [115216/254309]                time taken: 5481.441954 \n",
            "loss: 0.060078 [116816/254309]                time taken: 5557.575424 \n",
            "loss: 0.029497 [118416/254309]                time taken: 5633.694962 \n",
            "loss: 0.132404 [120016/254309]                time taken: 5709.696744 \n",
            "loss: 0.011176 [121616/254309]                time taken: 5785.763805 \n",
            "loss: 0.038684 [123216/254309]                time taken: 5862.015422 \n",
            "loss: 0.001708 [124816/254309]                time taken: 5938.075769 \n",
            "loss: 0.084544 [126416/254309]                time taken: 6014.050022 \n",
            "loss: 0.058563 [128016/254309]                time taken: 6090.207595 \n",
            "loss: 0.011724 [129616/254309]                time taken: 6166.355305 \n",
            "loss: 0.027183 [131216/254309]                time taken: 6242.484902 \n",
            "loss: 0.069267 [132816/254309]                time taken: 6318.639518 \n",
            "loss: 0.048498 [134416/254309]                time taken: 6394.634182 \n",
            "loss: 0.037032 [136016/254309]                time taken: 6470.687994 \n",
            "loss: 0.087723 [137616/254309]                time taken: 6546.750477 \n",
            "loss: 0.044642 [139216/254309]                time taken: 6622.988412 \n",
            "loss: 0.002544 [140816/254309]                time taken: 6699.005284 \n",
            "loss: 0.059845 [142416/254309]                time taken: 6774.767660 \n",
            "loss: 0.140505 [144016/254309]                time taken: 6850.710601 \n",
            "loss: 0.005105 [145616/254309]                time taken: 6926.773833 \n",
            "loss: 0.011969 [147216/254309]                time taken: 7002.726519 \n",
            "loss: 0.005363 [148816/254309]                time taken: 7078.662343 \n",
            "loss: 0.074486 [150416/254309]                time taken: 7154.769177 \n",
            "loss: 0.001193 [152016/254309]                time taken: 7231.004030 \n",
            "loss: 0.039894 [153616/254309]                time taken: 7307.237878 \n",
            "loss: 0.217620 [155216/254309]                time taken: 7383.291839 \n",
            "loss: 0.000488 [156816/254309]                time taken: 7459.409347 \n",
            "loss: 0.001248 [158416/254309]                time taken: 7535.487460 \n",
            "loss: 0.002739 [160016/254309]                time taken: 7611.681020 \n",
            "loss: 0.111228 [161616/254309]                time taken: 7687.879520 \n",
            "loss: 0.045281 [163216/254309]                time taken: 7763.952363 \n",
            "loss: 0.218937 [164816/254309]                time taken: 7840.047998 \n",
            "loss: 0.067025 [166416/254309]                time taken: 7916.127287 \n",
            "loss: 0.009787 [168016/254309]                time taken: 7992.100870 \n",
            "loss: 0.000308 [169616/254309]                time taken: 8068.138046 \n",
            "loss: 0.002379 [171216/254309]                time taken: 8144.087712 \n",
            "loss: 0.125360 [172816/254309]                time taken: 8220.150096 \n",
            "loss: 0.090517 [174416/254309]                time taken: 8296.540489 \n",
            "loss: 0.196412 [176016/254309]                time taken: 8372.669383 \n",
            "loss: 0.100068 [177616/254309]                time taken: 8448.898107 \n",
            "loss: 0.001016 [179216/254309]                time taken: 8525.368431 \n",
            "loss: 0.009685 [180816/254309]                time taken: 8601.788270 \n",
            "loss: 0.004937 [182416/254309]                time taken: 8677.883782 \n",
            "loss: 0.045896 [184016/254309]                time taken: 8754.003031 \n",
            "loss: 0.008054 [185616/254309]                time taken: 8830.224366 \n",
            "loss: 0.000218 [187216/254309]                time taken: 8906.366723 \n",
            "loss: 0.027578 [188816/254309]                time taken: 8982.573500 \n",
            "loss: 0.004406 [190416/254309]                time taken: 9058.681680 \n",
            "loss: 0.011493 [192016/254309]                time taken: 9134.998147 \n",
            "loss: 0.057875 [193616/254309]                time taken: 9211.367234 \n",
            "loss: 0.255068 [195216/254309]                time taken: 9287.503955 \n",
            "loss: 0.073097 [196816/254309]                time taken: 9363.689063 \n",
            "loss: 0.381610 [198416/254309]                time taken: 9439.873656 \n",
            "loss: 0.089548 [200016/254309]                time taken: 9516.130620 \n",
            "loss: 0.041158 [201616/254309]                time taken: 9592.530791 \n",
            "loss: 0.035386 [203216/254309]                time taken: 9668.475961 \n",
            "loss: 0.000622 [204816/254309]                time taken: 9744.532338 \n",
            "loss: 0.068213 [206416/254309]                time taken: 9820.853629 \n",
            "loss: 0.084376 [208016/254309]                time taken: 9897.170977 \n",
            "loss: 0.026022 [209616/254309]                time taken: 9973.042893 \n",
            "loss: 0.093872 [211216/254309]                time taken: 10049.193867 \n",
            "loss: 0.002791 [212816/254309]                time taken: 10125.641287 \n",
            "loss: 0.069127 [214416/254309]                time taken: 10201.663772 \n",
            "loss: 0.045332 [216016/254309]                time taken: 10277.897036 \n",
            "loss: 0.072348 [217616/254309]                time taken: 10353.851581 \n",
            "loss: 0.125277 [219216/254309]                time taken: 10429.988191 \n",
            "loss: 0.127358 [220816/254309]                time taken: 10506.060723 \n",
            "loss: 0.014393 [222416/254309]                time taken: 10582.046772 \n",
            "loss: 0.009057 [224016/254309]                time taken: 10658.373373 \n",
            "loss: 0.073390 [225616/254309]                time taken: 10734.677639 \n",
            "loss: 0.000809 [227216/254309]                time taken: 10810.678169 \n",
            "loss: 0.040402 [228816/254309]                time taken: 10886.762122 \n",
            "loss: 0.016438 [230416/254309]                time taken: 10963.070240 \n",
            "loss: 0.068376 [232016/254309]                time taken: 11039.398408 \n",
            "loss: 0.037250 [233616/254309]                time taken: 11115.514958 \n",
            "loss: 0.039210 [235216/254309]                time taken: 11191.459803 \n",
            "loss: 0.022355 [236816/254309]                time taken: 11267.483588 \n",
            "loss: 0.023582 [238416/254309]                time taken: 11343.611837 \n",
            "loss: 0.069759 [240016/254309]                time taken: 11419.853162 \n",
            "loss: 0.008394 [241616/254309]                time taken: 11495.940633 \n",
            "loss: 0.133203 [243216/254309]                time taken: 11572.061965 \n",
            "loss: 0.276979 [244816/254309]                time taken: 11648.305738 \n",
            "loss: 0.052923 [246416/254309]                time taken: 11724.355056 \n",
            "loss: 0.267493 [248016/254309]                time taken: 11800.403577 \n",
            "loss: 0.114919 [249616/254309]                time taken: 11876.426597 \n",
            "loss: 0.010285 [251216/254309]                time taken: 11952.695574 \n",
            "loss: 0.038792 [252816/254309]                time taken: 12028.743749 \n",
            "Training loss: 0.066991\n",
            "Training accuracy: 97.277328\n",
            "Test loss: 0.182373\n",
            "Test accuracy: 93.778533\n",
            "Epoch 3 -----------------------------------\n",
            "loss: 0.006480 [   16/254309]                time taken: 0.770333 \n",
            "loss: 0.131607 [ 1616/254309]                time taken: 77.059270 \n",
            "loss: 0.092122 [ 3216/254309]                time taken: 153.221137 \n",
            "loss: 0.033794 [ 4816/254309]                time taken: 229.310747 \n",
            "loss: 0.155736 [ 6416/254309]                time taken: 305.523183 \n",
            "loss: 0.092274 [ 8016/254309]                time taken: 381.615070 \n",
            "loss: 0.004655 [ 9616/254309]                time taken: 457.758897 \n",
            "loss: 0.004958 [11216/254309]                time taken: 533.994897 \n",
            "loss: 0.009511 [12816/254309]                time taken: 610.155288 \n",
            "loss: 0.014368 [14416/254309]                time taken: 686.360879 \n",
            "loss: 0.014351 [16016/254309]                time taken: 762.565183 \n",
            "loss: 0.208564 [17616/254309]                time taken: 838.782175 \n",
            "loss: 0.138852 [19216/254309]                time taken: 914.999222 \n",
            "loss: 0.009830 [20816/254309]                time taken: 991.150860 \n",
            "loss: 0.016228 [22416/254309]                time taken: 1067.214762 \n",
            "loss: 0.136541 [24016/254309]                time taken: 1143.469898 \n",
            "loss: 0.061214 [25616/254309]                time taken: 1219.628604 \n",
            "loss: 0.005067 [27216/254309]                time taken: 1295.851892 \n",
            "loss: 0.146803 [28816/254309]                time taken: 1371.842963 \n",
            "loss: 0.001959 [30416/254309]                time taken: 1447.886021 \n",
            "loss: 0.047444 [32016/254309]                time taken: 1523.859914 \n",
            "loss: 0.004679 [33616/254309]                time taken: 1599.922811 \n",
            "loss: 0.042430 [35216/254309]                time taken: 1675.983737 \n",
            "loss: 0.012008 [36816/254309]                time taken: 1752.119903 \n",
            "loss: 0.004757 [38416/254309]                time taken: 1828.116256 \n",
            "loss: 0.036141 [40016/254309]                time taken: 1904.212000 \n",
            "loss: 0.038384 [41616/254309]                time taken: 1980.443190 \n",
            "loss: 0.021275 [43216/254309]                time taken: 2056.707455 \n",
            "loss: 0.114797 [44816/254309]                time taken: 2132.845267 \n",
            "loss: 0.015853 [46416/254309]                time taken: 2209.005632 \n",
            "loss: 0.059438 [48016/254309]                time taken: 2285.154227 \n",
            "loss: 0.013719 [49616/254309]                time taken: 2361.259109 \n",
            "loss: 0.012200 [51216/254309]                time taken: 2437.517753 \n",
            "loss: 0.146064 [52816/254309]                time taken: 2513.694685 \n",
            "loss: 0.072821 [54416/254309]                time taken: 2589.875958 \n",
            "loss: 0.008686 [56016/254309]                time taken: 2666.203057 \n",
            "loss: 0.016061 [57616/254309]                time taken: 2742.495971 \n",
            "loss: 0.000691 [59216/254309]                time taken: 2818.693050 \n",
            "loss: 0.002433 [60816/254309]                time taken: 2894.732742 \n",
            "loss: 0.003191 [62416/254309]                time taken: 2970.841472 \n",
            "loss: 0.012155 [64016/254309]                time taken: 3047.050122 \n",
            "loss: 0.047754 [65616/254309]                time taken: 3123.345317 \n",
            "loss: 0.003845 [67216/254309]                time taken: 3199.542458 \n",
            "loss: 0.099821 [68816/254309]                time taken: 3275.518630 \n",
            "loss: 0.006084 [70416/254309]                time taken: 3351.510585 \n",
            "loss: 0.018916 [72016/254309]                time taken: 3427.778532 \n",
            "loss: 0.010097 [73616/254309]                time taken: 3503.987534 \n",
            "loss: 0.003459 [75216/254309]                time taken: 3580.253214 \n",
            "loss: 0.000339 [76816/254309]                time taken: 3656.613156 \n",
            "loss: 0.012881 [78416/254309]                time taken: 3732.815847 \n",
            "loss: 0.000846 [80016/254309]                time taken: 3809.048461 \n",
            "loss: 0.001001 [81616/254309]                time taken: 3885.236342 \n",
            "loss: 0.056737 [83216/254309]                time taken: 3961.383387 \n",
            "loss: 0.079061 [84816/254309]                time taken: 4037.494925 \n",
            "loss: 0.003578 [86416/254309]                time taken: 4113.558278 \n",
            "loss: 0.113219 [88016/254309]                time taken: 4189.732532 \n",
            "loss: 0.002724 [89616/254309]                time taken: 4265.888265 \n",
            "loss: 0.154035 [91216/254309]                time taken: 4342.104625 \n",
            "loss: 0.202432 [92816/254309]                time taken: 4418.252991 \n",
            "loss: 0.000773 [94416/254309]                time taken: 4494.411486 \n",
            "loss: 0.262263 [96016/254309]                time taken: 4570.558578 \n",
            "loss: 0.009385 [97616/254309]                time taken: 4646.747515 \n",
            "loss: 0.216004 [99216/254309]                time taken: 4722.734830 \n",
            "loss: 0.170479 [100816/254309]                time taken: 4798.834916 \n",
            "loss: 0.040797 [102416/254309]                time taken: 4875.092017 \n",
            "loss: 0.087703 [104016/254309]                time taken: 4951.186196 \n",
            "loss: 0.001336 [105616/254309]                time taken: 5027.232870 \n",
            "loss: 0.000346 [107216/254309]                time taken: 5103.319734 \n",
            "loss: 0.120503 [108816/254309]                time taken: 5179.372472 \n",
            "loss: 0.022878 [110416/254309]                time taken: 5255.438582 \n",
            "loss: 0.019289 [112016/254309]                time taken: 5331.551116 \n",
            "loss: 0.003273 [113616/254309]                time taken: 5407.829333 \n",
            "loss: 0.125028 [115216/254309]                time taken: 5484.128979 \n",
            "loss: 0.010921 [116816/254309]                time taken: 5560.442247 \n",
            "loss: 0.037354 [118416/254309]                time taken: 5636.613186 \n",
            "loss: 0.030901 [120016/254309]                time taken: 5712.800102 \n",
            "loss: 0.052906 [121616/254309]                time taken: 5789.009049 \n",
            "loss: 0.020756 [123216/254309]                time taken: 5865.299217 \n",
            "loss: 0.041684 [124816/254309]                time taken: 5941.561357 \n",
            "loss: 0.000385 [126416/254309]                time taken: 6017.660402 \n",
            "loss: 0.066489 [128016/254309]                time taken: 6093.978988 \n",
            "loss: 0.060298 [129616/254309]                time taken: 6170.070728 \n",
            "loss: 0.036208 [131216/254309]                time taken: 6246.237895 \n",
            "loss: 0.030602 [132816/254309]                time taken: 6322.411503 \n",
            "loss: 0.062777 [134416/254309]                time taken: 6398.658653 \n",
            "loss: 0.068494 [136016/254309]                time taken: 6474.924549 \n",
            "loss: 0.011566 [137616/254309]                time taken: 6551.207212 \n",
            "loss: 0.005831 [139216/254309]                time taken: 6627.526535 \n",
            "loss: 0.000327 [140816/254309]                time taken: 6703.821058 \n",
            "loss: 0.001101 [142416/254309]                time taken: 6780.047726 \n",
            "loss: 0.026030 [144016/254309]                time taken: 6856.205972 \n",
            "loss: 0.010991 [145616/254309]                time taken: 6932.322158 \n",
            "loss: 0.278512 [147216/254309]                time taken: 7008.577384 \n",
            "loss: 0.153616 [148816/254309]                time taken: 7084.680616 \n",
            "loss: 0.051073 [150416/254309]                time taken: 7160.880162 \n",
            "loss: 0.000891 [152016/254309]                time taken: 7237.209165 \n",
            "loss: 0.024141 [153616/254309]                time taken: 7313.268516 \n",
            "loss: 0.011204 [155216/254309]                time taken: 7389.629040 \n",
            "loss: 0.002941 [156816/254309]                time taken: 7465.907720 \n",
            "loss: 0.002260 [158416/254309]                time taken: 7542.068179 \n",
            "loss: 0.001348 [160016/254309]                time taken: 7618.292031 \n",
            "loss: 0.015502 [161616/254309]                time taken: 7694.624032 \n",
            "loss: 0.029326 [163216/254309]                time taken: 7770.879452 \n",
            "loss: 0.276951 [164816/254309]                time taken: 7846.928938 \n",
            "loss: 0.223897 [166416/254309]                time taken: 7922.995207 \n",
            "loss: 0.030055 [168016/254309]                time taken: 7999.191755 \n",
            "loss: 0.000946 [169616/254309]                time taken: 8075.510684 \n",
            "loss: 0.237825 [171216/254309]                time taken: 8151.768492 \n",
            "loss: 0.000724 [172816/254309]                time taken: 8227.955612 \n",
            "loss: 0.337435 [174416/254309]                time taken: 8304.380680 \n",
            "loss: 0.287944 [176016/254309]                time taken: 8380.707219 \n",
            "loss: 0.005182 [177616/254309]                time taken: 8456.853701 \n",
            "loss: 0.005375 [179216/254309]                time taken: 8532.963695 \n",
            "loss: 0.024349 [180816/254309]                time taken: 8609.182186 \n",
            "loss: 0.110776 [182416/254309]                time taken: 8685.419923 \n",
            "loss: 0.003435 [184016/254309]                time taken: 8761.585165 \n",
            "loss: 0.001101 [185616/254309]                time taken: 8837.905722 \n",
            "loss: 0.126568 [187216/254309]                time taken: 8913.897612 \n",
            "loss: 0.005068 [188816/254309]                time taken: 8989.934814 \n",
            "loss: 0.014146 [190416/254309]                time taken: 9066.044741 \n",
            "loss: 0.032394 [192016/254309]                time taken: 9142.244351 \n",
            "loss: 0.145056 [193616/254309]                time taken: 9218.453595 \n",
            "loss: 0.084092 [195216/254309]                time taken: 9294.589235 \n",
            "loss: 0.012421 [196816/254309]                time taken: 9370.574171 \n",
            "loss: 0.059184 [198416/254309]                time taken: 9446.626311 \n",
            "loss: 0.080409 [200016/254309]                time taken: 9522.862003 \n",
            "loss: 0.004558 [201616/254309]                time taken: 9598.889939 \n",
            "loss: 0.311397 [203216/254309]                time taken: 9675.122966 \n",
            "loss: 0.073817 [204816/254309]                time taken: 9751.168026 \n",
            "loss: 0.096312 [206416/254309]                time taken: 9827.294028 \n",
            "loss: 0.041863 [208016/254309]                time taken: 9903.446529 \n",
            "loss: 0.011732 [209616/254309]                time taken: 9979.570218 \n",
            "loss: 0.005874 [211216/254309]                time taken: 10055.651368 \n",
            "loss: 0.001473 [212816/254309]                time taken: 10131.706097 \n",
            "loss: 0.001855 [214416/254309]                time taken: 10207.782951 \n",
            "loss: 0.002584 [216016/254309]                time taken: 10283.793713 \n",
            "loss: 0.066342 [217616/254309]                time taken: 10359.907817 \n",
            "loss: 0.005011 [219216/254309]                time taken: 10436.105227 \n",
            "loss: 0.043929 [220816/254309]                time taken: 10512.335188 \n",
            "loss: 0.075169 [222416/254309]                time taken: 10588.378429 \n",
            "loss: 0.066917 [224016/254309]                time taken: 10664.599070 \n",
            "loss: 0.144168 [225616/254309]                time taken: 10740.602679 \n",
            "loss: 0.167900 [227216/254309]                time taken: 10816.528598 \n",
            "loss: 0.032421 [228816/254309]                time taken: 10892.571055 \n",
            "loss: 0.023309 [230416/254309]                time taken: 10968.658719 \n",
            "loss: 0.018706 [232016/254309]                time taken: 11044.882638 \n",
            "loss: 0.000347 [233616/254309]                time taken: 11120.911719 \n",
            "loss: 0.002511 [235216/254309]                time taken: 11197.096256 \n",
            "loss: 0.009777 [236816/254309]                time taken: 11273.318385 \n",
            "loss: 0.015014 [238416/254309]                time taken: 11349.393841 \n",
            "loss: 0.025230 [240016/254309]                time taken: 11425.608256 \n",
            "loss: 0.047414 [241616/254309]                time taken: 11501.748378 \n",
            "loss: 0.203878 [243216/254309]                time taken: 11577.978187 \n",
            "loss: 0.120952 [244816/254309]                time taken: 11654.225237 \n",
            "loss: 0.040730 [246416/254309]                time taken: 11730.235846 \n",
            "loss: 0.002836 [248016/254309]                time taken: 11806.220080 \n",
            "loss: 0.005830 [249616/254309]                time taken: 11882.303183 \n",
            "loss: 0.016557 [251216/254309]                time taken: 11958.781275 \n",
            "loss: 0.008388 [252816/254309]                time taken: 12035.083155 \n",
            "Training loss: 0.047661\n",
            "Training accuracy: 98.134946\n",
            "Test loss: 0.227941\n",
            "Test accuracy: 93.332626\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "test_acc = []\n",
        "train_acc = []\n",
        "\n",
        "for i in range(3):\n",
        "    print(f'Epoch {i+1} -----------------------------------')\n",
        "    train(train_loader, model, loss_func, optimizer, train_losses, train_acc)\n",
        "    test(test_loader, model, loss_func, test_losses, test_acc)\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ExJe5HTqb5WY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ExJe5HTqb5WY",
        "outputId": "502a9223-aaf3-4afa-e2c4-da39f26ff8b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 -----------------------------------\n",
            "loss: 0.689344 [   16/568021]                time taken: 1.353821 \n",
            "loss: 0.473305 [ 1616/568021]                time taken: 75.214820 \n",
            "loss: 0.333022 [ 3216/568021]                time taken: 148.983366 \n",
            "loss: 0.619504 [ 4816/568021]                time taken: 222.807957 \n",
            "loss: 0.299276 [ 6416/568021]                time taken: 296.631696 \n",
            "loss: 0.240862 [ 8016/568021]                time taken: 370.487958 \n",
            "loss: 0.406432 [ 9616/568021]                time taken: 444.336664 \n",
            "loss: 0.461289 [11216/568021]                time taken: 518.129998 \n",
            "loss: 0.242528 [12816/568021]                time taken: 591.814389 \n",
            "loss: 0.369542 [14416/568021]                time taken: 665.598759 \n",
            "loss: 0.172537 [16016/568021]                time taken: 739.354654 \n",
            "loss: 0.289647 [17616/568021]                time taken: 813.098019 \n",
            "loss: 0.381710 [19216/568021]                time taken: 886.951777 \n",
            "loss: 0.218352 [20816/568021]                time taken: 960.801540 \n",
            "loss: 0.103384 [22416/568021]                time taken: 1034.616787 \n",
            "loss: 0.438015 [24016/568021]                time taken: 1108.400498 \n",
            "loss: 0.517813 [25616/568021]                time taken: 1182.376216 \n",
            "loss: 0.276092 [27216/568021]                time taken: 1256.246335 \n",
            "loss: 0.373104 [28816/568021]                time taken: 1330.026562 \n",
            "loss: 0.301793 [30416/568021]                time taken: 1403.756934 \n",
            "loss: 0.160776 [32016/568021]                time taken: 1477.468332 \n",
            "loss: 0.216465 [33616/568021]                time taken: 1551.154272 \n",
            "loss: 0.145814 [35216/568021]                time taken: 1624.921630 \n",
            "loss: 0.374997 [36816/568021]                time taken: 1698.681599 \n",
            "loss: 0.146667 [38416/568021]                time taken: 1772.469284 \n",
            "loss: 0.026585 [40016/568021]                time taken: 1846.292475 \n",
            "loss: 0.341377 [41616/568021]                time taken: 1920.185686 \n",
            "loss: 0.385321 [43216/568021]                time taken: 1994.128648 \n",
            "loss: 0.156991 [44816/568021]                time taken: 2068.048751 \n",
            "loss: 0.120480 [46416/568021]                time taken: 2141.775102 \n",
            "loss: 0.123136 [48016/568021]                time taken: 2215.474240 \n",
            "loss: 0.281675 [49616/568021]                time taken: 2289.322383 \n",
            "loss: 0.169378 [51216/568021]                time taken: 2363.144413 \n",
            "loss: 0.264052 [52816/568021]                time taken: 2436.919922 \n",
            "loss: 0.076907 [54416/568021]                time taken: 2510.722880 \n",
            "loss: 0.114255 [56016/568021]                time taken: 2584.525771 \n",
            "loss: 0.304575 [57616/568021]                time taken: 2658.398185 \n",
            "loss: 0.235083 [59216/568021]                time taken: 2732.257787 \n",
            "loss: 0.242180 [60816/568021]                time taken: 2806.145206 \n",
            "loss: 0.206887 [62416/568021]                time taken: 2879.996109 \n",
            "loss: 0.192992 [64016/568021]                time taken: 2953.859513 \n",
            "loss: 0.169430 [65616/568021]                time taken: 3027.785076 \n",
            "loss: 0.222984 [67216/568021]                time taken: 3101.616705 \n",
            "loss: 0.313342 [68816/568021]                time taken: 3175.532973 \n",
            "loss: 0.309645 [70416/568021]                time taken: 3249.290202 \n",
            "loss: 0.126834 [72016/568021]                time taken: 3323.173448 \n",
            "loss: 0.109084 [73616/568021]                time taken: 3397.140239 \n",
            "loss: 0.110324 [75216/568021]                time taken: 3470.845396 \n",
            "loss: 0.228157 [76816/568021]                time taken: 3544.504840 \n",
            "loss: 0.330149 [78416/568021]                time taken: 3618.238890 \n",
            "loss: 0.337497 [80016/568021]                time taken: 3691.990339 \n",
            "loss: 0.242983 [81616/568021]                time taken: 3765.893013 \n",
            "loss: 0.231354 [83216/568021]                time taken: 3839.699378 \n",
            "loss: 0.324944 [84816/568021]                time taken: 3913.484921 \n",
            "loss: 0.148230 [86416/568021]                time taken: 3987.418959 \n",
            "loss: 0.356611 [88016/568021]                time taken: 4061.241482 \n",
            "loss: 0.058819 [89616/568021]                time taken: 4134.952732 \n",
            "loss: 0.374769 [91216/568021]                time taken: 4208.770092 \n",
            "loss: 0.060345 [92816/568021]                time taken: 4282.768139 \n",
            "loss: 0.198359 [94416/568021]                time taken: 4356.675531 \n",
            "loss: 0.270181 [96016/568021]                time taken: 4430.399204 \n",
            "loss: 0.126307 [97616/568021]                time taken: 4504.248522 \n",
            "loss: 0.093010 [99216/568021]                time taken: 4578.069939 \n",
            "loss: 0.154403 [100816/568021]                time taken: 4651.907286 \n",
            "loss: 0.213381 [102416/568021]                time taken: 4725.821109 \n",
            "loss: 0.239550 [104016/568021]                time taken: 4799.728197 \n",
            "loss: 0.245247 [105616/568021]                time taken: 4873.548071 \n",
            "loss: 0.189175 [107216/568021]                time taken: 4947.447107 \n",
            "loss: 0.201995 [108816/568021]                time taken: 5021.352530 \n",
            "loss: 0.228033 [110416/568021]                time taken: 5095.239069 \n",
            "loss: 0.060125 [112016/568021]                time taken: 5169.055995 \n",
            "loss: 0.225313 [113616/568021]                time taken: 5242.869344 \n",
            "loss: 0.228004 [115216/568021]                time taken: 5316.627912 \n",
            "loss: 0.546270 [116816/568021]                time taken: 5390.416643 \n",
            "loss: 0.060585 [118416/568021]                time taken: 5464.263837 \n",
            "loss: 0.257964 [120016/568021]                time taken: 5538.059317 \n",
            "loss: 0.052151 [121616/568021]                time taken: 5611.938182 \n",
            "loss: 0.276063 [123216/568021]                time taken: 5685.796164 \n",
            "loss: 0.120296 [124816/568021]                time taken: 5759.497285 \n",
            "loss: 0.137852 [126416/568021]                time taken: 5833.338217 \n",
            "loss: 0.263141 [128016/568021]                time taken: 5907.140177 \n",
            "loss: 0.119686 [129616/568021]                time taken: 5981.067527 \n",
            "loss: 0.256892 [131216/568021]                time taken: 6054.761241 \n",
            "loss: 0.124357 [132816/568021]                time taken: 6128.541002 \n",
            "loss: 0.435624 [134416/568021]                time taken: 6202.486371 \n",
            "loss: 0.133189 [136016/568021]                time taken: 6276.300507 \n",
            "loss: 0.251451 [137616/568021]                time taken: 6350.068707 \n",
            "loss: 0.075014 [139216/568021]                time taken: 6423.949408 \n",
            "loss: 0.113412 [140816/568021]                time taken: 6497.795457 \n",
            "loss: 0.080972 [142416/568021]                time taken: 6571.586090 \n",
            "loss: 0.142352 [144016/568021]                time taken: 6645.296761 \n",
            "loss: 0.465283 [145616/568021]                time taken: 6719.027265 \n",
            "loss: 0.141216 [147216/568021]                time taken: 6792.729267 \n",
            "loss: 0.070573 [148816/568021]                time taken: 6866.561010 \n",
            "loss: 0.192008 [150416/568021]                time taken: 6940.311379 \n",
            "loss: 0.220426 [152016/568021]                time taken: 7014.257450 \n",
            "loss: 0.121517 [153616/568021]                time taken: 7087.950403 \n",
            "loss: 0.053109 [155216/568021]                time taken: 7161.688622 \n",
            "loss: 0.124018 [156816/568021]                time taken: 7235.470978 \n",
            "loss: 0.014105 [158416/568021]                time taken: 7309.212176 \n",
            "loss: 0.084771 [160016/568021]                time taken: 7382.967110 \n",
            "loss: 0.006492 [161616/568021]                time taken: 7456.740591 \n",
            "loss: 0.157001 [163216/568021]                time taken: 7530.620789 \n",
            "loss: 0.271515 [164816/568021]                time taken: 7604.375652 \n",
            "loss: 0.243146 [166416/568021]                time taken: 7678.126595 \n",
            "loss: 0.149132 [168016/568021]                time taken: 7751.939312 \n",
            "loss: 0.225598 [169616/568021]                time taken: 7825.741894 \n",
            "loss: 0.133524 [171216/568021]                time taken: 7899.586764 \n",
            "loss: 0.330248 [172816/568021]                time taken: 7973.360146 \n",
            "loss: 0.105661 [174416/568021]                time taken: 8047.258452 \n",
            "loss: 0.047722 [176016/568021]                time taken: 8121.039587 \n",
            "loss: 0.545917 [177616/568021]                time taken: 8194.845665 \n",
            "loss: 0.084144 [179216/568021]                time taken: 8268.704525 \n",
            "loss: 0.092487 [180816/568021]                time taken: 8342.448359 \n",
            "loss: 0.098631 [182416/568021]                time taken: 8416.337901 \n",
            "loss: 0.227189 [184016/568021]                time taken: 8490.042831 \n",
            "loss: 0.128754 [185616/568021]                time taken: 8563.841141 \n",
            "loss: 0.112009 [187216/568021]                time taken: 8637.589311 \n",
            "loss: 0.409312 [188816/568021]                time taken: 8711.378056 \n",
            "loss: 0.664151 [190416/568021]                time taken: 8785.211501 \n",
            "loss: 0.176179 [192016/568021]                time taken: 8858.994257 \n",
            "loss: 0.225510 [193616/568021]                time taken: 8932.847777 \n",
            "loss: 0.039631 [195216/568021]                time taken: 9006.695534 \n",
            "loss: 0.088052 [196816/568021]                time taken: 9080.456962 \n",
            "loss: 0.174527 [198416/568021]                time taken: 9154.216181 \n",
            "loss: 0.136088 [200016/568021]                time taken: 9228.017921 \n",
            "loss: 0.216949 [201616/568021]                time taken: 9301.944861 \n",
            "loss: 0.406138 [203216/568021]                time taken: 9375.836130 \n",
            "loss: 0.246799 [204816/568021]                time taken: 9449.811975 \n",
            "loss: 0.061285 [206416/568021]                time taken: 9523.658645 \n",
            "loss: 0.139102 [208016/568021]                time taken: 9597.440750 \n",
            "loss: 0.153370 [209616/568021]                time taken: 9671.243807 \n",
            "loss: 0.117991 [211216/568021]                time taken: 9745.115048 \n",
            "loss: 0.274938 [212816/568021]                time taken: 9818.867694 \n",
            "loss: 0.077222 [214416/568021]                time taken: 9892.691183 \n",
            "loss: 0.415070 [216016/568021]                time taken: 9966.493728 \n",
            "loss: 0.080312 [217616/568021]                time taken: 10040.382571 \n",
            "loss: 0.672065 [219216/568021]                time taken: 10114.126019 \n",
            "loss: 0.471213 [220816/568021]                time taken: 10187.999585 \n",
            "loss: 0.248059 [222416/568021]                time taken: 10261.736965 \n",
            "loss: 0.038152 [224016/568021]                time taken: 10335.490910 \n",
            "loss: 0.014632 [225616/568021]                time taken: 10409.322176 \n",
            "loss: 0.225811 [227216/568021]                time taken: 10483.059484 \n",
            "loss: 0.008934 [228816/568021]                time taken: 10556.952426 \n",
            "loss: 0.076583 [230416/568021]                time taken: 10630.829397 \n",
            "loss: 0.221960 [232016/568021]                time taken: 10704.534091 \n",
            "loss: 0.199166 [233616/568021]                time taken: 10778.343717 \n",
            "loss: 0.120464 [235216/568021]                time taken: 10852.136512 \n",
            "loss: 0.224554 [236816/568021]                time taken: 10925.927340 \n",
            "loss: 0.124133 [238416/568021]                time taken: 10999.853223 \n",
            "loss: 0.178773 [240016/568021]                time taken: 11073.679345 \n",
            "loss: 0.537016 [241616/568021]                time taken: 11147.621213 \n",
            "loss: 0.034647 [243216/568021]                time taken: 11221.484107 \n",
            "loss: 0.064250 [244816/568021]                time taken: 11295.304351 \n",
            "loss: 0.060590 [246416/568021]                time taken: 11369.223399 \n",
            "loss: 0.091319 [248016/568021]                time taken: 11443.200390 \n",
            "loss: 0.071323 [249616/568021]                time taken: 11516.942518 \n",
            "loss: 0.159363 [251216/568021]                time taken: 11590.737597 \n",
            "loss: 0.019406 [252816/568021]                time taken: 11664.618888 \n",
            "loss: 0.052968 [254416/568021]                time taken: 11738.395408 \n",
            "loss: 0.165044 [256016/568021]                time taken: 11812.200571 \n",
            "loss: 0.174184 [257616/568021]                time taken: 11886.044369 \n",
            "loss: 0.254749 [259216/568021]                time taken: 11959.752217 \n",
            "loss: 0.145298 [260816/568021]                time taken: 12033.541384 \n",
            "loss: 0.064671 [262416/568021]                time taken: 12107.309849 \n",
            "loss: 0.098379 [264016/568021]                time taken: 12181.112023 \n",
            "loss: 0.217305 [265616/568021]                time taken: 12254.881584 \n",
            "loss: 0.067438 [267216/568021]                time taken: 12328.684756 \n",
            "loss: 0.349877 [268816/568021]                time taken: 12402.503173 \n",
            "loss: 0.170665 [270416/568021]                time taken: 12476.446633 \n",
            "loss: 0.330393 [272016/568021]                time taken: 12550.365389 \n",
            "loss: 0.196292 [273616/568021]                time taken: 12624.241464 \n",
            "loss: 0.355612 [275216/568021]                time taken: 12698.016984 \n",
            "loss: 0.274982 [276816/568021]                time taken: 12771.758083 \n",
            "loss: 0.068305 [278416/568021]                time taken: 12845.572615 \n",
            "loss: 0.046568 [280016/568021]                time taken: 12919.302498 \n",
            "loss: 0.216792 [281616/568021]                time taken: 12993.121194 \n",
            "loss: 0.202969 [283216/568021]                time taken: 13066.965480 \n",
            "loss: 0.545333 [284816/568021]                time taken: 13140.783057 \n",
            "loss: 0.180211 [286416/568021]                time taken: 13214.557666 \n",
            "loss: 0.115664 [288016/568021]                time taken: 13288.362048 \n",
            "loss: 0.307721 [289616/568021]                time taken: 13362.299060 \n",
            "loss: 0.283290 [291216/568021]                time taken: 13436.228720 \n",
            "loss: 0.178724 [292816/568021]                time taken: 13510.119213 \n",
            "loss: 0.100092 [294416/568021]                time taken: 13583.969702 \n",
            "loss: 0.273131 [296016/568021]                time taken: 13657.868990 \n",
            "loss: 0.095173 [297616/568021]                time taken: 13731.683588 \n",
            "loss: 0.156439 [299216/568021]                time taken: 13805.518751 \n",
            "loss: 0.200051 [300816/568021]                time taken: 13879.266505 \n",
            "loss: 0.104225 [302416/568021]                time taken: 13953.028656 \n",
            "loss: 0.266597 [304016/568021]                time taken: 14026.737141 \n",
            "loss: 0.251686 [305616/568021]                time taken: 14100.523835 \n",
            "loss: 0.091542 [307216/568021]                time taken: 14174.400529 \n",
            "loss: 0.084436 [308816/568021]                time taken: 14248.116157 \n",
            "loss: 0.127930 [310416/568021]                time taken: 14321.936559 \n",
            "loss: 0.265180 [312016/568021]                time taken: 14395.826520 \n",
            "loss: 0.113156 [313616/568021]                time taken: 14469.769663 \n",
            "loss: 0.170960 [315216/568021]                time taken: 14543.702370 \n",
            "loss: 0.128816 [316816/568021]                time taken: 14617.588131 \n",
            "loss: 0.109900 [318416/568021]                time taken: 14691.412431 \n",
            "loss: 0.127145 [320016/568021]                time taken: 14765.167934 \n",
            "loss: 0.200365 [321616/568021]                time taken: 14839.053284 \n",
            "loss: 0.443416 [323216/568021]                time taken: 14912.892045 \n",
            "loss: 0.271188 [324816/568021]                time taken: 14986.634711 \n",
            "loss: 0.056071 [326416/568021]                time taken: 15060.541582 \n",
            "loss: 0.101016 [328016/568021]                time taken: 15134.302735 \n",
            "loss: 0.029009 [329616/568021]                time taken: 15208.106801 \n",
            "loss: 0.218650 [331216/568021]                time taken: 15282.081400 \n",
            "loss: 0.298091 [332816/568021]                time taken: 15356.046232 \n",
            "loss: 0.298260 [334416/568021]                time taken: 15429.937637 \n",
            "loss: 0.089348 [336016/568021]                time taken: 15503.889586 \n",
            "loss: 0.041854 [337616/568021]                time taken: 15577.713057 \n",
            "loss: 0.107120 [339216/568021]                time taken: 15651.512872 \n",
            "loss: 0.049469 [340816/568021]                time taken: 15725.474732 \n",
            "loss: 0.219674 [342416/568021]                time taken: 15799.275190 \n",
            "loss: 0.147607 [344016/568021]                time taken: 15873.094811 \n",
            "loss: 0.049113 [345616/568021]                time taken: 15946.874100 \n",
            "loss: 0.185792 [347216/568021]                time taken: 16020.872402 \n",
            "loss: 0.088361 [348816/568021]                time taken: 16094.765144 \n",
            "loss: 0.116842 [350416/568021]                time taken: 16168.667315 \n",
            "loss: 0.164264 [352016/568021]                time taken: 16242.571861 \n",
            "loss: 0.032789 [353616/568021]                time taken: 16316.476152 \n",
            "loss: 0.144235 [355216/568021]                time taken: 16390.367048 \n",
            "loss: 0.216811 [356816/568021]                time taken: 16464.250042 \n",
            "loss: 0.087604 [358416/568021]                time taken: 16538.195712 \n",
            "loss: 0.178696 [360016/568021]                time taken: 16612.072500 \n",
            "loss: 0.133414 [361616/568021]                time taken: 16685.881119 \n",
            "loss: 0.136511 [363216/568021]                time taken: 16759.656817 \n",
            "loss: 0.077070 [364816/568021]                time taken: 16833.454767 \n",
            "loss: 0.089787 [366416/568021]                time taken: 16907.406137 \n",
            "loss: 0.467357 [368016/568021]                time taken: 16981.115659 \n",
            "loss: 0.129951 [369616/568021]                time taken: 17054.937064 \n",
            "loss: 0.109219 [371216/568021]                time taken: 17128.858751 \n",
            "loss: 0.044674 [372816/568021]                time taken: 17202.699253 \n",
            "loss: 0.167135 [374416/568021]                time taken: 17276.440524 \n",
            "loss: 0.312715 [376016/568021]                time taken: 17350.105789 \n",
            "loss: 0.222587 [377616/568021]                time taken: 17423.851313 \n",
            "loss: 0.206966 [379216/568021]                time taken: 17497.578609 \n",
            "loss: 0.031218 [380816/568021]                time taken: 17571.446748 \n",
            "loss: 0.067814 [382416/568021]                time taken: 17645.398229 \n",
            "loss: 0.122411 [384016/568021]                time taken: 17719.277290 \n",
            "loss: 0.126314 [385616/568021]                time taken: 17793.121261 \n",
            "loss: 0.159057 [387216/568021]                time taken: 17866.826255 \n",
            "loss: 0.144925 [388816/568021]                time taken: 17940.557888 \n",
            "loss: 0.067592 [390416/568021]                time taken: 18014.182208 \n",
            "loss: 0.183410 [392016/568021]                time taken: 18087.887974 \n",
            "loss: 0.107600 [393616/568021]                time taken: 18161.901425 \n",
            "loss: 0.222501 [395216/568021]                time taken: 18235.867433 \n",
            "loss: 0.152189 [396816/568021]                time taken: 18309.763478 \n",
            "loss: 0.393094 [398416/568021]                time taken: 18383.501297 \n",
            "loss: 0.085168 [400016/568021]                time taken: 18457.337257 \n",
            "loss: 0.097434 [401616/568021]                time taken: 18531.199296 \n",
            "loss: 0.131381 [403216/568021]                time taken: 18605.081882 \n",
            "loss: 0.066054 [404816/568021]                time taken: 18678.952978 \n",
            "loss: 0.029157 [406416/568021]                time taken: 18752.707185 \n",
            "loss: 0.106142 [408016/568021]                time taken: 18826.529760 \n",
            "loss: 0.068916 [409616/568021]                time taken: 18900.298384 \n",
            "loss: 0.034516 [411216/568021]                time taken: 18973.907189 \n",
            "loss: 0.153667 [412816/568021]                time taken: 19047.697781 \n",
            "loss: 0.028005 [414416/568021]                time taken: 19121.513723 \n",
            "loss: 0.279993 [416016/568021]                time taken: 19195.328035 \n",
            "loss: 0.490048 [417616/568021]                time taken: 19269.255446 \n",
            "loss: 0.172819 [419216/568021]                time taken: 19343.186873 \n",
            "loss: 0.013149 [420816/568021]                time taken: 19417.118532 \n",
            "loss: 0.306413 [422416/568021]                time taken: 19491.010095 \n",
            "loss: 0.128874 [424016/568021]                time taken: 19564.722541 \n",
            "loss: 0.332283 [425616/568021]                time taken: 19638.498806 \n",
            "loss: 0.051354 [427216/568021]                time taken: 19712.447773 \n",
            "loss: 0.065581 [428816/568021]                time taken: 19786.300594 \n",
            "loss: 0.066514 [430416/568021]                time taken: 19860.061433 \n",
            "loss: 0.268659 [432016/568021]                time taken: 19933.938171 \n",
            "loss: 0.147323 [433616/568021]                time taken: 20007.661908 \n",
            "loss: 0.023377 [435216/568021]                time taken: 20081.498700 \n",
            "loss: 0.161702 [436816/568021]                time taken: 20155.367561 \n",
            "loss: 0.048464 [438416/568021]                time taken: 20229.132784 \n",
            "loss: 0.105904 [440016/568021]                time taken: 20302.839845 \n",
            "loss: 0.200149 [441616/568021]                time taken: 20376.489154 \n",
            "loss: 0.146957 [443216/568021]                time taken: 20450.188617 \n",
            "loss: 0.094364 [444816/568021]                time taken: 20523.898726 \n",
            "loss: 0.063951 [446416/568021]                time taken: 20597.810621 \n",
            "loss: 0.092276 [448016/568021]                time taken: 20671.699636 \n",
            "loss: 0.063270 [449616/568021]                time taken: 20745.618406 \n",
            "loss: 0.032123 [451216/568021]                time taken: 20819.526106 \n",
            "loss: 0.275162 [452816/568021]                time taken: 20893.268310 \n",
            "loss: 0.103959 [454416/568021]                time taken: 20967.029053 \n",
            "loss: 0.063426 [456016/568021]                time taken: 21040.803928 \n",
            "loss: 0.093699 [457616/568021]                time taken: 21114.545222 \n",
            "loss: 0.043652 [459216/568021]                time taken: 21188.391531 \n",
            "loss: 0.177578 [460816/568021]                time taken: 21262.308899 \n",
            "loss: 0.170154 [462416/568021]                time taken: 21336.130530 \n",
            "loss: 0.064921 [464016/568021]                time taken: 21409.885450 \n",
            "loss: 0.238903 [465616/568021]                time taken: 21483.684383 \n",
            "loss: 0.046735 [467216/568021]                time taken: 21557.409065 \n",
            "loss: 0.251221 [468816/568021]                time taken: 21631.273372 \n",
            "loss: 0.145537 [470416/568021]                time taken: 21705.146592 \n",
            "loss: 0.080593 [472016/568021]                time taken: 21778.928105 \n",
            "loss: 0.078979 [473616/568021]                time taken: 21852.775513 \n",
            "loss: 0.121471 [475216/568021]                time taken: 21926.571903 \n",
            "loss: 0.203224 [476816/568021]                time taken: 22000.234173 \n",
            "loss: 0.095224 [478416/568021]                time taken: 22073.944342 \n",
            "loss: 0.269994 [480016/568021]                time taken: 22147.607172 \n",
            "loss: 0.028839 [481616/568021]                time taken: 22221.336245 \n",
            "loss: 0.065080 [483216/568021]                time taken: 22295.057884 \n",
            "loss: 0.216694 [484816/568021]                time taken: 22369.017581 \n",
            "loss: 0.059787 [486416/568021]                time taken: 22443.038542 \n",
            "loss: 0.033818 [488016/568021]                time taken: 22516.901989 \n",
            "loss: 0.151578 [489616/568021]                time taken: 22590.762917 \n",
            "loss: 0.018148 [491216/568021]                time taken: 22664.540362 \n",
            "loss: 0.034231 [492816/568021]                time taken: 22738.418926 \n",
            "loss: 0.072406 [494416/568021]                time taken: 22812.436248 \n",
            "loss: 0.152444 [496016/568021]                time taken: 22886.376697 \n",
            "loss: 0.098820 [497616/568021]                time taken: 22960.189465 \n",
            "loss: 0.373399 [499216/568021]                time taken: 23033.938043 \n",
            "loss: 0.193172 [500816/568021]                time taken: 23107.758345 \n",
            "loss: 0.259677 [502416/568021]                time taken: 23181.523068 \n",
            "loss: 0.004198 [504016/568021]                time taken: 23255.408793 \n",
            "loss: 0.208917 [505616/568021]                time taken: 23329.245560 \n",
            "loss: 0.340466 [507216/568021]                time taken: 23403.061606 \n",
            "loss: 0.235579 [508816/568021]                time taken: 23476.932579 \n",
            "loss: 0.018284 [510416/568021]                time taken: 23550.778338 \n",
            "loss: 0.056239 [512016/568021]                time taken: 23624.541858 \n",
            "loss: 0.072193 [513616/568021]                time taken: 23698.335354 \n",
            "loss: 0.100694 [515216/568021]                time taken: 23772.131684 \n",
            "loss: 0.200014 [516816/568021]                time taken: 23845.877292 \n",
            "loss: 0.181222 [518416/568021]                time taken: 23919.728645 \n",
            "loss: 0.033819 [520016/568021]                time taken: 23993.464524 \n",
            "loss: 0.073090 [521616/568021]                time taken: 24067.301939 \n",
            "loss: 0.385141 [523216/568021]                time taken: 24141.078270 \n",
            "loss: 0.083496 [524816/568021]                time taken: 24214.754001 \n",
            "loss: 0.222404 [526416/568021]                time taken: 24288.424973 \n",
            "loss: 0.160900 [528016/568021]                time taken: 24362.190444 \n",
            "loss: 0.235385 [529616/568021]                time taken: 24435.899226 \n",
            "loss: 0.150190 [531216/568021]                time taken: 24509.667130 \n",
            "loss: 0.174425 [532816/568021]                time taken: 24583.479585 \n",
            "loss: 0.183210 [534416/568021]                time taken: 24657.230783 \n",
            "loss: 0.029016 [536016/568021]                time taken: 24730.979475 \n",
            "loss: 0.152217 [537616/568021]                time taken: 24804.847800 \n",
            "loss: 0.098956 [539216/568021]                time taken: 24878.665599 \n",
            "loss: 0.020304 [540816/568021]                time taken: 24952.515680 \n",
            "loss: 0.091551 [542416/568021]                time taken: 25026.309191 \n",
            "loss: 0.085143 [544016/568021]                time taken: 25100.113895 \n",
            "loss: 0.038575 [545616/568021]                time taken: 25173.891339 \n",
            "loss: 0.134562 [547216/568021]                time taken: 25247.652134 \n",
            "loss: 0.064132 [548816/568021]                time taken: 25321.316884 \n",
            "loss: 0.262822 [550416/568021]                time taken: 25395.055896 \n",
            "loss: 0.110360 [552016/568021]                time taken: 25468.850459 \n",
            "loss: 0.165276 [553616/568021]                time taken: 25542.739611 \n",
            "loss: 0.092572 [555216/568021]                time taken: 25616.581081 \n",
            "loss: 0.017475 [556816/568021]                time taken: 25690.455156 \n",
            "loss: 0.081585 [558416/568021]                time taken: 25764.280139 \n",
            "loss: 0.165005 [560016/568021]                time taken: 25838.121585 \n",
            "loss: 0.158320 [561616/568021]                time taken: 25912.010631 \n",
            "loss: 0.111831 [563216/568021]                time taken: 25985.865352 \n",
            "loss: 0.110275 [564816/568021]                time taken: 26059.676988 \n",
            "loss: 0.224607 [566416/568021]                time taken: 26133.544481 \n",
            "loss: 0.301147 [568016/568021]                time taken: 26207.339625 \n",
            "Training loss: 0.174871\n",
            "Training accuracy: 92.223351\n",
            "________\n",
            "Test loss: 0.167511\n",
            "Test accuracy: 93.0%\n",
            "Epoch 2 -----------------------------------\n",
            "loss: 0.112369 [   16/568021]                time taken: 0.757106 \n",
            "loss: 0.027850 [ 1616/568021]                time taken: 74.625000 \n",
            "loss: 0.046285 [ 3216/568021]                time taken: 148.396940 \n",
            "loss: 0.040031 [ 4816/568021]                time taken: 222.292337 \n",
            "loss: 0.064279 [ 6416/568021]                time taken: 296.071566 \n",
            "loss: 0.022112 [ 8016/568021]                time taken: 369.873342 \n",
            "loss: 0.057694 [ 9616/568021]                time taken: 443.735229 \n",
            "loss: 0.142840 [11216/568021]                time taken: 517.461596 \n",
            "loss: 0.258959 [12816/568021]                time taken: 591.327888 \n",
            "loss: 0.040538 [14416/568021]                time taken: 665.101910 \n",
            "loss: 0.243149 [16016/568021]                time taken: 738.731234 \n",
            "loss: 0.316977 [17616/568021]                time taken: 812.468961 \n",
            "loss: 0.062970 [19216/568021]                time taken: 886.203763 \n",
            "loss: 0.157536 [20816/568021]                time taken: 959.831043 \n",
            "loss: 0.016993 [22416/568021]                time taken: 1033.571869 \n",
            "loss: 0.069772 [24016/568021]                time taken: 1107.377666 \n",
            "loss: 0.175353 [25616/568021]                time taken: 1181.102328 \n",
            "loss: 0.041439 [27216/568021]                time taken: 1254.860656 \n",
            "loss: 0.092072 [28816/568021]                time taken: 1328.708348 \n",
            "loss: 0.138195 [30416/568021]                time taken: 1402.477216 \n",
            "loss: 0.023516 [32016/568021]                time taken: 1476.208380 \n",
            "loss: 0.027789 [33616/568021]                time taken: 1550.010708 \n",
            "loss: 0.301929 [35216/568021]                time taken: 1623.755352 \n",
            "loss: 0.084732 [36816/568021]                time taken: 1697.667871 \n",
            "loss: 0.273392 [38416/568021]                time taken: 1771.386498 \n",
            "loss: 0.159009 [40016/568021]                time taken: 1844.989668 \n",
            "loss: 0.139581 [41616/568021]                time taken: 1918.620152 \n",
            "loss: 0.160310 [43216/568021]                time taken: 1992.248629 \n",
            "loss: 0.315688 [44816/568021]                time taken: 2066.028025 \n",
            "loss: 0.026787 [46416/568021]                time taken: 2139.777328 \n",
            "loss: 0.131406 [48016/568021]                time taken: 2213.580474 \n",
            "loss: 0.034010 [49616/568021]                time taken: 2287.476276 \n",
            "loss: 0.145695 [51216/568021]                time taken: 2361.289872 \n",
            "loss: 0.262247 [52816/568021]                time taken: 2435.118999 \n",
            "loss: 0.092099 [54416/568021]                time taken: 2508.899261 \n",
            "loss: 0.247014 [56016/568021]                time taken: 2582.662942 \n",
            "loss: 0.040840 [57616/568021]                time taken: 2656.501249 \n",
            "loss: 0.102514 [59216/568021]                time taken: 2730.361354 \n",
            "loss: 0.007923 [60816/568021]                time taken: 2804.216228 \n",
            "loss: 0.041769 [62416/568021]                time taken: 2878.181380 \n",
            "loss: 0.003735 [64016/568021]                time taken: 2952.027500 \n",
            "loss: 0.083631 [65616/568021]                time taken: 3025.977596 \n",
            "loss: 0.147788 [67216/568021]                time taken: 3099.761938 \n",
            "loss: 0.028330 [68816/568021]                time taken: 3173.489432 \n",
            "loss: 0.155829 [70416/568021]                time taken: 3247.376835 \n",
            "loss: 0.061136 [72016/568021]                time taken: 3321.096987 \n",
            "loss: 0.145296 [73616/568021]                time taken: 3394.950056 \n",
            "loss: 0.339116 [75216/568021]                time taken: 3468.913069 \n",
            "loss: 0.074744 [76816/568021]                time taken: 3542.750639 \n",
            "loss: 0.118849 [78416/568021]                time taken: 3616.481296 \n",
            "loss: 0.023351 [80016/568021]                time taken: 3690.184407 \n",
            "loss: 0.053309 [81616/568021]                time taken: 3764.133310 \n",
            "loss: 0.122776 [83216/568021]                time taken: 3837.997283 \n",
            "loss: 0.133282 [84816/568021]                time taken: 3911.875740 \n",
            "loss: 0.033230 [86416/568021]                time taken: 3985.534334 \n",
            "loss: 0.016744 [88016/568021]                time taken: 4059.422782 \n",
            "loss: 0.204286 [89616/568021]                time taken: 4133.399245 \n",
            "loss: 0.019437 [91216/568021]                time taken: 4207.180636 \n",
            "loss: 0.057083 [92816/568021]                time taken: 4280.799446 \n",
            "loss: 0.007446 [94416/568021]                time taken: 4354.591315 \n",
            "loss: 0.272958 [96016/568021]                time taken: 4428.541694 \n",
            "loss: 0.013837 [97616/568021]                time taken: 4502.262679 \n",
            "loss: 0.112631 [99216/568021]                time taken: 4575.942373 \n",
            "loss: 0.251323 [100816/568021]                time taken: 4649.539939 \n",
            "loss: 0.089597 [102416/568021]                time taken: 4723.224748 \n",
            "loss: 0.123210 [104016/568021]                time taken: 4797.134700 \n",
            "loss: 0.072950 [105616/568021]                time taken: 4870.894871 \n",
            "loss: 0.077519 [107216/568021]                time taken: 4944.640305 \n",
            "loss: 0.112724 [108816/568021]                time taken: 5018.383922 \n",
            "loss: 0.059621 [110416/568021]                time taken: 5092.059638 \n",
            "loss: 0.160673 [112016/568021]                time taken: 5165.774889 \n",
            "loss: 0.035427 [113616/568021]                time taken: 5239.371095 \n",
            "loss: 0.062855 [115216/568021]                time taken: 5313.127157 \n",
            "loss: 0.039587 [116816/568021]                time taken: 5386.830214 \n",
            "loss: 0.008366 [118416/568021]                time taken: 5460.614665 \n",
            "loss: 0.157642 [120016/568021]                time taken: 5534.312767 \n",
            "loss: 0.030419 [121616/568021]                time taken: 5608.006510 \n",
            "loss: 0.035505 [123216/568021]                time taken: 5681.817471 \n",
            "loss: 0.360220 [124816/568021]                time taken: 5755.594126 \n",
            "loss: 0.038259 [126416/568021]                time taken: 5829.358980 \n",
            "loss: 0.053287 [128016/568021]                time taken: 5903.046027 \n",
            "loss: 0.057981 [129616/568021]                time taken: 5976.774248 \n",
            "loss: 0.113714 [131216/568021]                time taken: 6050.559335 \n",
            "loss: 0.087017 [132816/568021]                time taken: 6124.520406 \n",
            "loss: 0.109464 [134416/568021]                time taken: 6198.477318 \n",
            "loss: 0.006719 [136016/568021]                time taken: 6272.234711 \n",
            "loss: 0.038492 [137616/568021]                time taken: 6346.076832 \n",
            "loss: 0.277702 [139216/568021]                time taken: 6419.970622 \n",
            "loss: 0.028407 [140816/568021]                time taken: 6493.900290 \n",
            "loss: 0.019104 [142416/568021]                time taken: 6567.791870 \n",
            "loss: 0.010589 [144016/568021]                time taken: 6641.503926 \n",
            "loss: 0.060678 [145616/568021]                time taken: 6715.352071 \n",
            "loss: 0.171001 [147216/568021]                time taken: 6789.196095 \n",
            "loss: 0.018202 [148816/568021]                time taken: 6863.012751 \n",
            "loss: 0.127671 [150416/568021]                time taken: 6936.707778 \n",
            "loss: 0.077674 [152016/568021]                time taken: 7010.489450 \n",
            "loss: 0.067171 [153616/568021]                time taken: 7084.528493 \n",
            "loss: 0.081796 [155216/568021]                time taken: 7158.500789 \n",
            "loss: 0.166873 [156816/568021]                time taken: 7232.301705 \n",
            "loss: 0.031804 [158416/568021]                time taken: 7305.999384 \n",
            "loss: 0.009304 [160016/568021]                time taken: 7379.663544 \n",
            "loss: 0.109050 [161616/568021]                time taken: 7453.611425 \n",
            "loss: 0.297676 [163216/568021]                time taken: 7527.450601 \n",
            "loss: 0.118772 [164816/568021]                time taken: 7601.227952 \n",
            "loss: 0.031290 [166416/568021]                time taken: 7674.910976 \n",
            "loss: 0.004738 [168016/568021]                time taken: 7748.826169 \n",
            "loss: 0.030592 [169616/568021]                time taken: 7822.814291 \n",
            "loss: 0.166339 [171216/568021]                time taken: 7896.680294 \n",
            "loss: 0.092559 [172816/568021]                time taken: 7970.556384 \n",
            "loss: 0.064162 [174416/568021]                time taken: 8044.330885 \n",
            "loss: 0.139825 [176016/568021]                time taken: 8118.113889 \n",
            "loss: 0.169404 [177616/568021]                time taken: 8191.946436 \n",
            "loss: 0.336153 [179216/568021]                time taken: 8265.736393 \n",
            "loss: 0.031249 [180816/568021]                time taken: 8339.473783 \n",
            "loss: 0.042555 [182416/568021]                time taken: 8413.202442 \n",
            "loss: 0.050832 [184016/568021]                time taken: 8487.039946 \n",
            "loss: 0.132308 [185616/568021]                time taken: 8561.002992 \n",
            "loss: 0.057020 [187216/568021]                time taken: 8634.929107 \n",
            "loss: 0.344095 [188816/568021]                time taken: 8708.797279 \n",
            "loss: 0.163684 [190416/568021]                time taken: 8782.503477 \n",
            "loss: 0.199456 [192016/568021]                time taken: 8856.336432 \n",
            "loss: 0.072948 [193616/568021]                time taken: 8930.219164 \n",
            "loss: 0.063663 [195216/568021]                time taken: 9004.021702 \n",
            "loss: 0.159776 [196816/568021]                time taken: 9077.851746 \n",
            "loss: 0.030429 [198416/568021]                time taken: 9151.749264 \n",
            "loss: 0.031551 [200016/568021]                time taken: 9225.474307 \n",
            "loss: 0.138727 [201616/568021]                time taken: 9299.312944 \n",
            "loss: 0.041335 [203216/568021]                time taken: 9373.072256 \n",
            "loss: 0.064323 [204816/568021]                time taken: 9446.963916 \n",
            "loss: 0.034779 [206416/568021]                time taken: 9520.731786 \n",
            "loss: 0.090511 [208016/568021]                time taken: 9594.674499 \n",
            "loss: 0.043502 [209616/568021]                time taken: 9668.537767 \n",
            "loss: 0.075652 [211216/568021]                time taken: 9742.269000 \n",
            "loss: 0.160900 [212816/568021]                time taken: 9816.006658 \n",
            "loss: 0.170625 [214416/568021]                time taken: 9889.857853 \n",
            "loss: 0.233496 [216016/568021]                time taken: 9963.739162 \n",
            "loss: 0.082956 [217616/568021]                time taken: 10037.389541 \n",
            "loss: 0.084842 [219216/568021]                time taken: 10111.131577 \n",
            "loss: 0.110631 [220816/568021]                time taken: 10184.835411 \n",
            "loss: 0.097566 [222416/568021]                time taken: 10258.697963 \n",
            "loss: 0.225587 [224016/568021]                time taken: 10332.561364 \n",
            "loss: 0.092706 [225616/568021]                time taken: 10406.278265 \n",
            "loss: 0.109136 [227216/568021]                time taken: 10480.124578 \n",
            "loss: 0.096217 [228816/568021]                time taken: 10554.097454 \n",
            "loss: 0.049711 [230416/568021]                time taken: 10627.894487 \n",
            "loss: 0.161697 [232016/568021]                time taken: 10701.676791 \n",
            "loss: 0.006961 [233616/568021]                time taken: 10775.613469 \n",
            "loss: 0.127217 [235216/568021]                time taken: 10849.330069 \n",
            "loss: 0.153972 [236816/568021]                time taken: 10923.272009 \n",
            "loss: 0.002730 [238416/568021]                time taken: 10997.190035 \n",
            "loss: 0.122671 [240016/568021]                time taken: 11071.007726 \n",
            "loss: 0.034739 [241616/568021]                time taken: 11144.790330 \n",
            "loss: 0.328664 [243216/568021]                time taken: 11218.461751 \n",
            "loss: 0.165027 [244816/568021]                time taken: 11292.383188 \n",
            "loss: 0.040322 [246416/568021]                time taken: 11366.233777 \n",
            "loss: 0.085814 [248016/568021]                time taken: 11440.180337 \n",
            "loss: 0.165736 [249616/568021]                time taken: 11513.925354 \n",
            "loss: 0.036159 [251216/568021]                time taken: 11587.663683 \n",
            "loss: 0.078593 [252816/568021]                time taken: 11661.404150 \n",
            "loss: 0.083086 [254416/568021]                time taken: 11735.330488 \n",
            "loss: 0.046406 [256016/568021]                time taken: 11809.133136 \n",
            "loss: 0.005913 [257616/568021]                time taken: 11882.943293 \n",
            "loss: 0.390689 [259216/568021]                time taken: 11956.797061 \n",
            "loss: 0.123933 [260816/568021]                time taken: 12030.633113 \n",
            "loss: 0.072062 [262416/568021]                time taken: 12104.424236 \n",
            "loss: 0.110970 [264016/568021]                time taken: 12178.096732 \n",
            "loss: 0.100925 [265616/568021]                time taken: 12251.835172 \n",
            "loss: 0.116135 [267216/568021]                time taken: 12325.651891 \n",
            "loss: 0.241306 [268816/568021]                time taken: 12399.496682 \n",
            "loss: 0.066128 [270416/568021]                time taken: 12473.426533 \n",
            "loss: 0.053847 [272016/568021]                time taken: 12547.187770 \n",
            "loss: 0.226437 [273616/568021]                time taken: 12620.917418 \n",
            "loss: 0.038467 [275216/568021]                time taken: 12694.712096 \n",
            "loss: 0.340935 [276816/568021]                time taken: 12768.666298 \n",
            "loss: 0.153094 [278416/568021]                time taken: 12842.409543 \n",
            "loss: 0.006442 [280016/568021]                time taken: 12916.240924 \n",
            "loss: 0.173061 [281616/568021]                time taken: 12990.053384 \n",
            "loss: 0.068230 [283216/568021]                time taken: 13063.926308 \n",
            "loss: 0.073256 [284816/568021]                time taken: 13137.666355 \n",
            "loss: 0.122627 [286416/568021]                time taken: 13211.261879 \n",
            "loss: 0.245035 [288016/568021]                time taken: 13285.031997 \n",
            "loss: 0.002378 [289616/568021]                time taken: 13358.856894 \n",
            "loss: 0.227220 [291216/568021]                time taken: 13432.740593 \n",
            "loss: 0.342966 [292816/568021]                time taken: 13506.751045 \n",
            "loss: 0.151547 [294416/568021]                time taken: 13580.519194 \n",
            "loss: 0.068801 [296016/568021]                time taken: 13654.175535 \n",
            "loss: 0.135424 [297616/568021]                time taken: 13727.939221 \n",
            "loss: 0.307664 [299216/568021]                time taken: 13801.690130 \n",
            "loss: 0.411638 [300816/568021]                time taken: 13875.533619 \n",
            "loss: 0.195361 [302416/568021]                time taken: 13949.313226 \n",
            "loss: 0.024618 [304016/568021]                time taken: 14023.025782 \n",
            "loss: 0.004587 [305616/568021]                time taken: 14096.798036 \n",
            "loss: 0.002339 [307216/568021]                time taken: 14170.714244 \n",
            "loss: 0.036624 [308816/568021]                time taken: 14244.536690 \n",
            "loss: 0.197602 [310416/568021]                time taken: 14318.289214 \n",
            "loss: 0.106534 [312016/568021]                time taken: 14392.117007 \n",
            "loss: 0.041364 [313616/568021]                time taken: 14465.896506 \n",
            "loss: 0.171957 [315216/568021]                time taken: 14539.509562 \n",
            "loss: 0.462601 [316816/568021]                time taken: 14613.199473 \n",
            "loss: 0.093328 [318416/568021]                time taken: 14687.079812 \n",
            "loss: 0.233290 [320016/568021]                time taken: 14760.894017 \n",
            "loss: 0.108308 [321616/568021]                time taken: 14834.820037 \n",
            "loss: 0.047152 [323216/568021]                time taken: 14908.718829 \n",
            "loss: 0.021649 [324816/568021]                time taken: 14982.539684 \n",
            "loss: 0.037664 [326416/568021]                time taken: 15056.197778 \n",
            "loss: 0.011627 [328016/568021]                time taken: 15129.877367 \n",
            "loss: 0.111725 [329616/568021]                time taken: 15203.820533 \n",
            "loss: 0.133789 [331216/568021]                time taken: 15277.526035 \n",
            "loss: 0.081214 [332816/568021]                time taken: 15351.187919 \n",
            "loss: 0.225002 [334416/568021]                time taken: 15424.954620 \n",
            "loss: 0.035644 [336016/568021]                time taken: 15498.721534 \n",
            "loss: 0.082507 [337616/568021]                time taken: 15572.653987 \n",
            "loss: 0.173504 [339216/568021]                time taken: 15646.452343 \n",
            "loss: 0.123405 [340816/568021]                time taken: 15720.155956 \n",
            "loss: 0.194415 [342416/568021]                time taken: 15793.821994 \n",
            "loss: 0.250641 [344016/568021]                time taken: 15867.650212 \n",
            "loss: 0.122363 [345616/568021]                time taken: 15941.607890 \n",
            "loss: 0.046899 [347216/568021]                time taken: 16015.347147 \n",
            "loss: 0.117272 [348816/568021]                time taken: 16089.168182 \n",
            "loss: 0.091105 [350416/568021]                time taken: 16162.813485 \n",
            "loss: 0.053526 [352016/568021]                time taken: 16236.472603 \n",
            "loss: 0.258239 [353616/568021]                time taken: 16310.220921 \n",
            "loss: 0.135871 [355216/568021]                time taken: 16384.176261 \n",
            "loss: 0.138515 [356816/568021]                time taken: 16457.952078 \n",
            "loss: 0.177868 [358416/568021]                time taken: 16531.723586 \n",
            "loss: 0.094510 [360016/568021]                time taken: 16605.676150 \n",
            "loss: 0.252075 [361616/568021]                time taken: 16679.454360 \n",
            "loss: 0.085452 [363216/568021]                time taken: 16753.276425 \n",
            "loss: 0.050387 [364816/568021]                time taken: 16826.982120 \n",
            "loss: 0.191356 [366416/568021]                time taken: 16900.731134 \n",
            "loss: 0.027637 [368016/568021]                time taken: 16974.426720 \n",
            "loss: 0.060110 [369616/568021]                time taken: 17048.105414 \n",
            "loss: 0.096246 [371216/568021]                time taken: 17122.032181 \n",
            "loss: 0.032098 [372816/568021]                time taken: 17195.873007 \n",
            "loss: 0.102565 [374416/568021]                time taken: 17269.612270 \n",
            "loss: 0.211739 [376016/568021]                time taken: 17343.370863 \n",
            "loss: 0.097877 [377616/568021]                time taken: 17417.089236 \n",
            "loss: 0.204455 [379216/568021]                time taken: 17490.839925 \n",
            "loss: 0.203743 [380816/568021]                time taken: 17564.528380 \n",
            "loss: 0.193574 [382416/568021]                time taken: 17638.364289 \n",
            "loss: 0.088054 [384016/568021]                time taken: 17712.109464 \n",
            "loss: 0.111527 [385616/568021]                time taken: 17785.888291 \n",
            "loss: 0.129529 [387216/568021]                time taken: 17859.582608 \n",
            "loss: 0.127498 [388816/568021]                time taken: 17933.353005 \n",
            "loss: 0.060627 [390416/568021]                time taken: 18007.197204 \n",
            "loss: 0.122047 [392016/568021]                time taken: 18081.198252 \n",
            "loss: 0.106289 [393616/568021]                time taken: 18155.024368 \n",
            "loss: 0.115683 [395216/568021]                time taken: 18228.859975 \n",
            "loss: 0.137044 [396816/568021]                time taken: 18302.497503 \n",
            "loss: 0.024736 [398416/568021]                time taken: 18376.178299 \n",
            "loss: 0.053969 [400016/568021]                time taken: 18449.837579 \n",
            "loss: 0.062592 [401616/568021]                time taken: 18523.743653 \n",
            "loss: 0.015623 [403216/568021]                time taken: 18597.554514 \n",
            "loss: 0.054389 [404816/568021]                time taken: 18671.470712 \n",
            "loss: 0.045152 [406416/568021]                time taken: 18745.333197 \n",
            "loss: 0.118378 [408016/568021]                time taken: 18819.277615 \n",
            "loss: 0.230363 [409616/568021]                time taken: 18893.126992 \n",
            "loss: 0.085571 [411216/568021]                time taken: 18966.933551 \n",
            "loss: 0.094733 [412816/568021]                time taken: 19040.754122 \n",
            "loss: 0.001640 [414416/568021]                time taken: 19114.526152 \n",
            "loss: 0.042593 [416016/568021]                time taken: 19188.321292 \n",
            "loss: 0.108735 [417616/568021]                time taken: 19262.060855 \n",
            "loss: 0.084162 [419216/568021]                time taken: 19335.748760 \n",
            "loss: 0.052634 [420816/568021]                time taken: 19409.541719 \n",
            "loss: 0.022716 [422416/568021]                time taken: 19483.413928 \n",
            "loss: 0.054195 [424016/568021]                time taken: 19557.216856 \n",
            "loss: 0.073955 [425616/568021]                time taken: 19630.962689 \n",
            "loss: 0.242863 [427216/568021]                time taken: 19704.786062 \n",
            "loss: 0.044481 [428816/568021]                time taken: 19778.665491 \n",
            "loss: 0.012846 [430416/568021]                time taken: 19852.431770 \n",
            "loss: 0.069294 [432016/568021]                time taken: 19926.115677 \n",
            "loss: 0.029983 [433616/568021]                time taken: 19999.766319 \n",
            "loss: 0.196048 [435216/568021]                time taken: 20073.777019 \n",
            "loss: 0.113675 [436816/568021]                time taken: 20147.550790 \n",
            "loss: 0.184234 [438416/568021]                time taken: 20221.183945 \n",
            "loss: 0.092817 [440016/568021]                time taken: 20294.876841 \n",
            "loss: 0.109472 [441616/568021]                time taken: 20368.723181 \n",
            "loss: 0.065610 [443216/568021]                time taken: 20442.663619 \n",
            "loss: 0.051016 [444816/568021]                time taken: 20516.489611 \n",
            "loss: 0.080802 [446416/568021]                time taken: 20590.214525 \n",
            "loss: 0.299003 [448016/568021]                time taken: 20663.897250 \n",
            "loss: 0.011405 [449616/568021]                time taken: 20737.854630 \n",
            "loss: 0.100138 [451216/568021]                time taken: 20811.825679 \n",
            "loss: 0.012234 [452816/568021]                time taken: 20885.633972 \n",
            "loss: 0.166985 [454416/568021]                time taken: 20959.344259 \n",
            "loss: 0.021188 [456016/568021]                time taken: 21033.130424 \n",
            "loss: 0.007425 [457616/568021]                time taken: 21106.816775 \n",
            "loss: 0.282505 [459216/568021]                time taken: 21180.678810 \n",
            "loss: 0.357816 [460816/568021]                time taken: 21254.684182 \n",
            "loss: 0.035293 [462416/568021]                time taken: 21328.529090 \n",
            "loss: 0.107774 [464016/568021]                time taken: 21402.259303 \n",
            "loss: 0.047856 [465616/568021]                time taken: 21476.058966 \n",
            "loss: 0.138968 [467216/568021]                time taken: 21549.735023 \n",
            "loss: 0.088625 [468816/568021]                time taken: 21623.373197 \n",
            "loss: 0.083814 [470416/568021]                time taken: 21697.237327 \n",
            "loss: 0.212094 [472016/568021]                time taken: 21771.128818 \n",
            "loss: 0.091095 [473616/568021]                time taken: 21845.006738 \n",
            "loss: 0.079821 [475216/568021]                time taken: 21918.794458 \n",
            "loss: 0.066027 [476816/568021]                time taken: 21992.565690 \n",
            "loss: 0.006209 [478416/568021]                time taken: 22066.206145 \n",
            "loss: 0.004422 [480016/568021]                time taken: 22139.993551 \n",
            "loss: 0.149501 [481616/568021]                time taken: 22213.817404 \n",
            "loss: 0.137638 [483216/568021]                time taken: 22287.737697 \n",
            "loss: 0.206227 [484816/568021]                time taken: 22361.435279 \n",
            "loss: 0.034922 [486416/568021]                time taken: 22435.154041 \n",
            "loss: 0.109094 [488016/568021]                time taken: 22508.976592 \n",
            "loss: 0.167957 [489616/568021]                time taken: 22582.867550 \n",
            "loss: 0.115058 [491216/568021]                time taken: 22656.789743 \n",
            "loss: 0.133960 [492816/568021]                time taken: 22730.533798 \n",
            "loss: 0.067353 [494416/568021]                time taken: 22804.223234 \n",
            "loss: 0.075852 [496016/568021]                time taken: 22877.952544 \n",
            "loss: 0.055639 [497616/568021]                time taken: 22951.670161 \n",
            "loss: 0.009177 [499216/568021]                time taken: 23025.471750 \n",
            "loss: 0.109798 [500816/568021]                time taken: 23099.036333 \n",
            "loss: 0.038321 [502416/568021]                time taken: 23172.839818 \n",
            "loss: 0.150958 [504016/568021]                time taken: 23246.564020 \n",
            "loss: 0.061634 [505616/568021]                time taken: 23320.317867 \n",
            "loss: 0.020373 [507216/568021]                time taken: 23394.112757 \n",
            "loss: 0.062235 [508816/568021]                time taken: 23467.996447 \n",
            "loss: 0.158133 [510416/568021]                time taken: 23541.759365 \n",
            "loss: 0.114751 [512016/568021]                time taken: 23615.531224 \n",
            "loss: 0.240804 [513616/568021]                time taken: 23689.417564 \n",
            "loss: 0.001860 [515216/568021]                time taken: 23763.334344 \n",
            "loss: 0.406583 [516816/568021]                time taken: 23837.223959 \n",
            "loss: 0.253719 [518416/568021]                time taken: 23910.992454 \n",
            "loss: 0.133599 [520016/568021]                time taken: 23984.773373 \n",
            "loss: 0.124749 [521616/568021]                time taken: 24058.561459 \n",
            "loss: 0.101093 [523216/568021]                time taken: 24132.454245 \n",
            "loss: 0.011798 [524816/568021]                time taken: 24206.365620 \n",
            "loss: 0.062948 [526416/568021]                time taken: 24280.149147 \n",
            "loss: 0.129220 [528016/568021]                time taken: 24353.867710 \n",
            "loss: 0.056862 [529616/568021]                time taken: 24427.534929 \n",
            "loss: 0.058057 [531216/568021]                time taken: 24501.451213 \n",
            "loss: 0.106180 [532816/568021]                time taken: 24575.456694 \n",
            "loss: 0.025387 [534416/568021]                time taken: 24649.307451 \n",
            "loss: 0.263202 [536016/568021]                time taken: 24723.085605 \n",
            "loss: 0.007988 [537616/568021]                time taken: 24796.954120 \n",
            "loss: 0.115194 [539216/568021]                time taken: 24870.761764 \n",
            "loss: 0.008841 [540816/568021]                time taken: 24944.598784 \n",
            "loss: 0.083458 [542416/568021]                time taken: 25018.334989 \n",
            "loss: 0.154044 [544016/568021]                time taken: 25092.083367 \n",
            "loss: 0.022438 [545616/568021]                time taken: 25165.813036 \n",
            "loss: 0.019053 [547216/568021]                time taken: 25239.752081 \n",
            "loss: 0.089131 [548816/568021]                time taken: 25313.728955 \n",
            "loss: 0.009574 [550416/568021]                time taken: 25387.528830 \n",
            "loss: 0.075097 [552016/568021]                time taken: 25461.323245 \n",
            "loss: 0.035257 [553616/568021]                time taken: 25535.056866 \n",
            "loss: 0.013530 [555216/568021]                time taken: 25608.678397 \n",
            "loss: 0.128784 [556816/568021]                time taken: 25682.516043 \n",
            "loss: 0.028103 [558416/568021]                time taken: 25756.473001 \n",
            "loss: 0.018547 [560016/568021]                time taken: 25830.279513 \n",
            "loss: 0.112547 [561616/568021]                time taken: 25904.020890 \n",
            "loss: 0.075294 [563216/568021]                time taken: 25977.746640 \n",
            "loss: 0.289227 [564816/568021]                time taken: 26051.391526 \n",
            "loss: 0.052235 [566416/568021]                time taken: 26125.226035 \n",
            "loss: 0.071629 [568016/568021]                time taken: 26199.076243 \n",
            "Training loss: 0.108612\n",
            "Training accuracy: 95.426930\n",
            "________\n",
            "Test loss: 0.134478\n",
            "Test accuracy: 94.9%\n",
            "Epoch 3 -----------------------------------\n",
            "loss: 0.003527 [   16/568021]                time taken: 0.760350 \n",
            "loss: 0.025523 [ 1616/568021]                time taken: 74.641647 \n",
            "loss: 0.006731 [ 3216/568021]                time taken: 148.503654 \n",
            "loss: 0.027518 [ 4816/568021]                time taken: 222.330302 \n",
            "loss: 0.057992 [ 6416/568021]                time taken: 296.007163 \n",
            "loss: 0.180549 [ 8016/568021]                time taken: 369.659997 \n",
            "loss: 0.047064 [ 9616/568021]                time taken: 443.511682 \n",
            "loss: 0.104530 [11216/568021]                time taken: 517.385820 \n",
            "loss: 0.071622 [12816/568021]                time taken: 591.267845 \n",
            "loss: 0.012300 [14416/568021]                time taken: 664.967823 \n",
            "loss: 0.001524 [16016/568021]                time taken: 738.694634 \n",
            "loss: 0.141224 [17616/568021]                time taken: 812.657171 \n",
            "loss: 0.100394 [19216/568021]                time taken: 886.428938 \n",
            "loss: 0.031901 [20816/568021]                time taken: 960.206855 \n",
            "loss: 0.263800 [22416/568021]                time taken: 1033.911782 \n",
            "loss: 0.013195 [24016/568021]                time taken: 1107.737074 \n",
            "loss: 0.042205 [25616/568021]                time taken: 1181.536966 \n",
            "loss: 0.145473 [27216/568021]                time taken: 1255.357474 \n",
            "loss: 0.046632 [28816/568021]                time taken: 1329.070202 \n",
            "loss: 0.006592 [30416/568021]                time taken: 1402.853048 \n",
            "loss: 0.100237 [32016/568021]                time taken: 1476.608546 \n",
            "loss: 0.025639 [33616/568021]                time taken: 1550.475578 \n",
            "loss: 0.188586 [35216/568021]                time taken: 1624.281585 \n",
            "loss: 0.040641 [36816/568021]                time taken: 1698.058934 \n",
            "loss: 0.072187 [38416/568021]                time taken: 1771.791325 \n",
            "loss: 0.035214 [40016/568021]                time taken: 1845.651240 \n",
            "loss: 0.199986 [41616/568021]                time taken: 1919.508040 \n",
            "loss: 0.010316 [43216/568021]                time taken: 1993.343205 \n",
            "loss: 0.056251 [44816/568021]                time taken: 2067.069319 \n",
            "loss: 0.072642 [46416/568021]                time taken: 2140.830946 \n",
            "loss: 0.018002 [48016/568021]                time taken: 2214.539579 \n",
            "loss: 0.072194 [49616/568021]                time taken: 2288.389724 \n",
            "loss: 0.018073 [51216/568021]                time taken: 2362.124671 \n",
            "loss: 0.021771 [52816/568021]                time taken: 2435.937142 \n",
            "loss: 0.028231 [54416/568021]                time taken: 2509.739862 \n",
            "loss: 0.129714 [56016/568021]                time taken: 2583.517686 \n",
            "loss: 0.004743 [57616/568021]                time taken: 2657.329962 \n",
            "loss: 0.009995 [59216/568021]                time taken: 2731.214575 \n",
            "loss: 0.125762 [60816/568021]                time taken: 2805.161041 \n",
            "loss: 0.024691 [62416/568021]                time taken: 2878.905275 \n",
            "loss: 0.002860 [64016/568021]                time taken: 2952.762219 \n",
            "loss: 0.018918 [65616/568021]                time taken: 3026.541425 \n",
            "loss: 0.013806 [67216/568021]                time taken: 3100.540419 \n",
            "loss: 0.018309 [68816/568021]                time taken: 3174.444950 \n",
            "loss: 0.056099 [70416/568021]                time taken: 3248.168003 \n",
            "loss: 0.002164 [72016/568021]                time taken: 3321.897340 \n",
            "loss: 0.124651 [73616/568021]                time taken: 3395.509519 \n",
            "loss: 0.039989 [75216/568021]                time taken: 3469.274085 \n",
            "loss: 0.051059 [76816/568021]                time taken: 3543.112832 \n",
            "loss: 0.106681 [78416/568021]                time taken: 3617.018464 \n",
            "loss: 0.005285 [80016/568021]                time taken: 3690.941237 \n",
            "loss: 0.004557 [81616/568021]                time taken: 3764.766158 \n",
            "loss: 0.011796 [83216/568021]                time taken: 3838.556519 \n",
            "loss: 0.084516 [84816/568021]                time taken: 3912.385687 \n",
            "loss: 0.085602 [86416/568021]                time taken: 3986.128017 \n",
            "loss: 0.041296 [88016/568021]                time taken: 4059.825811 \n",
            "loss: 0.162897 [89616/568021]                time taken: 4133.466540 \n",
            "loss: 0.029260 [91216/568021]                time taken: 4207.237699 \n",
            "loss: 0.011921 [92816/568021]                time taken: 4281.025905 \n",
            "loss: 0.004315 [94416/568021]                time taken: 4354.961717 \n",
            "loss: 0.137504 [96016/568021]                time taken: 4428.819782 \n",
            "loss: 0.002323 [97616/568021]                time taken: 4502.626673 \n",
            "loss: 0.214087 [99216/568021]                time taken: 4576.337839 \n",
            "loss: 0.117426 [100816/568021]                time taken: 4650.033344 \n",
            "loss: 0.068832 [102416/568021]                time taken: 4723.830888 \n",
            "loss: 0.068639 [104016/568021]                time taken: 4797.515099 \n",
            "loss: 0.008702 [105616/568021]                time taken: 4871.241976 \n",
            "loss: 0.053622 [107216/568021]                time taken: 4944.986862 \n",
            "loss: 0.012038 [108816/568021]                time taken: 5018.694225 \n",
            "loss: 0.113625 [110416/568021]                time taken: 5092.272157 \n",
            "loss: 0.095829 [112016/568021]                time taken: 5166.083571 \n",
            "loss: 0.069495 [113616/568021]                time taken: 5239.901140 \n",
            "loss: 0.007250 [115216/568021]                time taken: 5313.534712 \n",
            "loss: 0.071689 [116816/568021]                time taken: 5387.379924 \n",
            "loss: 0.017732 [118416/568021]                time taken: 5461.228307 \n",
            "loss: 0.194300 [120016/568021]                time taken: 5534.984399 \n",
            "loss: 0.014059 [121616/568021]                time taken: 5608.829947 \n",
            "loss: 0.104182 [123216/568021]                time taken: 5682.665669 \n",
            "loss: 0.048758 [124816/568021]                time taken: 5756.421477 \n",
            "loss: 0.054311 [126416/568021]                time taken: 5829.994508 \n",
            "loss: 0.064611 [128016/568021]                time taken: 5903.616965 \n",
            "loss: 0.080235 [129616/568021]                time taken: 5977.364826 \n",
            "loss: 0.048634 [131216/568021]                time taken: 6051.169010 \n",
            "loss: 0.146434 [132816/568021]                time taken: 6124.906550 \n",
            "loss: 0.008715 [134416/568021]                time taken: 6198.607044 \n",
            "loss: 0.135555 [136016/568021]                time taken: 6272.312204 \n",
            "loss: 0.014879 [137616/568021]                time taken: 6346.088240 \n",
            "loss: 0.011874 [139216/568021]                time taken: 6419.840327 \n",
            "loss: 0.027633 [140816/568021]                time taken: 6493.614506 \n",
            "loss: 0.005959 [142416/568021]                time taken: 6567.423046 \n",
            "loss: 0.024768 [144016/568021]                time taken: 6641.268663 \n",
            "loss: 0.027912 [145616/568021]                time taken: 6715.102574 \n",
            "loss: 0.000203 [147216/568021]                time taken: 6788.865859 \n",
            "loss: 0.228543 [148816/568021]                time taken: 6862.654451 \n",
            "loss: 0.005378 [150416/568021]                time taken: 6936.360106 \n",
            "loss: 0.225733 [152016/568021]                time taken: 7010.082504 \n",
            "loss: 0.034529 [153616/568021]                time taken: 7083.829813 \n",
            "loss: 0.022098 [155216/568021]                time taken: 7157.627884 \n",
            "loss: 0.026156 [156816/568021]                time taken: 7231.316054 \n",
            "loss: 0.089941 [158416/568021]                time taken: 7305.037318 \n",
            "loss: 0.078020 [160016/568021]                time taken: 7378.731373 \n",
            "loss: 0.278475 [161616/568021]                time taken: 7452.428103 \n",
            "loss: 0.022929 [163216/568021]                time taken: 7526.098401 \n",
            "loss: 0.045880 [164816/568021]                time taken: 7599.703365 \n",
            "loss: 0.014567 [166416/568021]                time taken: 7673.426962 \n",
            "loss: 0.014288 [168016/568021]                time taken: 7747.150064 \n",
            "loss: 0.105940 [169616/568021]                time taken: 7820.962887 \n",
            "loss: 0.033961 [171216/568021]                time taken: 7894.883739 \n",
            "loss: 0.028887 [172816/568021]                time taken: 7968.796416 \n",
            "loss: 0.043999 [174416/568021]                time taken: 8042.652945 \n",
            "loss: 0.072844 [176016/568021]                time taken: 8116.380552 \n",
            "loss: 0.028757 [177616/568021]                time taken: 8190.109482 \n",
            "loss: 0.028246 [179216/568021]                time taken: 8263.706931 \n",
            "loss: 0.225796 [180816/568021]                time taken: 8337.364646 \n",
            "loss: 0.020795 [182416/568021]                time taken: 8411.215561 \n",
            "loss: 0.056303 [184016/568021]                time taken: 8484.927599 \n",
            "loss: 0.032883 [185616/568021]                time taken: 8558.806953 \n",
            "loss: 0.196261 [187216/568021]                time taken: 8632.479287 \n",
            "loss: 0.035924 [188816/568021]                time taken: 8706.037305 \n",
            "loss: 0.006775 [190416/568021]                time taken: 8779.706787 \n",
            "loss: 0.118840 [192016/568021]                time taken: 8853.521868 \n",
            "loss: 0.044783 [193616/568021]                time taken: 8927.225703 \n",
            "loss: 0.018379 [195216/568021]                time taken: 9000.933808 \n",
            "loss: 0.010810 [196816/568021]                time taken: 9074.673653 \n",
            "loss: 0.100685 [198416/568021]                time taken: 9148.348048 \n",
            "loss: 0.004728 [200016/568021]                time taken: 9221.981591 \n",
            "loss: 0.099786 [201616/568021]                time taken: 9295.650564 \n",
            "loss: 0.012076 [203216/568021]                time taken: 9369.376968 \n",
            "loss: 0.043738 [204816/568021]                time taken: 9443.195368 \n",
            "loss: 0.223341 [206416/568021]                time taken: 9516.940966 \n",
            "loss: 0.004058 [208016/568021]                time taken: 9590.666261 \n",
            "loss: 0.135787 [209616/568021]                time taken: 9664.427065 \n",
            "loss: 0.030575 [211216/568021]                time taken: 9738.157146 \n",
            "loss: 0.002231 [212816/568021]                time taken: 9812.074170 \n",
            "loss: 0.010187 [214416/568021]                time taken: 9885.884522 \n",
            "loss: 0.079154 [216016/568021]                time taken: 9959.617606 \n",
            "loss: 0.000270 [217616/568021]                time taken: 10033.458585 \n",
            "loss: 0.125688 [219216/568021]                time taken: 10107.410055 \n",
            "loss: 0.156736 [220816/568021]                time taken: 10181.035046 \n",
            "loss: 0.014106 [222416/568021]                time taken: 10254.753770 \n",
            "loss: 0.039934 [224016/568021]                time taken: 10328.408083 \n",
            "loss: 0.050649 [225616/568021]                time taken: 10402.227746 \n",
            "loss: 0.300852 [227216/568021]                time taken: 10476.106599 \n",
            "loss: 0.078161 [228816/568021]                time taken: 10550.050318 \n",
            "loss: 0.185331 [230416/568021]                time taken: 10623.904203 \n",
            "loss: 0.459945 [232016/568021]                time taken: 10697.796706 \n",
            "loss: 0.002655 [233616/568021]                time taken: 10771.552526 \n",
            "loss: 0.025124 [235216/568021]                time taken: 10845.324034 \n",
            "loss: 0.005807 [236816/568021]                time taken: 10919.238286 \n",
            "loss: 0.017453 [238416/568021]                time taken: 10993.199636 \n",
            "loss: 0.001257 [240016/568021]                time taken: 11067.054170 \n",
            "loss: 0.020895 [241616/568021]                time taken: 11140.894644 \n",
            "loss: 0.089597 [243216/568021]                time taken: 11214.815469 \n",
            "loss: 0.040872 [244816/568021]                time taken: 11288.792336 \n",
            "loss: 0.099634 [246416/568021]                time taken: 11362.671888 \n",
            "loss: 0.051657 [248016/568021]                time taken: 11436.478791 \n",
            "loss: 0.047299 [249616/568021]                time taken: 11510.484378 \n",
            "loss: 0.176356 [251216/568021]                time taken: 11584.361370 \n",
            "loss: 0.023086 [252816/568021]                time taken: 11658.179043 \n",
            "loss: 0.086347 [254416/568021]                time taken: 11731.845734 \n",
            "loss: 0.058808 [256016/568021]                time taken: 11805.693372 \n",
            "loss: 0.021022 [257616/568021]                time taken: 11879.483919 \n",
            "loss: 0.123175 [259216/568021]                time taken: 11953.247361 \n",
            "loss: 0.006353 [260816/568021]                time taken: 12026.942074 \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-d887d1439740>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {i+1} -----------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-1962447de8d1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer, train_losses, train_acc)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0maccuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-f153f315829a>\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(pred, label)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "test_acc = []\n",
        "train_acc = []\n",
        "\n",
        "for i in range(3):\n",
        "    print(f'Epoch {i+1} -----------------------------------')\n",
        "    train(train_loader, model, loss_func, optimizer, train_losses, train_acc)\n",
        "    test(test_loader, model, loss_func, test_losses, test_acc)\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XYVH43QWwpjG",
      "metadata": {
        "id": "XYVH43QWwpjG"
      },
      "outputs": [],
      "source": [
        "for data in train_loader:\n",
        "    print(data['input_ids'].shape)\n",
        "    break\n",
        "\n",
        "for batch, (data) in enumerate(train_loader):\n",
        "    print(data['input_ids'].shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5rNHq8FxwrWR",
      "metadata": {
        "id": "5rNHq8FxwrWR"
      },
      "outputs": [],
      "source": [
        "eval_loader = DataLoader(test_df_main['cleaned_text'], batch_size=3, shuffle=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in eval_loader:\n",
        "        inputs = data['input_ids'].to(device)\n",
        "        attention = data['attention_mask'].to(device)\n",
        "        pred = model(inputs, attention_mask = attention)\n",
        "        pred = nn.Sigmoid()(pred.logits)\n",
        "\n",
        "test_df_main[\"generated\"] = pred.cpu().detach().numpy().squeeze()\n",
        "\n",
        "submission = test_df_main[[\"id\", \"generated\"]]\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5UVlC7xIxpv8",
      "metadata": {
        "id": "5UVlC7xIxpv8"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "preds = []\n",
        "true_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        x = data['input_ids'].to(device)\n",
        "        y = data['labels'].to(device)\n",
        "        attention = data['attention_masks'].to(device)\n",
        "        pred = model(x, attention_mask = attention)\n",
        "        pred = nn.Sigmoid()(pred.logits)\n",
        "        true_preds.append(y.cpu().detach())\n",
        "        pred = (pred > 0.5).long()\n",
        "        preds.append(pred.cpu().detach())\n",
        "\n",
        "flattened_preds = [arr.flatten() for arr in preds]\n",
        "preds = np.concatenate(flattened_preds)\n",
        "\n",
        "flattened_true = [arr.flatten() for arr in true_preds]\n",
        "true_preds= np.concatenate(flattened_true)\n",
        "\n",
        "\n",
        "print(preds)\n",
        "print(true_preds )\n",
        "\n",
        "\n",
        "cm = confusion_matrix(true_preds, preds)\n",
        "sns.heatmap(cm,\n",
        "            annot=True,\n",
        "            fmt='g',\n",
        "            xticklabels=['Student', 'AI'],\n",
        "            yticklabels=['Student', 'AI'])\n",
        "plt.xlabel('Prediction',fontsize=13)\n",
        "plt.ylabel('Actual',fontsize=13)\n",
        "plt.title('Confusion Matrix',fontsize=17)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EpIlo87Bx0MM",
      "metadata": {
        "id": "EpIlo87Bx0MM"
      },
      "outputs": [],
      "source": [
        "print(classification_report(true_preds, preds, target_names=['human', 'ai']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FK__hXpFx3l3",
      "metadata": {
        "id": "FK__hXpFx3l3"
      },
      "outputs": [],
      "source": [
        "generatedText = ['''### The Impact of Fintech on Financial Inclusion\n",
        "\n",
        "The advent of financial technology, or fintech, has revolutionized the financial services industry, breaking down traditional barriers and extending financial inclusion to millions of underserved and unbanked individuals worldwide. Financial inclusion is the process of ensuring that individuals and businesses have access to useful and affordable financial products and services that meet their needs – transactions, payments, savings, credit, and insurance – delivered in a responsible and sustainable way. Fintech has played a critical role in this mission by leveraging technology to provide innovative financial solutions.\n",
        "\n",
        "#### Enhancing Access to Financial Services\n",
        "\n",
        "One of the primary ways fintech has impacted financial inclusion is by enhancing access to financial services. Traditional banking infrastructure often fails to reach remote or rural areas due to high costs and logistical challenges. Fintech companies, however, can operate with lower overheads and leverage mobile technology to reach these underserved areas. Mobile banking, in particular, has been a game-changer. In regions like Sub-Saharan Africa, mobile money services such as M-Pesa have enabled millions of people to perform financial transactions through their mobile phones, bypassing the need for a physical bank branch.\n",
        "\n",
        "#### Reducing Costs and Improving Efficiency\n",
        "\n",
        "Fintech has also significantly reduced the costs associated with financial services. Digital-only banks and payment platforms operate without the need for physical branches, reducing operational expenses and allowing them to offer lower fees to customers. These cost savings are particularly beneficial for low-income individuals who previously found traditional banking fees prohibitive. Moreover, fintech solutions often provide faster and more efficient services. For instance, peer-to-peer (P2P) lending platforms and online loan applications streamline the borrowing process, reducing the time it takes to receive credit compared to traditional banks.\n",
        "\n",
        "#### Expanding Credit Access\n",
        "\n",
        "Credit access is a crucial component of financial inclusion, enabling individuals and small businesses to invest in opportunities that can improve their livelihoods. Fintech companies have developed innovative credit assessment methods using alternative data sources such as mobile phone usage, social media activity, and transaction history. These methods allow for more accurate risk assessments of individuals who lack traditional credit histories. Consequently, fintech has opened up credit access to a broader audience, including those who were previously deemed unbankable by conventional standards.\n",
        "\n",
        "#### Fostering Financial Literacy and Empowerment\n",
        "\n",
        "Financial literacy is essential for effective financial inclusion, and fintech companies have contributed significantly in this area. Through mobile apps and online platforms, fintech provides educational content and tools that help individuals manage their finances better. These resources empower users with knowledge about budgeting, saving, and investing, enabling them to make informed financial decisions. Additionally, the intuitive and user-friendly interfaces of fintech applications make financial management accessible even to those with limited financial literacy.\n",
        "\n",
        "#### Promoting Savings and Investment\n",
        "\n",
        "Fintech solutions have also promoted savings and investment among underserved populations. Digital savings platforms and automated saving tools encourage individuals to save regularly, even in small amounts. These platforms often provide higher interest rates compared to traditional banks, incentivizing savings. Similarly, robo-advisors and micro-investment apps have democratized access to investment opportunities, allowing individuals to invest in diversified portfolios with minimal initial capital. This democratization is crucial for financial inclusion as it provides opportunities for wealth accumulation and financial security.\n",
        "\n",
        "#### Challenges and Considerations\n",
        "\n",
        "Despite the significant strides made by fintech in promoting financial inclusion, several challenges remain. Digital literacy and internet access are prerequisites for benefiting from fintech services, yet many underserved populations lack these resources. Ensuring the security and privacy of user data is another critical concern, as fintech platforms often handle sensitive financial information. Additionally, regulatory frameworks need to evolve to keep pace with the rapid innovation in fintech, ensuring consumer protection without stifling innovation.\n",
        "\n",
        "#### Conclusion\n",
        "\n",
        "Fintech has undeniably transformed the landscape of financial inclusion, making financial services more accessible, affordable, and efficient. By leveraging technology, fintech companies have bridged the gap between traditional financial institutions and underserved populations, providing innovative solutions that cater to the needs of the unbanked and underbanked. While challenges remain, the continued evolution and expansion of fintech hold promise for achieving greater financial inclusion globally, empowering individuals and businesses to participate fully in the economic system and improve their financial well-being.''',\n",
        "\n",
        "\n",
        "'''A sharing or shared economy is an economic model that is followed by a firm or company, it relies on the principles of lending resources to one another for free or for a fee. Quality of life refers to the standard of living or the economic development of a particular area that can be measured through indicators such as GDP, Revenue, Expenditures etc. As the economy has finally moved out of the pandemic phase, it is necessary that economic systems that promote sustainable growth and improve the quality of life should be adopted to achieve success towards the United Nations Sustainable Development Goal 8 of Decent Work and Economic Growth while also addressing the day to day needs of communities. As part of the current generation, the most relevant and rising community are entrepreneurs, start-up geniuses who find innovative ways to address the needs and problems of the common man that are fit for consumption and commercialization.\n",
        "\n",
        "A sharing economy is further divided into 5 sectors which are ride sharing, peer to peer lending, crowdfunding and apartment renting. Ride sharing is when a person with access to a vehicle would give a lift to another person for a specific amount of fee. Here both the driver and the person taking the lift are consumers. Another example of this is P2P or peer to peer lending, where a person with an unused resource such as a television or a fridge wants to sell it to another person to earn money. A sharing economy is based on the principles of sharing and collaboration all through the Internet of Things (IoT). It is important to note that the shared economy, unlike other economic models, is followed by a firm and not an entire country, this way it could co-exist with other economic models to provide more advantageous competition and improve the quality of life.\n",
        "\n",
        "This type of malleability is one major advantage of the shared economic model. Since all firms that operate on this model have to be on the internet and work through an online platform or website, it makes it highly accessible to all citizens in a country regardless of their geographical location and social class. Being on the internet also opens multiple doors towards digitization and interconnection. Multiple companies have been using neural networks and other forms of artificial intelligence to improve the quality of life of users. This consists of search algorithms, recommendations, streamlining logistics as well as ease of access. All of such promoting the UN SDG goal 9 of Industry, Innovation and Infrastructure. Another great benefit that is posed to firm founders and stakeholders is the incorporation of ESG (Environmental, Social, Governance) which is a metric of analysis for companies that need investment. Not only is this metric becoming a mandate in the European region, multinational companies have been using this metric to make them more suitable for angel investors and customer acquisition. Another major benefit of a shared economy is the reduced environmental impact which is part of ESG itself, since there is absolutely no need for physical infrastructure to manage a firm based on this economic model, it reduces the carbon footprint of the company on a large scale, and if there is some sort of technical infrastructure required to run the databases and servers, any small brownfield site could be used to fulfill the purpose. With so many benefits, such as starting a company from scratch, requiring almost minimal to none startup capital and serving consumers from anywhere in the world at any time makes it a very suitable option towards entrepreneurs.\n",
        "\n",
        "A few disadvantages of this model would be the lack of government intervention and regulation. Since, companies that run on this economic model usually fall under the private sector and have little to no government jurisdiction over them, these companies are prone to fraudulent and criminal acts. For example, stock and share management becomes a huge issue, since there is no governing body, any company could gain liquidity in exchange for stock and then pull the plug on the company, making it almost legal to commit fraud through a shared economy. Also, entire companies are based on the internet so if a hacker hacks a single transaction chain, they can gain access to entire servers and wipe off companies overnight. However, this problem is also prone in blockchains and cryptocurrency. Other than that, since entrepreneurs would only be the middle men in their demand and supply chain they miss out on multiple opportunities on allowances, company package benefits as well as certain tax benefits that are country specific. This makes “earning money” a much less viable option to any startup company since the first priority would always be gaining capital and re-investing.\n",
        "\n",
        "Despite the risk of fraud and hacking, the advantages of a shared economy to entrepreneurs completely outweigh its disadvantages. Firstly, little to no government intervention may mean that there is more risk to fraud and no recovery, it also opens doors to commissions and negotiations, which can be hugely beneficial when considering that the entrepreneur would only be a middle man. Incentivizing and other quaternary economic activities are already prominent in a shared economy model, for example in uber and ebay, the more rides or products you can sell to the end consumer, the more money you can earn, but where’s the benefit for the company then? Well, the more prominent a company becomes in the market the more they can commoditize their products and gain free marketing, apart from that when becoming relevant towards a consumer, increasing prices for convenience seems like the best idea. For example, if you need to move houses, and you need to pack your stuff up, it can take hours and even days but eventually it would be free. However, if someone offered to do all of this hectic work for you just for a mere $10, you would instantly say yes, which is basically what convenience cost is and is exactly how shared economies become very successful. The biggest players in this industry are Uber placed at $56 billion net worth, Airbnb at $38 billion and eBay placed at $25 billion. There is not a single doubt that shared economies could not only increase the quality of life of consumers and entrepreneurs, it also provides multiple opportunities to become successful and leave a stamp on the market.\n",
        "''']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j72_nAWsyB3r",
      "metadata": {
        "id": "j72_nAWsyB3r"
      },
      "outputs": [],
      "source": [
        "generatedText = [processText(text) for text in generatedText]\n",
        "batch_size = 1\n",
        "eval_loader = DataLoader(generatedText, batch_size=batch_size, shuffle=False)\n",
        "preds = []\n",
        "with torch.no_grad():\n",
        "    for data in eval_loader:\n",
        "        x = data['input_ids'].to(device)\n",
        "        attention = data['attention_mask'].to(device)\n",
        "        pred = model(x, attention_mask = attention)\n",
        "        pred = nn.Sigmoid()(pred.logits)\n",
        "        print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cpflU-KnyGw8",
      "metadata": {
        "id": "cpflU-KnyGw8"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model = model.to('cpu')\n",
        "torch.save(model, 'model_finetuned.pth')\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "}, 'model_with_optimizer.pth')\n",
        "torch.save(model.state_dict(), 'model_state_dict.pth')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5nbIn_VzyIXA",
      "metadata": {
        "id": "5nbIn_VzyIXA"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model1 = RobertaForSequenceClassification.from_pretrained('distilroberta-base', num_labels=1)\n",
        "model1.load_state_dict(torch.load('model_state_dict.pth'))\n",
        "model1.to(device)\n",
        "model1.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in eval_loader:\n",
        "        x = data['input_ids'].to(device)\n",
        "        attention = data['attention_mask'].to(device)\n",
        "        pred = model1(x, attention_mask = attention)\n",
        "        pred = nn.Sigmoid()(pred.logits)\n",
        "        print(pred)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o3OhV3Z_COGg",
      "metadata": {
        "id": "o3OhV3Z_COGg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Clear the GPU cache\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Gpt7rvNV3_zD",
      "metadata": {
        "id": "Gpt7rvNV3_zD"
      },
      "source": [
        "# DISTILBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EVmFcCMY3_dR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVmFcCMY3_dR",
        "outputId": "c41e3ef2-5ea9-4ed5-ac8c-3cf9e55bbd4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cqQJyM4p4IFk",
      "metadata": {
        "id": "cqQJyM4p4IFk"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Define your dataset class\n",
        "# Define your dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_length):\n",
        "        self.texts = df['cleaned_text'].tolist()\n",
        "        self.labels = df['label'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "skMO1QcfojIT",
      "metadata": {
        "id": "skMO1QcfojIT"
      },
      "outputs": [],
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LF_19xKE99A-",
      "metadata": {
        "id": "LF_19xKE99A-"
      },
      "outputs": [],
      "source": [
        "train_dataset = TextDataset(train_df, tokenizer, 512)\n",
        "test_dataset = TextDataset(test_df, tokenizer, 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H1QBsCf-ogeY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1QBsCf-ogeY",
        "outputId": "417916d4-e59f-4bfa-fe63-edfe800365c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IsU6E_PxomD9",
      "metadata": {
        "id": "IsU6E_PxomD9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FWdCFwwCYPJk",
      "metadata": {
        "id": "FWdCFwwCYPJk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, Dataset, DistributedSampler\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def train_loop():\n",
        "    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    num_epochs = 3\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):  # Wrap train_loader with tqdm and add description\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Move tensors to the TPU device\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            xm.optimizer_step(optimizer)\n",
        "\n",
        "        print(f\"Finished training epoch {epoch}\")\n",
        "\n",
        "        # Evaluate after each epoch\n",
        "        evaluate_model(model, test_dataset, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FJMpgQ4bZPWH",
      "metadata": {
        "id": "FJMpgQ4bZPWH"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_dataset, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8)  # Adjust batch size as needed\n",
        "\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculations for evaluation\n",
        "        for batch in test_loader:\n",
        "            # Move tensors to the TPU device\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            predicted_labels = torch.argmax(outputs.logits, dim=1)  # Get predicted labels\n",
        "\n",
        "            total_correct += (predicted_labels == labels).sum().item()  # Count correct predictions\n",
        "            total_samples += labels.size(0)  # Count total samples\n",
        "\n",
        "    accuracy = total_correct / total_samples\n",
        "    print(f\"Evaluation Accuracy: {accuracy}\")  # Print the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MLu6nYXWkMon",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLu6nYXWkMon",
        "outputId": "645ddeaa-b662-43c1-d3cd-9abb635b958a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/dev/accel0  /dev/accel1  /dev/accel2  /dev/accel3\n"
          ]
        }
      ],
      "source": [
        "!ls /dev/accel*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3o31VhB8pAQU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o31VhB8pAQU",
        "outputId": "89dbfe09-a735-430b-f921-06d81ba45a19"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   0%|          | 36/141283 [1:57:31<12504:37:45, 318.71s/it]"
          ]
        }
      ],
      "source": [
        "train_loop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rxv3nkdlZM3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxv3nkdlZM3e",
        "outputId": "a930c93a-0ac5-4235-aec0-2eb6451041b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Unsupported nprocs (4), ignoring...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in worker 0: torch_xla/csrc/tensor.cpp:190 : Check failed: data()->tensor_data \n",
            "*** Begin stack trace ***\n",
            "\ttsl::CurrentStackTrace()\n",
            "\ttorch_xla::XLATensor::shape() const\n",
            "\ttorch_xla::XLATensorImpl::SetupSizeProperties()\n",
            "\ttorch_xla::XLATensorImpl::sym_sizes_custom() const\n",
            "\ttorch_xla::XLANativeFunctions::_to_copy(at::Tensor const&, std::optional<c10::ScalarType>, std::optional<c10::Layout>, std::optional<c10::Device>, std::optional<bool>, bool, std::optional<c10::MemoryFormat>)\n",
            "\t\n",
            "\tat::_ops::_to_copy::redispatch(c10::DispatchKeySet, at::Tensor const&, std::optional<c10::ScalarType>, std::optional<c10::Layout>, std::optional<c10::Device>, std::optional<bool>, bool, std::optional<c10::MemoryFormat>)\n",
            "\t\n",
            "\tat::_ops::_to_copy::call(at::Tensor const&, std::optional<c10::ScalarType>, std::optional<c10::Layout>, std::optional<c10::Device>, std::optional<bool>, bool, std::optional<c10::MemoryFormat>)\n",
            "\t\n",
            "\tat::_ops::_to_copy::redispatch(c10::DispatchKeySet, at::Tensor const&, std::optional<c10::ScalarType>, std::optional<c10::Layout>, std::optional<c10::Device>, std::optional<bool>, bool, std::optional<c10::MemoryFormat>)\n",
            "\t\n",
            "\t\n",
            "\tat::_ops::_to_copy::call(at::Tensor const&, std::optional<c10::ScalarType>, std::optional<c10::Layout>, std::optional<c10::Device>, std::optional<bool>, bool, std::optional<c10::MemoryFormat>)\n",
            "\tat::native::to(at::Tensor const&, std::optional<c10::ScalarType>, std::optional<c10::Layout>, std::optional<c10::Device>, std::optional<bool>, bool, bool, std::optional<c10::MemoryFormat>)\n",
            "\t\n",
            "\tat::_ops::to_dtype_layout::call(at::Tensor const&, std::optional<c10::ScalarType>, std::optional<c10::Layout>, std::optional<c10::Device>, std::optional<bool>, bool, bool, std::optional<c10::MemoryFormat>)\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t_PyEval_EvalFrameDefault\n",
            "\t_PyFunction_Vectorcall\n",
            "\t_PyEval_EvalFrameDefault\n",
            "\t\n",
            "\t_PyEval_EvalFrameDefault\n",
            "\t\n",
            "\t_PyEval_EvalFrameDefault\n",
            "\t\n",
            "\t_PyEval_EvalFrameDefault\n",
            "\t\n",
            "\t_PyEval_EvalFrameDefault\n",
            "\t\n",
            "\t_PyEval_EvalFrameDefault\n",
            "\t\n",
            "\t_PyEval_EvalFrameDefault\n",
            "\t\n",
            "\t_PyEval_EvalFrameDefault\n",
            "\t\n",
            "\t_PyEval_EvalFrameDefault\n",
            "\t_PyFunction_Vectorcall\n",
            "\t_PyEval_EvalFrameDefault\n",
            "\t_PyFunction_Vectorcall\n",
            "\t_PyEval_EvalFrameDefault\n",
            "\t_PyObject_FastCallDictTstate\n",
            "\t_PyObject_Call_Prepend\n",
            "\t\n",
            "\tPyObject_Call\n",
            "\t\n",
            "\t_PyObject_MakeTpCall\n",
            "\t_PyEval_EvalFrameDefault\n",
            "\t_PyFunction_Vectorcall\n",
            "\t_PyEval_EvalFrameDefault\n",
            "\t_PyFunction_Vectorcall\n",
            "\t_PyEval_EvalFrameDefault\n",
            "\t_PyFunction_Vectorcall\n",
            "\t_PyEval_EvalFrameDefault\n",
            "\t_PyFunction_Vectorcall\n",
            "\t_PyEval_EvalFrameDefault\n",
            "\t_PyFunction_Vectorcall\n",
            "\t_PyEval_EvalFrameDefault\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "\t\n",
            "*** End stack trace ***\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def _mp_fn(index, flags):\n",
        "    # Use the recommended functions\n",
        "    torch.set_default_dtype(torch.float32)  # Set default data type to float32\n",
        "    # If you need to set a default device, use torch.set_default_device() here\n",
        "    train_loop(index, flags)\n",
        "\n",
        "FLAGS = {}\n",
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=4, start_method='fork')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kQnW7QP5l_zo",
      "metadata": {
        "id": "kQnW7QP5l_zo"
      },
      "outputs": [],
      "source": [
        "device = xm.xla_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AIH_8aPzmJ7_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIH_8aPzmJ7_",
        "outputId": "2a0e8fd5-831e-4fd7-9ffb-32a75d3a505a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vyMfME9fl0ud",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyMfME9fl0ud",
        "outputId": "dadc4558-f050-4946-9f30-847ee4a44544"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter: distilbert.embeddings.word_embeddings.weight, Device: xla:0\n",
            "Parameter: distilbert.embeddings.position_embeddings.weight, Device: xla:0\n",
            "Parameter: distilbert.embeddings.LayerNorm.weight, Device: xla:0\n",
            "Parameter: distilbert.embeddings.LayerNorm.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.0.attention.q_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.0.attention.q_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.0.attention.k_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.0.attention.k_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.0.attention.v_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.0.attention.v_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.0.attention.out_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.0.attention.out_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.0.sa_layer_norm.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.0.sa_layer_norm.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.0.ffn.lin1.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.0.ffn.lin1.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.0.ffn.lin2.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.0.ffn.lin2.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.0.output_layer_norm.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.0.output_layer_norm.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.1.attention.q_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.1.attention.q_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.1.attention.k_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.1.attention.k_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.1.attention.v_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.1.attention.v_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.1.attention.out_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.1.attention.out_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.1.sa_layer_norm.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.1.sa_layer_norm.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.1.ffn.lin1.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.1.ffn.lin1.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.1.ffn.lin2.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.1.ffn.lin2.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.1.output_layer_norm.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.1.output_layer_norm.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.2.attention.q_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.2.attention.q_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.2.attention.k_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.2.attention.k_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.2.attention.v_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.2.attention.v_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.2.attention.out_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.2.attention.out_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.2.sa_layer_norm.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.2.sa_layer_norm.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.2.ffn.lin1.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.2.ffn.lin1.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.2.ffn.lin2.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.2.ffn.lin2.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.2.output_layer_norm.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.2.output_layer_norm.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.3.attention.q_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.3.attention.q_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.3.attention.k_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.3.attention.k_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.3.attention.v_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.3.attention.v_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.3.attention.out_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.3.attention.out_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.3.sa_layer_norm.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.3.sa_layer_norm.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.3.ffn.lin1.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.3.ffn.lin1.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.3.ffn.lin2.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.3.ffn.lin2.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.3.output_layer_norm.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.3.output_layer_norm.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.4.attention.q_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.4.attention.q_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.4.attention.k_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.4.attention.k_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.4.attention.v_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.4.attention.v_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.4.attention.out_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.4.attention.out_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.4.sa_layer_norm.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.4.sa_layer_norm.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.4.ffn.lin1.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.4.ffn.lin1.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.4.ffn.lin2.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.4.ffn.lin2.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.4.output_layer_norm.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.4.output_layer_norm.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.5.attention.q_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.5.attention.q_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.5.attention.k_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.5.attention.k_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.5.attention.v_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.5.attention.v_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.5.attention.out_lin.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.5.attention.out_lin.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.5.sa_layer_norm.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.5.sa_layer_norm.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.5.ffn.lin1.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.5.ffn.lin1.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.5.ffn.lin2.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.5.ffn.lin2.bias, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.5.output_layer_norm.weight, Device: xla:0\n",
            "Parameter: distilbert.transformer.layer.5.output_layer_norm.bias, Device: xla:0\n",
            "Parameter: pre_classifier.weight, Device: xla:0\n",
            "Parameter: pre_classifier.bias, Device: xla:0\n",
            "Parameter: classifier.weight, Device: xla:0\n",
            "Parameter: classifier.bias, Device: xla:0\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "       print(f\"Parameter: {name}, Device: {param.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FoQd_8Un-vKy",
      "metadata": {
        "id": "FoQd_8Un-vKy"
      },
      "outputs": [],
      "source": [
        "# Start training on TPUs\n",
        "def _mp_fn(index, flags):\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "    train_loop(index, flags)\n",
        "\n",
        "FLAGS = {}\n",
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=1, start_method='fork')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9H_Xpb_u4SuQ",
      "metadata": {
        "id": "9H_Xpb_u4SuQ"
      },
      "outputs": [],
      "source": [
        "# Start training on TPUs\n",
        "def _mp_fn(index, flags):\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "    train_loop(index, flags)\n",
        "\n",
        "FLAGS = {}\n",
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vvA8d8KsT2-f",
      "metadata": {
        "id": "vvA8d8KsT2-f"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nmmwm9ROULws",
      "metadata": {
        "id": "nmmwm9ROULws"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WA4ZAcuBPliP",
      "metadata": {
        "id": "WA4ZAcuBPliP"
      },
      "outputs": [],
      "source": [
        "# Split dataset into train and test\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df['cleaned_text'].tolist(), df['label'].tolist(), test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MBIMD1xmaIqN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "MBIMD1xmaIqN",
        "outputId": "dbf6abd7-3299-401e-884a-0dad3d527d32"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-00ea611c9001>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_texts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Token Length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of Texts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-00ea611c9001>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_texts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Token Length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of Texts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 method).\n\u001b[1;32m   2714\u001b[0m         \"\"\"\n\u001b[0;32m-> 2715\u001b[0;31m         encoded_inputs = self.encode_plus(\n\u001b[0m\u001b[1;32m   2716\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3125\u001b[0m         )\n\u001b[1;32m   3126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3127\u001b[0;31m         return self._encode_plus(\n\u001b[0m\u001b[1;32m   3128\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3129\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    786\u001b[0m             )\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m                 \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m                 \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0;31m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(self, text, split_special_tokens)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_basic_tokenize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             for token in self.basic_tokenizer.tokenize(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msplit_special_tokens\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             ):\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip_accents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_strip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0msplit_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_split_on_punc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0moutput_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhitespace_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m_run_split_on_punc\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mchar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0m_is_punctuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0mstart_new_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_is_punctuation\u001b[0;34m(char)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_is_punctuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0;34m\"\"\"Checks whether `char` is a punctuation character.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "lengths = [len(tokenizer.encode(text)) for text in train_texts]\n",
        "plt.hist(lengths, bins=50)\n",
        "plt.xlabel('Token Length')\n",
        "plt.ylabel('Number of Texts')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T_9TYs-EasX5",
      "metadata": {
        "id": "T_9TYs-EasX5"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jbtYFkyba1Ct",
      "metadata": {
        "id": "jbtYFkyba1Ct"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "\n",
        "def tokenize_batch(texts):\n",
        "    return tokenizer(texts, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Number of CPU cores to use\n",
        "num_cores = multiprocessing.cpu_count()\n",
        "\n",
        "# Tokenize in parallel\n",
        "with multiprocessing.Pool(num_cores) as pool:\n",
        "    train_encodings = pool.map(tokenize_batch, [train_texts[i::num_cores] for i in range(num_cores)])\n",
        "    val_encodings = pool.map(tokenize_batch, [val_texts[i::num_cores] for i in range(num_cores)])\n",
        "\n",
        "# Flatten the list of tokenized batches\n",
        "train_encodings = {key: torch.cat([enc[key] for enc in train_encodings]) for key in train_encodings[0]}\n",
        "val_encodings = {key: torch.cat([enc[key] for enc in val_encodings]) for key in val_encodings[0]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FD0XhzhSa49v",
      "metadata": {
        "id": "FD0XhzhSa49v"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer.batch_encode_plus(\n",
        "    train_texts,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=512,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "val_encodings = tokenizer.batch_encode_plus(\n",
        "    val_texts,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=512,\n",
        "    return_tensors='pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T7LDKjd9suvs",
      "metadata": {
        "id": "T7LDKjd9suvs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_xla.core.xla_model as xm\n",
        "from transformers import BertTokenizerFast, BertModel, AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qges-zmgUdgQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qges-zmgUdgQ",
        "outputId": "ae589d20-3361-4ea8-d9be-86b48d8832ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-24-b6904a09e775>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(train_encodings['input_ids']),\n",
            "<ipython-input-24-b6904a09e775>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(train_encodings['attention_mask']),\n",
            "<ipython-input-24-b6904a09e775>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(val_encodings['input_ids']),\n",
            "<ipython-input-24-b6904a09e775>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(val_encodings['attention_mask']),\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "train_dataset = TensorDataset(\n",
        "    torch.tensor(train_encodings['input_ids']),\n",
        "    torch.tensor(train_encodings['attention_mask']),\n",
        "    torch.tensor(train_labels)\n",
        ")\n",
        "\n",
        "val_dataset = TensorDataset(\n",
        "    torch.tensor(val_encodings['input_ids']),\n",
        "    torch.tensor(val_encodings['attention_mask']),\n",
        "    torch.tensor(val_labels)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "s2FkaEz7UrPy",
      "metadata": {
        "id": "s2FkaEz7UrPy"
      },
      "outputs": [],
      "source": [
        "import torch_xla.core.xla_model as xm\n",
        "\n",
        "# Set TPU device\n",
        "device = xm.xla_device()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yR310P3OU31W",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR310P3OU31W",
        "outputId": "0f9cf60b-49c8-4476-8270-f648cc1eed94"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Initialize model and move to TPU\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-aRZv2uNvwyd",
      "metadata": {
        "id": "-aRZv2uNvwyd"
      },
      "outputs": [],
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "    def __init__(self, bert):\n",
        "        super(BERT_Arch, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(768, 512)\n",
        "        self.fc2 = nn.Linear(512, 2)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, sent_id, mask):\n",
        "        cls_hs = self.bert(sent_id, attention_mask=mask)['pooler_output']\n",
        "        x = self.fc1(cls_hs)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "model = BERT_Arch(bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ABRq89jBwAcu",
      "metadata": {
        "id": "ABRq89jBwAcu"
      },
      "outputs": [],
      "source": [
        "device = xm.xla_device()\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dMVmdYWlyGVE",
      "metadata": {
        "id": "dMVmdYWlyGVE"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)  # Reduced batch size\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JifMc9-KwB7t",
      "metadata": {
        "id": "JifMc9-KwB7t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print(f'  Batch {step} of {len(train_dataloader)}.')\n",
        "        batch = [r.to(device) for r in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(sent_id, mask)\n",
        "        loss = cross_entropy(preds, labels)\n",
        "\n",
        "        # Accumulate loss without detaching\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        xm.optimizer_step(optimizer) # Call optimizer_step here\n",
        "\n",
        "        # Clear memory after each step\n",
        "        del sent_id, mask, labels, preds, loss\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()  # Use torch.cuda.empty_cache() instead of just empty_cache()\n",
        "\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    return avg_loss\n",
        "\n",
        "# Reduce batch size in your dataloaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7o-gUwFpxelX",
      "metadata": {
        "id": "7o-gUwFpxelX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print(f'  Batch {step} of {len(train_dataloader)}.')\n",
        "        batch = [r.to(device) for r in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(sent_id, mask)\n",
        "        loss = cross_entropy(preds, labels)\n",
        "\n",
        "        # Accumulate loss without detaching\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        xm.optimizer_step(optimizer) # Call optimizer_step here\n",
        "\n",
        "        # No need to manually delete tensors when using XLA\n",
        "        # XLA handles memory management differently\n",
        "        # del sent_id, mask, labels, preds, loss\n",
        "        # gc.collect()\n",
        "        # torch.cuda.empty_cache()  # Use torch.cuda.empty_cache() instead of just empty_cache()\n",
        "\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    return avg_loss\n",
        "\n",
        "# Unfreeze the embeddings layer\n",
        "for param in model.bert.embeddings.parameters():\n",
        "    param.requires_grad = True  # Allow gradients to flow\n",
        "\n",
        "# Reduce batch size in your dataloaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Erlgsy-e29u7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Erlgsy-e29u7",
        "outputId": "23b21898-bfb7-4f37-b3da-35f3cd4f03b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 2\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "torch_xla/csrc/tensor.cpp:190 : Check failed: data()->tensor_data \n*** Begin stack trace ***\n\ttsl::CurrentStackTrace()\n\ttorch_xla::XLATensor::shape() const\n\ttorch_xla::XLATensorImpl::SetupSizeProperties()\n\ttorch_xla::XLATensorImpl::sizes_custom() const\n\tat::FunctionalTensorWrapper::sizes_custom() const\n\tat::native::math_native_layer_norm(at::Tensor const&, c10::ArrayRef<long>, std::optional<at::Tensor> const&, std::optional<at::Tensor> const&, double)\n\ttorch_xla::XLANativeFunctions::native_layer_norm(at::Tensor const&, c10::ArrayRef<long>, std::optional<at::Tensor> const&, std::optional<at::Tensor> const&, double)\n\t\n\tat::_ops::native_layer_norm::call(at::Tensor const&, c10::ArrayRef<c10::SymInt>, std::optional<at::Tensor> const&, std::optional<at::Tensor> const&, double)\n\tat::native::layer_norm_symint(at::Tensor const&, c10::ArrayRef<c10::SymInt>, std::optional<at::Tensor> const&, std::optional<at::Tensor> const&, double, bool)\n\t\n\tat::_ops::layer_norm::call(at::Tensor const&, c10::ArrayRef<c10::SymInt>, std::optional<at::Tensor> const&, std::optional<at::Tensor> const&, double, bool)\n\t\n\t\n\t_PyObject_MakeTpCall\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_Vectorcall\n\t_PyEval_EvalFrameDefault\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t_PyEval_EvalFrameDefault\n\t_PyObject_FastCallDictTstate\n\t_PyObject_Call_Prepend\n\t\n\t_PyObject_MakeTpCall\n\t_PyEval_EvalFrameDefault\n\t\n\tPyObject_Call\n\t_PyEval_EvalFrameDefault\n\t\n\tPyObject_Call\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_Vectorcall\n\t_PyObject_FastCallDictTstate\n\t_PyObject_Call_Prepend\n\t\n\t_PyObject_MakeTpCall\n\t_PyEval_EvalFrameDefault\n\t\n\tPyObject_Call\n\t_PyEval_EvalFrameDefault\n\t\n\tPyObject_Call\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_Vectorcall\n\t_PyObject_FastCallDictTstate\n\t_PyObject_Call_Prepend\n\t\n\t_PyObject_MakeTpCall\n\t_PyEval_EvalFrameDefault\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t_PyEval_EvalFrameDefault\n\t_PyObject_FastCallDictTstate\n\t_PyObject_Call_Prepend\n\t\n\t_PyObject_MakeTpCall\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_Vectorcall\n\t_PyEval_EvalFrameDefault\n\t\n\tPyEval_EvalCode\n\t\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t\n\t\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_Vectorcall\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_Vectorcall\n\t_PyEval_EvalFrameDefault\n\t\n\tPyObject_Call\n\t_PyEval_EvalFrameDefault\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t\n\t\n\t\n\t\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_Vectorcall\n\t_PyEval_EvalFrameDefault\n\t\n\t\n\t\n\t\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t\n\t\n\t\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t\n\t\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_Vectorcall\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_Vectorcall\n\t\n\t\n\t\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_Vectorcall\n\t_PyEval_EvalFrameDefault\n*** End stack trace ***\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-a91c168dc1e9>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\n Epoch {epoch + 1} / {epochs}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Call the train function to train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assuming you have an 'evaluate' function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-84-7824d5fea5b0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-fb54223a5029>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pooler_output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_hs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1075\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1077\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m   1078\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0membeddings\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         return F.layer_norm(\n\u001b[0m\u001b[1;32m    202\u001b[0m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2571\u001b[0m             \u001b[0mlayer_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2572\u001b[0m         )\n\u001b[0;32m-> 2573\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: torch_xla/csrc/tensor.cpp:190 : Check failed: data()->tensor_data \n*** Begin stack trace ***\n\ttsl::CurrentStackTrace()\n\ttorch_xla::XLATensor::shape() const\n\ttorch_xla::XLATensorImpl::SetupSizeProperties()\n\ttorch_xla::XLATensorImpl::sizes_custom() const\n\tat::FunctionalTensorWrapper::sizes_custom() const\n\tat::native::math_native_layer_norm(at::Tensor const&, c10::ArrayRef<long>, std::optional<at::Tensor> const&, std::optional<at::Tensor> const&, double)\n\ttorch_xla::XLANativeFunctions::native_layer_norm(at::Tensor const&, c10::ArrayRef<long>, std::optional<at::Tensor> const&, std::optional<at::Tensor> const&, double)\n\t\n\tat::_ops::native_layer_norm::call(at::Tensor const&, c10::ArrayRef<c10::SymInt>, std::optional<at::Tensor> const&, std::optional<at::Tensor> const&, double)\n\tat::native::layer_norm_symint(at::Tensor const&, c10::ArrayRef<c10::SymInt>, std::optional<at::Tensor> const&, std::optional<at::Tensor> const&, double, bool)\n\t\n\tat::_ops::layer_norm::call(at::Tensor const&, c10::ArrayRef<c10::SymInt>, std::optional<at::Tensor> const&, std::optional<at::Tensor> const&, double, bool)\n\t\n\t\n\t_PyObject_MakeTpCall\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_Vectorcall\n\t_PyEval_EvalFrameDefault\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t_PyEval_EvalFrameDefault\n\t_PyObject_FastCallDictTstate\n\t_PyObject_Call_Prepend\n\t\n\t_PyObject_MakeTpCall\n\t_PyEval_EvalFrameDefault\n\t\n\tPyObject_Call\n\t_PyEval_EvalFrameDefault\n\t\n\tPyObject_Call\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_Vectorcall\n\t_PyObject_FastCallDictTstate\n\t_PyObject_Call_Prepend\n\t\n\t_PyObject_MakeTpCall\n\t_PyEval_EvalFrameDefault\n\t\n\tPyObject_Call\n\t_PyEval_EvalFrameDefault\n\t\n\tPyObject_Call\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_Vectorcall\n\t_PyObject_FastCallDictTstate\n\t_PyObject_Call_Prepend\n\t\n\t_PyObject_MakeTpCall\n\t_PyEval_EvalFrameDefault\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t_PyEval_EvalFrameDefault\n\t_PyObject_FastCallDictTstate\n\t_PyObject_Call_Prepend\n\t\n\t_PyObject_MakeTpCall\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_Vectorcall\n\t_PyEval_EvalFrameDefault\n\t\n\tPyEval_EvalCode\n\t\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t\n\t\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_Vectorcall\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_Vectorcall\n\t_PyEval_EvalFrameDefault\n\t\n\tPyObject_Call\n\t_PyEval_EvalFrameDefault\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t\n\t\n\t\n\t\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_Vectorcall\n\t_PyEval_EvalFrameDefault\n\t\n\t\n\t\n\t\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t\n\t\n\t\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t\n\t\n\t\n\t_PyEval_EvalFrameDefault\n\t\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_Vectorcall\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_Vectorcall\n\t\n\t\n\t\n\t_PyEval_EvalFrameDefault\n\t_PyFunction_Vectorcall\n\t_PyEval_EvalFrameDefault\n*** End stack trace ***\n"
          ]
        }
      ],
      "source": [
        "epochs = 2  # Define the number of epochs\n",
        "best_valid_loss = float('inf')\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f'\\n Epoch {epoch + 1} / {epochs}')\n",
        "\n",
        "    train_loss = train()  # Call the train function to train for one epoch\n",
        "    valid_loss = evaluate()  # Assuming you have an 'evaluate' function\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        xm.save(model.state_dict(), 'best_model_weights.pt')\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bXjQPLKixj2A",
      "metadata": {
        "id": "bXjQPLKixj2A"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('best_model_weights.pt'))\n",
        "\n",
        "# Assuming test_seq and test_mask are prepared similarly to train and val\n",
        "with torch.no_grad():\n",
        "    preds = model(test_seq.to(device), test_mask.to(device))\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "\n",
        "preds = np.argmax(preds, axis=1)\n",
        "print(classification_report(test_y, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Z9tAM-Atxlsn",
      "metadata": {
        "id": "Z9tAM-Atxlsn"
      },
      "source": [
        "# REPEATED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "og1gRiM_wY6s",
      "metadata": {
        "id": "og1gRiM_wY6s"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
        "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=32)\n",
        "val_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CZxYGfPEsKg0",
      "metadata": {
        "id": "CZxYGfPEsKg0"
      },
      "outputs": [],
      "source": [
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "cross_entropy = nn.NLLLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print(f'  Batch {step} of {len(train_dataloader)}.')\n",
        "        batch = [r.to(device) for r in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(sent_id, mask)\n",
        "        loss = cross_entropy(preds, labels)\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        xm.optimizer_step(optimizer)\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    return avg_loss\n",
        "\n",
        "def evaluate():\n",
        "    print(\"\\nEvaluating...\")\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    for step, batch in enumerate(val_dataloader):\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print(f'  Batch {step} of {len(val_dataloader)}.')\n",
        "        batch = [t.to(device) for t in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "        with torch.no_grad():\n",
        "            preds = model(sent_id, mask)\n",
        "            loss = cross_entropy(preds, labels)\n",
        "            total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(val_dataloader)\n",
        "    return avg_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Zm5CCyZfwp6o",
      "metadata": {
        "id": "Zm5CCyZfwp6o"
      },
      "outputs": [],
      "source": [
        "best_valid_loss = float('inf')\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f'\\n Epoch {epoch + 1} / {epochs}')\n",
        "\n",
        "    train_loss = train()\n",
        "    valid_loss = evaluate()\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        xm.save(model.state_dict(), 'best_model_weights.pt')\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FWRnh6qRsME1",
      "metadata": {
        "id": "FWRnh6qRsME1"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print(f'  Batch {step} of {len(train_dataloader)}.')\n",
        "\n",
        "        batch = [r.to(device) for r in batch]  # Move batch to TPU\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        preds = model(sent_id, mask)  # Get predictions\n",
        "        loss = cross_entropy(preds, labels)  # Compute loss\n",
        "        total_loss += loss.item()  # Accumulate loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping\n",
        "        xm.optimizer_step(optimizer)  # TPU-specific optimizer step\n",
        "\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    return avg_loss\n",
        "\n",
        "def evaluate():\n",
        "    print(\"\\nEvaluating...\")\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    for step, batch in enumerate(val_dataloader):\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print(f'  Batch {step} of {len(val_dataloader)}.')\n",
        "\n",
        "        batch = [t.to(device) for t in batch]  # Move batch to TPU\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        with torch.no_grad():  # Deactivate autograd\n",
        "            preds = model(sent_id, mask)  # Get predictions\n",
        "            loss = cross_entropy(preds, labels)  # Compute loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(val_dataloader)\n",
        "    return avg_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tfVkB39MsPkI",
      "metadata": {
        "id": "tfVkB39MsPkI"
      },
      "outputs": [],
      "source": [
        "best_valid_loss = float('inf')\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f'\\n Epoch {epoch + 1} / {epochs}')\n",
        "\n",
        "    train_loss = train()\n",
        "    valid_loss = evaluate()\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        xm.save(model.state_dict(), 'best_model_weights.pt')\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yJTq3yHZsVEf",
      "metadata": {
        "id": "yJTq3yHZsVEf"
      },
      "outputs": [],
      "source": [
        "# Load best model weights\n",
        "model.load_state_dict(torch.load('best_model_weights.pt'))\n",
        "\n",
        "# Evaluate on test set\n",
        "with torch.no_grad():\n",
        "    preds = model(test_seq.to(device), test_mask.to(device))\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "\n",
        "# Get predictions and evaluate\n",
        "preds = np.argmax(preds, axis=1)\n",
        "print(classification_report(test_y, preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jmq0gDniQQAS",
      "metadata": {
        "id": "jmq0gDniQQAS"
      },
      "outputs": [],
      "source": [
        "for batch in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "    xm.optimizer_step(optimizer)  # Use xm.optimizer_step instead of optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A8osGksdQSE4",
      "metadata": {
        "id": "A8osGksdQSE4"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(model.parameters(), lr=2e-5)\n",
        "\n",
        "for epoch in range(3):  # Change to more epochs if needed\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        xm.optimizer_step(optimizer)  # Use xm.optimizer_step instead of optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9HrFC6AtQi-m",
      "metadata": {
        "id": "9HrFC6AtQi-m"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "val_preds = []\n",
        "\n",
        "for batch in val_loader:\n",
        "    input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    logits = outputs.logits\n",
        "    preds = torch.argmax(logits, dim=1).flatten()\n",
        "    val_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "# Calculate accuracy and classification report\n",
        "accuracy = accuracy_score(val_labels, val_preds)\n",
        "report = classification_report(val_labels, val_preds, target_names=['REAL', 'FAKE'])\n",
        "\n",
        "print(f\"Validation Accuracy: {accuracy}\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zUl6dH2NQmUE",
      "metadata": {
        "id": "zUl6dH2NQmUE"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(val_labels, val_preds)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['REAL', 'FAKE'], yticklabels=['REAL', 'FAKE'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SijFvNQmQomj",
      "metadata": {
        "id": "SijFvNQmQomj"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained('bert_model')\n",
        "tokenizer.save_pretrained('bert_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ClrZ6RGjQG6j",
      "metadata": {
        "id": "ClrZ6RGjQG6j"
      },
      "outputs": [],
      "source": [
        "device = xm.xla_device()\n",
        "\n",
        "# Initialize the model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "model = model.to(device)  # Move model to TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EE1cfGAWQHut",
      "metadata": {
        "id": "EE1cfGAWQHut"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82716ccb",
      "metadata": {
        "id": "82716ccb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Assuming you have a DataFrame 'df' with your dataset loaded\n",
        "# df = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Randomly select 400,000 rows from the dataset\n",
        "df_sampled = df.sample(n=400000, random_state=42)\n",
        "\n",
        "# Separate the dataset into two categories\n",
        "df_0 = df_sampled[df_sampled['label'] == 0]\n",
        "df_1 = df_sampled[df_sampled['label'] == 1]\n",
        "\n",
        "# Determine the minimum count between the two categories to balance them\n",
        "min_count = min(len(df_0), len(df_1))\n",
        "\n",
        "# Resample the two categories to have the same number of rows\n",
        "df_0_balanced = resample(df_0, replace=False, n_samples=min_count, random_state=42)\n",
        "df_1_balanced = resample(df_1, replace=False, n_samples=min_count, random_state=42)\n",
        "\n",
        "# Combine the two balanced datasets\n",
        "df_balanced = pd.concat([df_0_balanced, df_1_balanced])\n",
        "\n",
        "# Shuffle the final dataset\n",
        "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Save the balanced dataset to a CSV file\n",
        "df_balanced.to_csv('balanced_dataset.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a265356",
      "metadata": {
        "id": "0a265356"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cea1e452",
      "metadata": {
        "id": "cea1e452"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b204692a",
      "metadata": {
        "id": "b204692a"
      },
      "source": [
        "# TRAIN ARRAY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebe7a8f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebe7a8f2",
        "outputId": "ce8cba67-142b-432b-ea6c-c00f577ab098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF matrix shape: (353208, 5000)\n",
            "Time taken: 94.16932797431946 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  # Import the class\n",
        "\n",
        "# Define the TfidfVectorizer with the specified parameters\n",
        "tfidf = TfidfVectorizer(max_df=0.85, min_df=2, max_features=5000)\n",
        "\n",
        "# Start the timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Fit and transform the text data\n",
        "X = tfidf.fit_transform(df['cleaned_text'])\n",
        "\n",
        "# End the timer\n",
        "end_time = time.time()\n",
        "y = df['label']\n",
        "\n",
        "# If you want to convert the result to a dense array (optional, be cautious with large data)\n",
        "X = X.toarray()\n",
        "\n",
        "# Display the shape of the matrix and time\n",
        "print(f\"TF-IDF matrix shape: {X.shape}\")\n",
        "print(f\"Time taken: {end_time - start_time} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af6d16c9",
      "metadata": {
        "id": "af6d16c9"
      },
      "outputs": [],
      "source": [
        "y = df['label']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "893508a9",
      "metadata": {
        "id": "893508a9"
      },
      "source": [
        "# SKIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bde254d6",
      "metadata": {
        "id": "bde254d6",
        "outputId": "893e915c-285e-4c02-839a-7b4ff78ec258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows in df: 788922\n",
            "Number of rows in merged_df: 854260\n"
          ]
        }
      ],
      "source": [
        "# Number of rows in df\n",
        "num_rows_df = df.shape[0]\n",
        "\n",
        "# Number of rows in merged_df\n",
        "num_rows_merged_df = merged_df.shape[0]\n",
        "\n",
        "# Print the results\n",
        "print(f\"Number of rows in df: {num_rows_df}\")\n",
        "print(f\"Number of rows in merged_df: {num_rows_merged_df}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab73d063-fd41-464f-a80c-5a7efb5f1e78",
      "metadata": {
        "id": "ab73d063-fd41-464f-a80c-5a7efb5f1e78",
        "outputId": "96204094-5de9-44d0-f917-64477c2058d9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>source</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text_length</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Federal law supersedes state law, and cannabis...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>967</td>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Miles feels restless after working all day. He...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5068</td>\n",
              "      <td>778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>So first of I am danish. That means that I fol...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1602</td>\n",
              "      <td>267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In this paper we present a novel rule-based ap...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5469</td>\n",
              "      <td>848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Most social progressives, love democracy, and ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2379</td>\n",
              "      <td>380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788917</th>\n",
              "      <td>\\nIn the vast expanse of time, where the echoe...</td>\n",
              "      <td>1</td>\n",
              "      <td>1293</td>\n",
              "      <td>5523</td>\n",
              "      <td>870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788918</th>\n",
              "      <td>\\nThe phenomenon of brain drain, particularly ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1154</td>\n",
              "      <td>4540</td>\n",
              "      <td>677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788919</th>\n",
              "      <td>\\nThe Influence of Climate Change on Marine Ec...</td>\n",
              "      <td>1</td>\n",
              "      <td>2783</td>\n",
              "      <td>3889</td>\n",
              "      <td>598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788920</th>\n",
              "      <td>\\nTitle: The Case for Limiting Car Usage: Navi...</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>3560</td>\n",
              "      <td>533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788921</th>\n",
              "      <td>\\nIn the vast expanse of a globalized society,...</td>\n",
              "      <td>1</td>\n",
              "      <td>4318</td>\n",
              "      <td>4563</td>\n",
              "      <td>693</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>788922 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  source  prompt_id  \\\n",
              "0       Federal law supersedes state law, and cannabis...       1          0   \n",
              "1       Miles feels restless after working all day. He...       1          0   \n",
              "2       So first of I am danish. That means that I fol...       1          0   \n",
              "3       In this paper we present a novel rule-based ap...       1          0   \n",
              "4       Most social progressives, love democracy, and ...       1          0   \n",
              "...                                                   ...     ...        ...   \n",
              "788917  \\nIn the vast expanse of time, where the echoe...       1       1293   \n",
              "788918  \\nThe phenomenon of brain drain, particularly ...       1       1154   \n",
              "788919  \\nThe Influence of Climate Change on Marine Ec...       1       2783   \n",
              "788920  \\nTitle: The Case for Limiting Car Usage: Navi...       1         41   \n",
              "788921  \\nIn the vast expanse of a globalized society,...       1       4318   \n",
              "\n",
              "        text_length  word_count  \n",
              "0               967         157  \n",
              "1              5068         778  \n",
              "2              1602         267  \n",
              "3              5469         848  \n",
              "4              2379         380  \n",
              "...             ...         ...  \n",
              "788917         5523         870  \n",
              "788918         4540         677  \n",
              "788919         3889         598  \n",
              "788920         3560         533  \n",
              "788921         4563         693  \n",
              "\n",
              "[788922 rows x 5 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Transform 'source' column\n",
        "df['source'] = df['source'].apply(lambda x: 0 if 'Human' in x else 1)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86c78b58-9346-45b8-9604-78d1ae864b23",
      "metadata": {
        "id": "86c78b58-9346-45b8-9604-78d1ae864b23",
        "outputId": "ef7abce7-99d5-41ad-8c95-3033b3aa0ff2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Federal law supersedes state law, and cannabis...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Miles feels restless after working all day. He...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>So first of I am danish. That means that I fol...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In this paper we present a novel rule-based ap...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Most social progressives, love democracy, and ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788917</th>\n",
              "      <td>\\nIn the vast expanse of time, where the echoe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788918</th>\n",
              "      <td>\\nThe phenomenon of brain drain, particularly ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788919</th>\n",
              "      <td>\\nThe Influence of Climate Change on Marine Ec...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788920</th>\n",
              "      <td>\\nTitle: The Case for Limiting Car Usage: Navi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788921</th>\n",
              "      <td>\\nIn the vast expanse of a globalized society,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>788922 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  label\n",
              "0       Federal law supersedes state law, and cannabis...      1\n",
              "1       Miles feels restless after working all day. He...      1\n",
              "2       So first of I am danish. That means that I fol...      1\n",
              "3       In this paper we present a novel rule-based ap...      1\n",
              "4       Most social progressives, love democracy, and ...      1\n",
              "...                                                   ...    ...\n",
              "788917  \\nIn the vast expanse of time, where the echoe...      1\n",
              "788918  \\nThe phenomenon of brain drain, particularly ...      1\n",
              "788919  \\nThe Influence of Climate Change on Marine Ec...      1\n",
              "788920  \\nTitle: The Case for Limiting Car Usage: Navi...      1\n",
              "788921  \\nIn the vast expanse of a globalized society,...      1\n",
              "\n",
              "[788922 rows x 2 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Drop specified columns\n",
        "columns_to_drop = ['prompt_id', 'text_length', 'word_count']\n",
        "df = df.drop(columns=columns_to_drop)\n",
        "\n",
        "\n",
        "# Rename the 'source' column to 'label'\n",
        "df = df.rename(columns={'source': 'label'})\n",
        "\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63b13931-1987-4222-bced-4777ea70a0b4",
      "metadata": {
        "id": "63b13931-1987-4222-bced-4777ea70a0b4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9332351-9966-4013-9870-7dd8da1c55bd",
      "metadata": {
        "id": "a9332351-9966-4013-9870-7dd8da1c55bd",
        "outputId": "5ce537dc-6b85-4579-af43-4d885e1f2c16",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "1    476499\n",
            "0    377761\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calculate value counts\n",
        "label_counts = merged_df['label'].value_counts()\n",
        "\n",
        "# Print the actual value counts\n",
        "print(label_counts)\n",
        "\n",
        "# Plot the bar chart\n",
        "label_counts.plot.bar()\n",
        "plt.title('Label Distribution')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=0)  # Rotate category labels for better readability if necessary\n",
        "\n",
        "# Add text annotations on each bar\n",
        "for index, value in enumerate(label_counts):\n",
        "    plt.text(index, value, str(value), ha='center', va='bottom')\n",
        "\n",
        "# Show the plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "297bdb5d",
      "metadata": {
        "id": "297bdb5d",
        "outputId": "a422ac4d-f780-42d6-8f5d-ac1496c2e863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "1    441230\n",
            "0    347692\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Calculate value counts\n",
        "label_counts = df['label'].value_counts()\n",
        "\n",
        "# Print the actual value counts\n",
        "print(label_counts)\n",
        "\n",
        "# Plot the bar chart\n",
        "label_counts.plot.bar()\n",
        "plt.title('Label Distribution')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=0)  # Rotate category labels for better readability if necessary\n",
        "\n",
        "# Add text annotations on each bar\n",
        "for index, value in enumerate(label_counts):\n",
        "    plt.text(index, value, str(value), ha='center', va='bottom')\n",
        "\n",
        "# Show the plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4460263-4f27-450a-bed4-3fc072796896",
      "metadata": {
        "id": "d4460263-4f27-450a-bed4-3fc072796896",
        "outputId": "ffc9059c-fbd2-4a4a-b5dd-b3110db5987f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "0    377761\n",
            "1    476499\n",
            "Name: text, dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "([<matplotlib.patches.Wedge at 0x2377d5d5e90>,\n",
              "  <matplotlib.patches.Wedge at 0x2377d6af1d0>],\n",
              " [Text(0.1986178067959356, 1.08192003716706, '0'),\n",
              "  Text(-0.19861780679593574, -1.0819200371670599, '1')],\n",
              " [Text(0.10833698552505577, 0.5901382020911237, '44%'),\n",
              "  Text(-0.10833698552505584, -0.5901382020911236, '56%')])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_classes = merged_df.groupby('label').count()['text']\n",
        "print(data_classes)\n",
        "plt.title('class distribution in dataset')\n",
        "plt.pie(data_classes , labels = ['0','1'] ,autopct='%0.0f%%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edfc19fe",
      "metadata": {
        "id": "edfc19fe",
        "outputId": "a80ff7de-7f65-4df8-f235-a0feb81f85e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "0    347692\n",
            "1    441230\n",
            "Name: text, dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "([<matplotlib.patches.Wedge at 0x2377d6bf290>,\n",
              "  <matplotlib.patches.Wedge at 0x2377d6fdf10>],\n",
              " [Text(0.20368216572248712, 1.0809780642393245, '0'),\n",
              "  Text(-0.20368206451401583, -1.0809780833094205, '1')],\n",
              " [Text(0.1110993631213566, 0.5896243986759951, '44%'),\n",
              "  Text(-0.11109930791673589, -0.5896244090778656, '56%')])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_classes = df.groupby('label').count()['text']\n",
        "print(data_classes)\n",
        "plt.title('class distribution in dataset')\n",
        "plt.pie(data_classes , labels = ['0','1'] ,autopct='%0.0f%%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d34a638d-3c03-47df-9947-ffe532103e8e",
      "metadata": {
        "id": "d34a638d-3c03-47df-9947-ffe532103e8e",
        "outputId": "383c2ffd-8a19-414d-f94e-3df5738bf870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text            0\n",
            "label           0\n",
            "cleaned_text    3\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values\n",
        "print(merged_df.isnull().sum())\n",
        "\n",
        "# Drop rows with missing values (if any)\n",
        "merged_df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0460baf4",
      "metadata": {
        "id": "0460baf4",
        "outputId": "4f8aebef-90c7-4a3e-8548-cf89aec255f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text     0\n",
            "label    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Drop rows with missing values (if any)\n",
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba36364b-40c0-43b6-9e79-3321748629ab",
      "metadata": {
        "id": "ba36364b-40c0-43b6-9e79-3321748629ab",
        "outputId": "fcb839b6-8010-446c-9272-8ab0ce2ba8e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\brotz\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\brotz\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Remove newline characters\n",
        "    text = text.replace('\\n', ' ')\n",
        "    # Remove non-alphabetic characters\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Remove references and citations\n",
        "    text = re.sub(r'\\[.*?\\]|\\(.*?\\)', '', text)\n",
        "    # Remove LaTeX commands and special characters\n",
        "    text = re.sub(r'\\$\\\\?[a-zA-Z]+|\\$|\\\\', '', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove extra whitespaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    # Tokenize the text\n",
        "    words = text.split()\n",
        "    # Remove stopwords and lemmatize the words\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Apply the preprocessing function to the 'text' column\n",
        "df['cleaned_text'] =df['text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cefa2266",
      "metadata": {
        "id": "cefa2266",
        "outputId": "773c65d3-336a-4157-8d78-dba3f1c53008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned data saved to C:\\Users\\brotz\\Downloads\\dataset\\cleaned_data.csv\n"
          ]
        }
      ],
      "source": [
        "output_file_path = r'C:\\Users\\brotz\\Downloads\\dataset\\cleaned_data.csv'\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(f\"Cleaned data saved to {output_file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05a246a7",
      "metadata": {
        "id": "05a246a7"
      },
      "source": [
        "# END SKIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0ad106c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0ad106c",
        "outputId": "53e6fe1f-a2ef-4330-896e-31bea53e491a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n"
          ]
        }
      ],
      "source": [
        "pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc0377ef",
      "metadata": {
        "id": "cc0377ef"
      },
      "source": [
        "## RANDOM Forest (TAKES TOO LONG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cd7f782",
      "metadata": {
        "id": "7cd7f782"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "# Define the parameter grid (reduced for memory efficiency)\n",
        "param_grid = {\n",
        "    'n_estimators': [int(x) for x in np.linspace(start=100, stop=500, num=5)],\n",
        "    'max_features': ['auto', 'sqrt'],\n",
        "    'max_depth': [int(x) for x in np.linspace(10, 50, num=5)] + [None],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'bootstrap': [True]\n",
        "}\n",
        "\n",
        "# Initialize a RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Use RandomizedSearchCV to search for the best hyperparameters\n",
        "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=param_grid,\n",
        "                                n_iter=50, cv=3, verbose=0, random_state=42, n_jobs=1)\n",
        "\n",
        "# Add a progress bar to the fitting process using tqdm\n",
        "with tqdm(total=rf_random.n_iter * rf_random.cv, desc=\"Fitting RandomizedSearchCV\") as pbar:\n",
        "    rf_random.fit(X_train, y_train)\n",
        "    pbar.update(rf_random.n_iter * rf_random.cv)\n",
        "\n",
        "# Print the best parameters found by RandomizedSearchCV\n",
        "print(f\"Best parameters: {rf_random.best_params_}\")\n",
        "\n",
        "# Evaluate the optimized model on the test set\n",
        "y_pred = rf_random.predict(X_test)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Clear memory explicitly\n",
        "del rf_random\n",
        "gc.collect()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f98c58ff",
      "metadata": {
        "id": "f98c58ff",
        "outputId": "d6f73729-6eec-4849-854f-011af23f3b09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3987"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "del rf_random\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76a01168",
      "metadata": {
        "id": "76a01168"
      },
      "source": [
        "## Log reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5ac2237",
      "metadata": {
        "id": "c5ac2237"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD, PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Assuming merged_data_all is your DataFrame with 'cleaned_text' and 'label'\n",
        "X = df['cleaned_text']\n",
        "y = df['label']\n",
        "\n",
        "X_sample = X.sample(frac=0.2, random_state=42)\n",
        "y_sample = y.sample(frac=0.2, random_state=42)\n",
        "\n",
        "# Feature sizes to test\n",
        "feature_sizes = [5000, 7000,10000]\n",
        "\n",
        "# Results dictionary\n",
        "results = {'Features': [], 'Original TF-IDF Accuracy': [], 'Truncated SVD Accuracy': [], 'PCA Accuracy': []}\n",
        "\n",
        "# Function to create and evaluate a pipeline\n",
        "def evaluate_pipeline(tfidf_max_features, method='original'):\n",
        "    # Create TF-IDF vectorizer\n",
        "    tfidf = TfidfVectorizer(max_features=tfidf_max_features, max_df=0.85, min_df=5)\n",
        "\n",
        "    # Create the pipeline\n",
        "    if method == 'svd':\n",
        "        svd = TruncatedSVD(n_components=500)  # You can adjust the number of components for SVD\n",
        "        pipeline = Pipeline([\n",
        "            ('tfidf', tfidf),\n",
        "            ('svd', svd),\n",
        "            ('clf', LogisticRegression(solver='liblinear', max_iter=1000))\n",
        "        ])\n",
        "    elif method == 'pca':\n",
        "        pca = PCA(n_components=500)  # You can adjust the number of components for PCA\n",
        "        pipeline = Pipeline([\n",
        "            ('tfidf', tfidf),\n",
        "            ('pca', pca),\n",
        "            ('clf', LogisticRegression(solver='liblinear', max_iter=1000))\n",
        "        ])\n",
        "    else:\n",
        "        pipeline = Pipeline([\n",
        "            ('tfidf', tfidf),\n",
        "            ('clf', LogisticRegression(solver='liblinear', max_iter=1000))\n",
        "        ])\n",
        "\n",
        "    # Evaluate the pipeline using cross-validation\n",
        "    scores = cross_val_score(pipeline, X_sample, y_sample, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "    return scores.mean()\n",
        "\n",
        "# Loop through each feature size and evaluate\n",
        "for size in feature_sizes:\n",
        "    # Evaluate with original TF-IDF\n",
        "    tfidf_acc = evaluate_pipeline(size, method='original')\n",
        "\n",
        "    # Evaluate with Truncated SVD\n",
        "    svd_acc = evaluate_pipeline(size, method='svd')\n",
        "\n",
        "    # Evaluate with PCA\n",
        "    pca_acc = evaluate_pipeline(size, method='pca')\n",
        "\n",
        "    # Store results\n",
        "    results['Features'].append(size)\n",
        "    results['Original TF-IDF Accuracy'].append(tfidf_acc)\n",
        "    results['Truncated SVD Accuracy'].append(svd_acc)\n",
        "    results['PCA Accuracy'].append(pca_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bac9b2b",
      "metadata": {
        "id": "3bac9b2b",
        "outputId": "aa1221cf-399a-43c3-c2a3-91fb39fea961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Features  Original TF-IDF Accuracy  Truncated SVD Accuracy  PCA Accuracy\n",
            "0      5000                  0.833494                0.793623      0.794529\n",
            "1      7000                  0.838006                0.795930      0.795949\n",
            "2     10000                  0.842557                0.795689      0.795892\n"
          ]
        }
      ],
      "source": [
        "# Convert results to DataFrame for easier display\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Display the results\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb231b95",
      "metadata": {
        "id": "bb231b95"
      },
      "outputs": [],
      "source": [
        "# Convert results to DataFrame for easier display\n",
        "merged_results_df = pd.DataFrame(merged_results)\n",
        "\n",
        "# Display the results\n",
        "print(merged_results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7985587b",
      "metadata": {
        "id": "7985587b",
        "outputId": "e4ff7842-c0a6-48b4-f654-a8d85596385e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformed data has been saved as 'X_svd.npy'\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Assuming X is your text data\n",
        "X = merged_df['cleaned_text']\n",
        "y = merged_df['label']\n",
        "\n",
        "# Initialize TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(max_features=5000, max_df=0.85, min_df=2)\n",
        "\n",
        "# Transform the text data using TfidfVectorizer\n",
        "X_tfidf = tfidf.fit_transform(X)\n",
        "\n",
        "# Initialize TruncatedSVD to reduce dimensionality\n",
        "svd = TruncatedSVD(n_components=500)  # You can adjust the number of components as needed\n",
        "\n",
        "# Fit TruncatedSVD on the TF-IDF transformed data\n",
        "X_svd = svd.fit_transform(X_tfidf)\n",
        "\n",
        "# Save the transformed array to a .npy file\n",
        "np.save('X_svd.npy', X_svd)\n",
        "\n",
        "print(\"Transformed data has been saved as 'X_svd.npy'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60bda321",
      "metadata": {
        "id": "60bda321"
      },
      "outputs": [],
      "source": [
        "# Assuming X1 is your text data from df\n",
        "X1 = df['cleaned_text']\n",
        "y1 = df['label']\n",
        "\n",
        "# Initialize TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(max_features=5000, max_df=0.85, min_df=2)\n",
        "\n",
        "# Transform the text data using TfidfVectorizer\n",
        "X1_tfidf = tfidf.fit_transform(X1)\n",
        "\n",
        "# Initialize TruncatedSVD to reduce dimensionality\n",
        "svd = TruncatedSVD(n_components=500)  # You can adjust the number of components as needed\n",
        "\n",
        "# Fit TruncatedSVD on the TF-IDF transformed data\n",
        "X1_svd = svd.fit_transform(X1_tfidf)\n",
        "\n",
        "# Save the transformed array to a .npy file\n",
        "np.save('X1_svd.npy', X1_svd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ee358ce",
      "metadata": {
        "id": "7ee358ce",
        "outputId": "ae2590d4-6a64-4ebb-abad-608545614ad0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\brotz\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation metrics:\n",
            "Accuracy: 0.7564\n",
            "Precision: 0.7575\n",
            "Recall: 0.7564\n",
            "F1 Score: 0.7525\n",
            "ROC AUC: 0.8354\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Load the transformed data from the saved .npy file\n",
        "#X_svd = np.load('X_svd.npy')\n",
        "\n",
        "# Assuming merged_df is your DataFrame with 'label'\n",
        "# Define your labels (y)\n",
        "y = merged_df['label']\n",
        "\n",
        "# Define the Logistic Regression model\n",
        "clf = LogisticRegression(solver='liblinear', max_iter=1000)\n",
        "\n",
        "# Define the scoring metrics\n",
        "scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'precision': make_scorer(precision_score, average='weighted'),\n",
        "    'recall': make_scorer(recall_score, average='weighted'),\n",
        "    'f1': make_scorer(f1_score, average='weighted'),\n",
        "    'roc_auc': make_scorer(roc_auc_score, average='weighted', needs_proba=True)\n",
        "}\n",
        "\n",
        "# Perform cross-validation with multiple metrics\n",
        "scores = cross_validate(clf, X_svd, y, cv=5, scoring=scoring, return_train_score=False)\n",
        "\n",
        "# Print the results\n",
        "print(\"Cross-validation metrics:\")\n",
        "print(f\"Accuracy: {scores['test_accuracy'].mean():.4f}\")\n",
        "print(f\"Precision: {scores['test_precision'].mean():.4f}\")\n",
        "print(f\"Recall: {scores['test_recall'].mean():.4f}\")\n",
        "print(f\"F1 Score: {scores['test_f1'].mean():.4f}\")\n",
        "print(f\"ROC AUC: {scores['test_roc_auc'].mean():.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfc709ea",
      "metadata": {
        "id": "cfc709ea",
        "outputId": "d6681896-ef80-4f68-f7ac-0d142dd1ba35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation metrics:\n",
            "Accuracy: 0.7660\n",
            "Precision: 0.7730\n",
            "Recall: 0.7660\n",
            "F1 Score: 0.7605\n",
            "ROC AUC: 0.8509\n"
          ]
        }
      ],
      "source": [
        "# Load the transformed data from the saved .npy file\n",
        "#X1_svd = np.load('X1_svd.npy')\n",
        "\n",
        "# Assuming merged_df is your DataFrame with 'label'\n",
        "# Define your labels (y)\n",
        "y1 = df['label']\n",
        "\n",
        "# Define the Logistic Regression model\n",
        "clf = LogisticRegression(solver='liblinear', max_iter=1000)\n",
        "\n",
        "# Define the scoring metrics\n",
        "scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'precision': make_scorer(precision_score, average='weighted'),\n",
        "    'recall': make_scorer(recall_score, average='weighted'),\n",
        "    'f1': make_scorer(f1_score, average='weighted'),\n",
        "    'roc_auc': make_scorer(roc_auc_score, average='weighted', response_method='predict_proba')\n",
        "}\n",
        "\n",
        "# Perform cross-validation with multiple metrics\n",
        "scores = cross_validate(clf, X1_svd, y1, cv=5, scoring=scoring, return_train_score=False)\n",
        "\n",
        "# Print the results\n",
        "print(\"Cross-validation metrics:\")\n",
        "print(f\"Accuracy: {scores['test_accuracy'].mean():.4f}\")\n",
        "print(f\"Precision: {scores['test_precision'].mean():.4f}\")\n",
        "print(f\"Recall: {scores['test_recall'].mean():.4f}\")\n",
        "print(f\"F1 Score: {scores['test_f1'].mean():.4f}\")\n",
        "print(f\"ROC AUC: {scores['test_roc_auc'].mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9f3654c-e7ae-4916-a229-f33701a92851",
      "metadata": {
        "id": "e9f3654c-e7ae-4916-a229-f33701a92851"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aa90021",
      "metadata": {
        "id": "1aa90021"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbe413a4",
      "metadata": {
        "id": "fbe413a4"
      },
      "outputs": [],
      "source": [
        "def create_model(learning_rate=0.001, dropout_rate=0.2, activation='relu'):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=X1_svd.shape[1], activation=activation))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(64, activation=activation))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Use 'softmax' for multi-class\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4db792af",
      "metadata": {
        "id": "4db792af"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the cross-validation strategy\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Hyperparameters to try\n",
        "learning_rate = 0.001\n",
        "dropout_rate = 0.3\n",
        "activation = 'relu'\n",
        "units_layer1 = 128\n",
        "units_layer2 = 64\n",
        "batch_size = 32\n",
        "epochs = 200\n",
        "\n",
        "# Callback to track metrics at each epoch\n",
        "class EpochPerformance(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        epoch_performance['epoch'].append(epoch)\n",
        "        epoch_performance['val_loss'].append(logs['val_loss'])\n",
        "        epoch_performance['accuracy'].append(logs['accuracy'])\n",
        "        epoch_performance['val_accuracy'].append(logs['val_accuracy'])\n",
        "        tqdm_bar.update(1)  # Update the progress bar for each epoch\n",
        "\n",
        "# Cross-validation loop with tracking of best epoch\n",
        "epoch_performance = {\n",
        "    'epoch': [],\n",
        "    'val_loss': [],\n",
        "    'accuracy': [],\n",
        "    'val_accuracy': []\n",
        "}\n",
        "\n",
        "for train_index, test_index in kf.split(X1_svd, y1):\n",
        "    # Split the data\n",
        "    X_train, X_test = X1_svd[train_index], X1_svd[test_index]\n",
        "    y_train, y_test = y1[train_index], y1[test_index]\n",
        "\n",
        "    # Scale the data\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Create the model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units_layer1, input_dim=X_train.shape[1], activation=activation))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(units_layer2, activation=activation))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Use 'softmax' for multi-class\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Initialize the progress bar\n",
        "    tqdm_bar = tqdm(total=epochs, desc=\"Training Progress\")\n",
        "\n",
        "    # Train the model with tracking of metrics at each epoch\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        verbose=0,\n",
        "        validation_data=(X_test, y_test),\n",
        "        callbacks=[EpochPerformance()]\n",
        "    )\n",
        "\n",
        "    tqdm_bar.close()  # Close the progress bar after training\n",
        "\n",
        "# Determine the best epoch based on validation accuracy\n",
        "best_epoch = np.argmax(epoch_performance['val_accuracy'])\n",
        "best_val_accuracy = epoch_performance['val_accuracy'][best_epoch]\n",
        "best_val_loss = epoch_performance['val_loss'][best_epoch]\n",
        "\n",
        "print(f\"Best Epoch: {best_epoch + 1}\")\n",
        "print(f\"Validation Accuracy at Best Epoch: {best_val_accuracy:.4f}\")\n",
        "print(f\"Validation Loss at Best Epoch: {best_val_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c9744c7",
      "metadata": {
        "id": "6c9744c7",
        "outputId": "f72a2f50-9a50-45fe-fc4f-38500a7bfd14"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "Training Progress: 100%|██████████| 1000/1000 [4:26:09<00:00, 15.97s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Epoch: 100\n",
            "Validation Accuracy at Best Epoch: 0.8891\n",
            "Validation Loss at Best Epoch: 0.2487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Hyperparameters to try\n",
        "learning_rate = 0.001\n",
        "dropout_rate = 0.3\n",
        "activation = 'relu'\n",
        "units_layer1 = 128\n",
        "units_layer2 = 64\n",
        "batch_size = 32\n",
        "epochs = 1000\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X1_svd, y1, test_size=0.2, random_state=42, stratify=y1)\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Callback to track metrics at each epoch\n",
        "class EpochPerformance(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        epoch_performance['epoch'].append(epoch)\n",
        "        epoch_performance['val_loss'].append(logs['val_loss'])\n",
        "        epoch_performance['accuracy'].append(logs['accuracy'])\n",
        "        epoch_performance['val_accuracy'].append(logs['val_accuracy'])\n",
        "        tqdm_bar.update(1)  # Update the progress bar for each epoch\n",
        "\n",
        "# Dictionary to store the performance metrics at each epoch\n",
        "epoch_performance = {\n",
        "    'epoch': [],\n",
        "    'val_loss': [],\n",
        "    'accuracy': [],\n",
        "    'val_accuracy': []\n",
        "}\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Dense(units_layer1, input_dim=X_train.shape[1], activation=activation))\n",
        "model.add(Dropout(dropout_rate))\n",
        "model.add(Dense(units_layer2, activation=activation))\n",
        "model.add(Dropout(dropout_rate))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Use 'softmax' for multi-class\n",
        "\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Initialize the progress bar\n",
        "tqdm_bar = tqdm(total=epochs, desc=\"Training Progress\")\n",
        "\n",
        "# Train the model with tracking of metrics at each epoch\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    verbose=0,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[EpochPerformance()]\n",
        ")\n",
        "\n",
        "tqdm_bar.close()  # Close the progress bar after training\n",
        "\n",
        "# Determine the best epoch based on validation accuracy\n",
        "best_epoch = np.argmax(epoch_performance['val_accuracy'])\n",
        "best_val_accuracy = epoch_performance['val_accuracy'][best_epoch]\n",
        "best_val_loss = epoch_performance['val_loss'][best_epoch]\n",
        "\n",
        "print(f\"Best Epoch: {best_epoch + 1}\")\n",
        "print(f\"Validation Accuracy at Best Epoch: {best_val_accuracy:.4f}\")\n",
        "print(f\"Validation Loss at Best Epoch: {best_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f451ff2b",
      "metadata": {
        "id": "f451ff2b"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f599790f-863d-4542-8372-c05deec893b7",
      "metadata": {
        "id": "f599790f-863d-4542-8372-c05deec893b7",
        "outputId": "b27e9120-02e4-467b-a915-8812bd795874"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame saved to merged_data_all.csv\n"
          ]
        }
      ],
      "source": [
        "# Save the DataFrame with the cleaned text to a new CSV file\n",
        "output_file_path_cleaned = 'merged_data_all.csv'\n",
        "merged_data_all.to_csv(output_file_path_cleaned, index=False)\n",
        "\n",
        "print(f\"DataFrame saved to {output_file_path_cleaned}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "680cc54f-f403-495a-a2e6-be46399e6552",
      "metadata": {
        "id": "680cc54f-f403-495a-a2e6-be46399e6552"
      },
      "outputs": [],
      "source": [
        "# Sample 500,000 rows from the data\n",
        "merged_data_500 = merged_data_all.sample(n=500000, random_state=42)\n",
        "\n",
        "# Save the sampled data\n",
        "merged_data_500.to_csv('merged_data_500.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffd06726-b554-40a6-b2d7-a309ab991000",
      "metadata": {
        "id": "ffd06726-b554-40a6-b2d7-a309ab991000"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Logistic Regression\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c40ffaf-a30f-41e0-8060-2aedba4ac5bf",
      "metadata": {
        "id": "4c40ffaf-a30f-41e0-8060-2aedba4ac5bf",
        "outputId": "c42e86a8-de18-4a16-dd3b-4e187894bab2",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.78      0.81     75379\n",
            "           1       0.84      0.88      0.86     95473\n",
            "\n",
            "    accuracy                           0.84    170852\n",
            "   macro avg       0.84      0.83      0.83    170852\n",
            "weighted avg       0.84      0.84      0.84    170852\n",
            "\n",
            "[[59081 16298]\n",
            " [11649 83824]]\n",
            "Accuracy: 0.8364256783649007\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# THIS IS WITH NO TRUNCATED APPLIED\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the pipeline with only the Logistic Regression classifier\n",
        "pipeline = Pipeline([\n",
        "    ('logistic', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets\n"
      ],
      "metadata": {
        "id": "1ONhRgA4zS51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "34d79ffe-1708-47e3-8f92-1375f74b7ff4"
      },
      "id": "1ONhRgA4zS51",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.21.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              },
              "id": "666d0779acd545c099da57d074b13316"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import XLNetTokenizer, XLNetForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import DataCollatorWithPadding\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import sentencepiece as spm"
      ],
      "metadata": {
        "id": "9I49BMb8y68u"
      },
      "id": "9I49BMb8y68u",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "id": "GCPu43hy6u3C"
      },
      "id": "GCPu43hy6u3C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "edsBoNr6yqNG"
      },
      "id": "edsBoNr6yqNG",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "QzUZJ7bTy-U0",
        "outputId": "65362ce9-3148-4794-f751-3836f19ca722"
      },
      "id": "QzUZJ7bTy-U0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7750c7ee2c4e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Clear cache\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Reset the GPU memory by clearing the allocated cache and emptying the cache\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "print(\"CUDA memory cleaned.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDYiHA_zjPAh",
        "outputId": "176f0999-8dd6-4a4c-97c2-a98b8e9d5ceb"
      },
      "id": "kDYiHA_zjPAh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA memory cleaned.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "id": "Q3hh9yyQ4q7c"
      },
      "id": "Q3hh9yyQ4q7c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "B6I6IKVG6YQI"
      },
      "id": "B6I6IKVG6YQI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_lengths = [len(tokenizer(text, truncation=False)['input_ids']) for text in df['cleaned_text']]\n",
        "print(f\"Average length: {np.mean(text_lengths)}\")\n",
        "print(f\"Median length: {np.median(text_lengths)}\")\n",
        "print(f\"Max length: {np.max(text_lengths)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO2Iiexm6Xfb",
        "outputId": "5887a5c8-8108-4998-a642-86f5a5ae9d5d"
      },
      "id": "YO2Iiexm6Xfb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average length: 349.83655239971915\n",
            "Median length: 207.0\n",
            "Max length: 51368\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "468cd797",
      "metadata": {
        "id": "468cd797"
      },
      "source": [
        "# xlNET TAKES TOO LONG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8837a810",
      "metadata": {
        "id": "8837a810",
        "outputId": "81dc80e2-e818-4e30-c28f-cd80779effce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604,
          "referenced_widgets": [
            "56d54a932b074238b9d335af9544720a",
            "300424c9062a4d63b4611fcc0f23bba0",
            "2d829b285d7b4349bd979d24a4caefc1",
            "47d5e46702d94a139669d3995b962730",
            "8fa5b74b00aa4575b79bd1a382bd5e47",
            "81a9028a3465402a9e1963f62f30b47e",
            "d127678ac43747ffa61086ca8ef600cf",
            "ac14de2e8f8f4c0984fa9ad73f01cb76",
            "a71aa329cd664e1a8f0319b7f75fcc01",
            "e87bac90e3a74f1d93d21da3e13f9a6e",
            "0fde597e90464d58a20dafd322964690",
            "1e52161416ca4d988bfe0410d8c5dac7",
            "aa8ba78d95f2451993dc42cdbbcae38f",
            "4c2332fb6601484e8f8290aa9a5eade2",
            "f3bf3ba764ee4e558a04da58d34eacbb",
            "26f42b53a58e4830b788b5fc8ded6c95",
            "9a31a7fc6ec644b4a7033c3a260e9c1d",
            "3432b5d89d414095b3ef62c05ce1b792",
            "9ede36b99f21404ca094b63df27b0fb1",
            "ec0facd592954ddba8094ebb618a588f",
            "7cfe744029ac4baa83f32e826704cc06",
            "1ef5c361847a46a5b867d0fd94fcc3a3"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56d54a932b074238b9d335af9544720a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/63576 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e52161416ca4d988bfe0410d8c5dac7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7064 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='865' max='9930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 865/9930 28:24 < 4:58:25, 0.51 it/s, Epoch 0.87/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9930' max='9930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9930/9930 5:42:31, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.226200</td>\n",
              "      <td>0.217064</td>\n",
              "      <td>0.899349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.146400</td>\n",
              "      <td>0.317559</td>\n",
              "      <td>0.881795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.107100</td>\n",
              "      <td>0.359530</td>\n",
              "      <td>0.881087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.102000</td>\n",
              "      <td>0.320536</td>\n",
              "      <td>0.912373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.028700</td>\n",
              "      <td>0.460678</td>\n",
              "      <td>0.906569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.037400</td>\n",
              "      <td>0.414491</td>\n",
              "      <td>0.906144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.012000</td>\n",
              "      <td>0.443150</td>\n",
              "      <td>0.906002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.013000</td>\n",
              "      <td>0.429702</td>\n",
              "      <td>0.911665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.009900</td>\n",
              "      <td>0.496155</td>\n",
              "      <td>0.913364</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=9930, training_loss=0.0832274560733114, metrics={'train_runtime': 20553.4133, 'train_samples_per_second': 30.932, 'train_steps_per_second': 0.483, 'total_flos': 8.782834314126418e+16, 'train_loss': 0.0832274560733114, 'epoch': 9.996224990562476})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import XLNetTokenizer, XLNetForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "# Assuming you have a DataFrame `df` with columns 'cleaned_text' and 'label'\n",
        "X = balanced_dataset['cleaned_text']\n",
        "y = balanced_dataset['label']\n",
        "\n",
        "# Combine them into a single DataFrame if not already combined\n",
        "df_combined = pd.DataFrame({'text': X, 'label': y})\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_df, test_df = train_test_split(df_combined, test_size=0.1, random_state=42, stratify=df_combined['label'])\n",
        "\n",
        "# Convert to Hugging Face Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
        "\n",
        "# Tokenize the dataset with a reduced sequence length and dynamic padding\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples['text'],\n",
        "        truncation=True,   # Truncate sequences longer than max_length\n",
        "        padding=False,     # Padding will be handled dynamically later\n",
        "        max_length=256     # Cap sequences at 256 tokens\n",
        "    )\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Data collator to dynamically pad the input sequences\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Load the pretrained XLNet model\n",
        "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=2)\n",
        "\n",
        "# Move the model to the device (GPU/CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Load the accuracy metric from the datasets library\n",
        "accuracy_metric = load_metric(\"accuracy\")\n",
        "\n",
        "# Define compute metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "    return {\"eval_accuracy\": accuracy}\n",
        "\n",
        "# Define training arguments with progress tracking and GPU/CPU usage\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy='epoch',  # Evaluate every epoch\n",
        "    save_strategy='epoch',  # Save the model every epoch\n",
        "    per_device_train_batch_size=4,  # Minimized batch size\n",
        "    per_device_eval_batch_size=4,   # Minimized batch size\n",
        "    gradient_accumulation_steps=16,  # Further increase gradient accumulation steps\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',  # Directory for storing logs\n",
        "    logging_steps=10,  # Log every 10 steps\n",
        "    save_total_limit=3,  # Only keep the last 3 checkpoints\n",
        "    load_best_model_at_end=True,  # Load the best model when finished\n",
        "    metric_for_best_model=\"eval_accuracy\",  # Use eval_accuracy as the metric for selecting the best model\n",
        "    logging_first_step=True,\n",
        "    report_to=\"tensorboard\",  # Report to TensorBoard\n",
        "    fp16=True,  # Enable mixed precision training for faster training (if supported by GPU)\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,  # Use the dynamic padding collator\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import XLNetTokenizer, XLNetForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "# Assuming you have a DataFrame `df` with columns 'cleaned_text' and 'label'\n",
        "X = balanced_dataset['cleaned_text']\n",
        "y = balanced_dataset['label']\n",
        "\n",
        "# Combine them into a single DataFrame if not already combined\n",
        "df_combined = pd.DataFrame({'text': X, 'label': y})\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_df, test_df = train_test_split(df_combined, test_size=0.1, random_state=42, stratify=df_combined['label'])\n",
        "\n",
        "# Convert to Hugging Face Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
        "\n",
        "# Tokenize the dataset with a reduced sequence length and dynamic padding\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples['text'],\n",
        "        truncation=True,   # Truncate sequences longer than max_length\n",
        "        padding=False,     # Padding will be handled dynamically later\n",
        "        max_length=256     # Cap sequences at 256 tokens\n",
        "    )\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Data collator to dynamically pad the input sequences\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Load the pretrained XLNet model\n",
        "model = XLNetForSequenceClassification.from_pretrained('xlnet-large-cased', num_labels=2)\n",
        "\n",
        "# Move the model to the device (GPU/CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Load the accuracy metric from the datasets library\n",
        "accuracy_metric = load_metric(\"accuracy\")\n",
        "\n",
        "# Define compute metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "    return {\"eval_accuracy\": accuracy}\n",
        "\n",
        "# Define training arguments with progress tracking and GPU/CPU usage\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy='epoch',  # Evaluate every epoch\n",
        "    save_strategy='epoch',  # Save the model every epoch\n",
        "    per_device_train_batch_size=8,  # Minimized batch size\n",
        "    per_device_eval_batch_size=8,   # Minimized batch size\n",
        "    gradient_accumulation_steps=16,  # Further increase gradient accumulation steps\n",
        "    num_train_epochs=15,\n",
        "    warmup_steps=500,\n",
        "    early_stopping_patience=3,\n",
        "    weight_decay=0.02,\n",
        "    logging_dir='./logs',  # Directory for storing logs\n",
        "    logging_steps=10,  # Log every 10 steps\n",
        "    save_total_limit=3,  # Only keep the last 3 checkpoints\n",
        "    load_best_model_at_end=True,  # Load the best model when finished\n",
        "    metric_for_best_model=\"eval_accuracy\",  # Use eval_accuracy as the metric for selecting the best model\n",
        "    logging_first_step=True,\n",
        "    report_to=\"tensorboard\",  # Report to TensorBoard\n",
        "    fp16=True,  # Enable mixed precision training for faster training (if supported by GPU)\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,  # Use the dynamic padding collator\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "GTz683aVJm18"
      },
      "id": "GTz683aVJm18",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "H9w1OfthsWdX"
      },
      "id": "H9w1OfthsWdX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import XLNetTokenizer, XLNetForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "# Assuming you have a DataFrame `df` with columns 'cleaned_text' and 'label'\n",
        "X = balanced_dataset['cleaned_text']\n",
        "y = balanced_dataset['label']\n",
        "\n",
        "# Combine them into a single DataFrame if not already combined\n",
        "df_combined = pd.DataFrame({'text': X, 'label': y})\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_df, test_df = train_test_split(df_combined, test_size=0.1, random_state=42, stratify=df_combined['label'])\n",
        "\n",
        "# Convert to Hugging Face Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
        "\n",
        "# Tokenize the dataset with a reduced sequence length and dynamic padding\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples['text'],\n",
        "        truncation=True,   # Truncate sequences longer than max_length\n",
        "        padding=False,     # Padding will be handled dynamically later\n",
        "        max_length=256     # Cap sequences at 256 tokens\n",
        "    )\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Data collator to dynamically pad the input sequences\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Load the pretrained XLNet model\n",
        "model = XLNetForSequenceClassification.from_pretrained('xlnet-large-cased', num_labels=2)\n",
        "\n",
        "# Move the model to the device (GPU/CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Load the accuracy metric from the datasets library\n",
        "accuracy_metric = load_metric(\"accuracy\")\n",
        "\n",
        "# Define compute metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "    return {\"eval_accuracy\": accuracy}\n",
        "\n",
        "\n",
        "learning_rates = [1e-5, 3e-5, 5e-5, 1e-4]\n",
        "best_accuracy = 0\n",
        "best_lr = None\n",
        "\n",
        "for lr in learning_rates:\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./results',\n",
        "        evaluation_strategy='epoch',\n",
        "        save_strategy='epoch',\n",
        "        per_device_train_batch_size=4,\n",
        "        per_device_eval_batch_size=4,\n",
        "        gradient_accumulation_steps=16,\n",
        "        num_train_epochs=5,\n",
        "        weight_decay=0.01,\n",
        "        learning_rate=lr,  # Set learning rate here\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=10,\n",
        "        save_total_limit=3,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"eval_accuracy\",\n",
        "        logging_first_step=True,\n",
        "        report_to=\"tensorboard\",\n",
        "        fp16=True,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=test_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate the model\n",
        "    eval_result = trainer.evaluate()\n",
        "    accuracy = eval_result['eval_accuracy']\n",
        "\n",
        "    print(f\"Learning Rate: {lr}, Accuracy: {accuracy}\")\n",
        "\n",
        "    # Track the best learning rate\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_lr = lr\n",
        "\n",
        "print(f\"Best Learning Rate: {best_lr}, Best Accuracy: {best_accuracy}\")"
      ],
      "metadata": {
        "id": "mzB05FTQsvAF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643,
          "referenced_widgets": [
            "051f6f95d0bc4075b15fd0fbe44f9f6e",
            "9cfba44e99eb4d7eb368a2151516d17c",
            "113a740b8a9d4b559235174ed7df3c17",
            "7a754a0f3a0144d2a9c8c0d908df0144",
            "279f06e1dc1f4d6798227e02cae5f7ad",
            "b342b16693e24e8cbb103b59d47150b2",
            "22b12b3e368946c6ae8617add152fe92",
            "0bbec1ca26864c72ab932deeffb8414a",
            "4833a3fc1aec47adadb9a873c64426bc",
            "f7705600b1304affbc48dcd02f2deb61",
            "771c3c680dd74b9aaadbd7b13c1af17d",
            "a2f5ca2e5270474e9766bc108b561a25",
            "8f9bbbdc6fec4b2b83637cf9bb6b8415",
            "7d97be5ddf994d469506301d60fcbc80",
            "3b9bc23f56e0445e8305b8e468307c1b",
            "2a437e852bb74d4187869b3a5222a236",
            "44f7472ac1c1446586068598630084d1",
            "6606eaa648894695beb9128d4a9886a0",
            "57dbb3ff589a4a7eaea293f4acf97bd2",
            "e81712f25802456c9af8c135ae183445",
            "0cbe1ad975064104bb86649f391c815b",
            "d4705b6e987b47ce8b587502c15ba2ff",
            "c595fd8396fc4c628d11dd51f3878363",
            "b194de094deb4ca2a656244d0d80027b",
            "0b2b2e28ad00405eb9210a08ce9ace7e",
            "f548d35d3b274f768408f4731d12c64f",
            "43bc1a417b444cd7928ad7c6ae4e966b",
            "7b3ebdbca6ed4b14b0ebc18b327953d9",
            "0ccb0925ff7f42b08409e5bed03fc325",
            "75f4d9d1cdae4773bef551611b3c19ba",
            "21f6cd67825a476e8689cf810e94ade5",
            "dd01d9ebd11042dba38866a5eb648969",
            "d5674fe6307448c5b3f2e7ffbbc275b0",
            "b60f50c9a5024c1fa1b618057a5b0d0b",
            "dbdd3d51845c4757a91a98f0abc635f3",
            "d2a39df0acb64207bc9964a668eca6ac",
            "ab7e9b5e06894389bf3dab2873f9e067",
            "cef0b17c3b924cbfbeeef0f398782054",
            "b458ddd10907480898c4f12dd2c51f24",
            "433c7550b5ee4536ae11e948751cc23a",
            "aa01f398e02b4e2f9e5a60137a4f10e8",
            "443b95b167684d7cafde7d43eb49f2ea",
            "d827f92f326347699e7b80a8d7efd85f",
            "ef9cb782290e4e3e9e7e8e9df0030b7e",
            "208dac8324d04d44922a1e9eb419ca32",
            "06fd856dc6314ac38238ccc869c13de4",
            "43b6a46304364c8c9a197c8c9587e74a",
            "0f598a817cc74a80bd65804e3432532d",
            "6c95770a33324be5926b988f00adadb8",
            "25f96651ce6145cbb83f572270a5055b",
            "3b5e941e08b0412081db17818c593bd8",
            "d0f4d6c72f574928bdd21acf73715925",
            "f905691ad7314f4b975990354b01e5b0",
            "78453f9ec04744d1b378977e9fa42457",
            "e87ac7f82102475c86382bc1e0c3dd8e",
            "e0a2a5c238434843a26289a44e90cbcd",
            "0a7be706443f4c609702a6dec907f3fc",
            "058026b532ce4276849f821ec730f3ec",
            "6b221024391e425ea8634f6fba4212fa",
            "fe944585869a4f8fb2ba7e74f8e68c77",
            "9a8d23c350ac454896ad857c1e8b4b47",
            "b14fe64ce3e44f99abd2422d2d4cd244",
            "ca0f8990a86d4b6c8ae69393fd1c568b",
            "a38cad1c6cfe4f848a25e72bd739a2ab",
            "95f5e85270134e35adefedf15da40f97",
            "37925af2c0dc489b91958ea70dabc064",
            "f361bb07700a43a7aad56ff6cf81b90a",
            "ae667cc02f9b4f55b0b0707456740626",
            "d0cc41dcf2ae435998bf440e548c1093",
            "eada422a68c2403795b0f3b3a3e7b76a",
            "4da96d097d4b45f38dcb501d0449ee10",
            "5c87bd0b61434a07bce3adeb8e1d3a43",
            "04b39d8d11614b5fa34bff17f7a8ea57",
            "fb3c8bc7ebc741259d0ef38d159a3226",
            "199888a38ae2457db9012d9965982ab3",
            "b3db1f12017948458275a601a0fee8d4",
            "98fa3ed1d90748fc9f59f74120fa32a9",
            "19f6c2b80db841c8bde00dbcebc3aa3b",
            "334caf88212c4836b5abb557ef593492",
            "1d74c30a97244cf592f9914ac4a7c5f7",
            "9cbb19e62a8e4a39a9d7340a78b8816f",
            "717b7ba20cde401ead438cdb8c53568d",
            "394a15a25b7b4dbfac7332d43d8bde43",
            "be6f5958b0a84705a3990c1aa67a1865",
            "806170a8becc499ea5617b5e7b12cfb2",
            "6f78d595a3eb430387fc1d70d114b70f",
            "840ae742c7764be7a8ad8f5259434334",
            "8f70b5641a984abba7bdf1e4055738a3"
          ]
        },
        "outputId": "585cc35a-e77f-4c8b-8dc3-32d9ba8428b3"
      },
      "id": "mzB05FTQsvAF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "051f6f95d0bc4075b15fd0fbe44f9f6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2f5ca2e5270474e9766bc108b561a25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c595fd8396fc4c628d11dd51f3878363"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/26490 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b60f50c9a5024c1fa1b618057a5b0d0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2944 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "208dac8324d04d44922a1e9eb419ca32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/761 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0a2a5c238434843a26289a44e90cbcd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.44G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f361bb07700a43a7aad56ff6cf81b90a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-large-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-12-64eadd358e7f>:49: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  accuracy_metric = load_metric(\"accuracy\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19f6c2b80db841c8bde00dbcebc3aa3b"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for accuracy contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/accuracy.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:482: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='39' max='2065' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  39/2065 01:38 < 1:29:40, 0.38 it/s, Epoch 0.09/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "VaAO9eiGrmw3"
      },
      "id": "VaAO9eiGrmw3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from transformers import XLNetTokenizer, XLNetForSequenceClassification, Trainer\n",
        "\n",
        "\n",
        "# Step 2: Define the output directory in Google Drive\n",
        "output_dir = '/content/drive/MyDrive/xlnet_model'\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Assuming you have your `trainer`, `model`, and `tokenizer` already defined\n",
        "\n",
        "# Save the model and tokenizer after training\n",
        "trainer.save_model(output_dir)  # Saves the model to the specified directory\n",
        "tokenizer.save_pretrained(output_dir)  # Save the tokenizer to the same directory\n",
        "\n",
        "print(f\"Model and tokenizer saved to {output_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "qQe0gr4nqw9W",
        "outputId": "de750757-9631-4fe8-b4ed-cb64d9484a81"
      },
      "id": "qQe0gr4nqw9W",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'trainer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-0af417e092cd>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Save the model and tokenizer after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Saves the model to the specified directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Save the tokenizer to the same directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hj7Wh-qaqhqA"
      },
      "id": "hj7Wh-qaqhqA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure this is run before training\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "E7IkD9PLV7KR"
      },
      "id": "E7IkD9PLV7KR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,  # Pass the compute_metrics function\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "Gbh3nqtUV8uv",
        "outputId": "3f931541-efe5-4fbf-db01-a8779acf143f"
      },
      "id": "Gbh3nqtUV8uv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='28338' max='59601' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [28338/59601 13:05:38 < 14:26:48, 0.60 it/s, Epoch 1.43/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.647300</td>\n",
              "      <td>0.755014</td>\n",
              "      <td>0.499986</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-42428066ed14>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1933\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2267\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3322\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3324\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3326\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2145\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2146\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2148\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_lomo_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "\n",
        "# Convert the DataFrame to a Hugging Face Dataset\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "# Determine the number of entries per label\n",
        "label_counts = df['label'].value_counts()\n",
        "third_count = label_counts // 12  # Get one-third of the entries for each label\n",
        "\n",
        "# Define a function to filter the dataset\n",
        "def filter_balanced(dataset, third_count):\n",
        "    filtered_data = []\n",
        "    counts = {label: 0 for label in third_count.index}\n",
        "\n",
        "    for entry in dataset:\n",
        "        label = entry['label']\n",
        "        if counts[label] < third_count[label]:\n",
        "            filtered_data.append(entry)\n",
        "            counts[label] += 1\n",
        "        # Stop early if we have enough entries for each label\n",
        "        if all(count == third_count[label] for label, count in counts.items()):\n",
        "            break\n",
        "\n",
        "    return Dataset.from_list(filtered_data)\n",
        "\n",
        "# Apply the filter\n",
        "balanced_dataset = filter_balanced(dataset, third_count)\n",
        "\n",
        "# Inspect the balanced Dataset\n",
        "print(balanced_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2Y-YcREQshu",
        "outputId": "aef419d3-f0e7-48fe-ff84-886c41099b5d"
      },
      "id": "x2Y-YcREQshu",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'label', 'cleaned_text'],\n",
            "    num_rows: 29434\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import XLNetTokenizer, XLNetForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "# Load the dataset (assuming 'balanced_dataset' is already defined)\n",
        "X = balanced_dataset['cleaned_text']\n",
        "y = balanced_dataset['label']\n",
        "\n",
        "# Combine them into a single DataFrame\n",
        "df_combined = pd.DataFrame({'text': X, 'label': y})\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_df, test_df = train_test_split(df_combined, test_size=0.1, random_state=42, stratify=df_combined['label'])\n",
        "\n",
        "# Convert to Hugging Face Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
        "\n",
        "# Tokenize the dataset with a reduced sequence length and dynamic padding\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples['text'],\n",
        "        truncation=True,   # Truncate sequences longer than max_length\n",
        "        padding=False,     # Padding will be handled dynamically later\n",
        "        max_length=256     # Cap sequences at 256 tokens\n",
        "    )\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Data collator to dynamically pad the input sequences\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Load the pretrained XLNet model\n",
        "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=2)\n",
        "\n",
        "# Load the accuracy metric from the datasets library\n",
        "accuracy_metric = load_metric(\"accuracy\")\n",
        "\n",
        "# Define compute metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "    return {\"eval_accuracy\": accuracy}\n",
        "\n",
        "# List of learning rates to try\n",
        "learning_rates = [1e-5, 3e-5, 5e-5, 1e-4]\n",
        "best_accuracy = 0\n",
        "best_lr = None\n",
        "\n",
        "# Loop over the learning rates\n",
        "for lr in learning_rates:\n",
        "    # Define the training arguments with the current learning rate\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./results',\n",
        "        evaluation_strategy='epoch',  # Evaluate every epoch\n",
        "        save_strategy='epoch',  # Save the model every epoch\n",
        "        per_device_train_batch_size=8,  # Batch size per device\n",
        "        per_device_eval_batch_size=8,   # Evaluation batch size per device\n",
        "        gradient_accumulation_steps=16,  # Gradient accumulation steps\n",
        "        num_train_epochs=5,  # Number of epochs\n",
        "        weight_decay=0.01,  # Weight decay for regularization\n",
        "        learning_rate=lr,  # Current learning rate\n",
        "        logging_dir='./logs',  # Directory for storing logs\n",
        "        logging_steps=10,  # Log every 10 steps\n",
        "        save_total_limit=3,  # Only keep the last 3 checkpoints\n",
        "        load_best_model_at_end=True,  # Load the best model at the end\n",
        "        metric_for_best_model=\"eval_accuracy\",  # Use eval_accuracy as the metric for the best model\n",
        "        logging_first_step=True,\n",
        "        report_to=\"tensorboard\",  # Report to TensorBoard\n",
        "        fp16=True,  # Enable mixed precision training\n",
        "    )\n",
        "\n",
        "    # Initialize the Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=test_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate the model\n",
        "    eval_result = trainer.evaluate()\n",
        "    accuracy = eval_result['eval_accuracy']\n",
        "\n",
        "    print(f\"Learning Rate: {lr}, Accuracy: {accuracy}\")\n",
        "\n",
        "    # Track the best learning rate and accuracy\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_lr = lr\n",
        "\n",
        "# Output the best learning rate and accuracy\n",
        "print(f\"Best Learning Rate: {best_lr}, Best Accuracy: {best_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "35938cac89a64355afd3e9c0a0820529",
            "aae76d1556274628b97a97c0976b7a45",
            "fe373c3f404c4d9186a4733cedf2f422",
            "f7f55e62e80647f6bbbe461de397313e",
            "c37c3183828e4296a4033aef3aaea032",
            "135bbea15bdd4235ab7e439fd83d787c",
            "6f0c1870662d41cfaa76750c11945c60",
            "a7c4461556a84746b8ac8bc3b4943018",
            "05e7c77cfd44449281afb4e599c89279",
            "1993e7a3ad7f4b2d8b9529d7918a2d11",
            "3467f41520574c9487fe1e863d2a5d0e",
            "11032b328ba44545862cac11bd09d9fd",
            "3e5379af6a9a465ba9bffc68adb80d0e",
            "b441ea8e286140578743ecf6b1e5b918",
            "e7f64f3ef4f948209daf2e1eb5c9e513",
            "69a7d39f43b64fa588cd5206c5501e70",
            "190e41579f514eea93abfa952d0bdac5",
            "55ebf9110b0a4ce29e70096e44d17b5e",
            "58cfb3708bd748a098051af112dc5e74",
            "d5c5d19de2aa400b8574c6cb005beb5c",
            "43a11ea696bc4a9585f416815ed8e23e",
            "d3c601cd9e114ff880ab15b954a4d045",
            "3c28060d60064054b50b4cf7d693365a",
            "24b8b21be9354525bbb481346f6c8a74",
            "8c70855b10234f1a8cfd0fea3533e51a",
            "1edbd8a2d30f4a399762442b2d7eac20",
            "3a686e0897894c5eba60e9fd77658d0a",
            "9664b04f10654ae1bbc8a3188ecc8576",
            "4a798ab0be704fd8a7902a4038185fb5",
            "43a2758ff46641bf8843a718dd6e8780",
            "7212dfcdf3624b98a723a109f812b4f4",
            "a238904a196a4aa4bd2a578c8c792f74",
            "dc78c7030e1f478cadc0c08846a6ecb7",
            "eff5ebe2fd6e47c48efea6be25c2318a",
            "e6a2e82b4fa8412d987435bd227f4721",
            "f42ee34da4404743b414065c6c80782a",
            "2204baa514384f618c04968ad2c77521",
            "03f03292546448938a8e02dd454e1b21",
            "c22a63d44e80444ab25ffaf382dcf9af",
            "32a587a41aba4107a0a6ba27e6acd87a",
            "977f2a9dec3b40faa5a8b0f4cccc8a7d",
            "25c631e86cfe4ed88ae2ff1999da053f",
            "5eb78ac5fc6b449f87adda1f096f06a6",
            "30e0037bfbad4c36946a35fcd6810331",
            "7a359f6143b941169fcc535c93a9bf96",
            "9b504d24985e4d5485b8179b34d7e09c",
            "db3d15ec8de64b939ca5a086e5c9f856",
            "42a54b262c904e0584262ba799fd43f9",
            "dbc70204c68943698c7cb9c24961a9db",
            "a3748376194c4ce198e82b49b0c2948d",
            "c51ce32380bb47f4af50e14a7ac277e2",
            "909502e699604091b504249988ea6b40",
            "76535d4f7f8e411386440e6707cc5287",
            "9625a8c3c17d485586618cfc699e7961",
            "50aa4ff23893498591d2b9c6df8e1607",
            "5c5ab3715a5843c9988d7331d2295059",
            "45f0f0cd28844a74abf99ab3156e479d",
            "3bbc466660a04695bf8a658f05a9d073",
            "db7860b9419744ce89c2d958b10b0c67",
            "1d517f263a9c42f595231728e3d0d831",
            "2b3770c1c6934279ae153773122cdf81",
            "a9f5771555e44a188ee8d59ff3028109",
            "7706b766e4bb4490873fbe42ffedbb2d",
            "31c05c6cad4148f7a1d78c40feeaad30",
            "9e1a30c1849b4cdd9fbe23968787d440",
            "4c069415bd0e4455b61b4301f84e17a8",
            "6048b8d7bb994a5c8d1a30db9e360990",
            "169c34bebc374ba0affa1344329b5c3f",
            "0268ee428d6f4c58a58a03669a1d3b87",
            "2083781d01874c1d83d28c5e251bbb19",
            "f0ef7bc4987f45aaaaaa98ce32863507",
            "efa4cd5988e8452e92f680d74e1f3494",
            "850ed8dcd81e46c59308ece90e75ce26",
            "6c1d2f5f0b49423d9f0dc754af5c42e4",
            "55321cad3ca74037bfedbc4d8a4b9e4b",
            "3c0a05cd53f041bf8ca458113a2307bc",
            "ffdac3cdfb5d4024a1c459b51358c3d2"
          ]
        },
        "id": "B8dOVTR_uicX",
        "outputId": "daead273-7b70-44c6-955c-8b4687395720"
      },
      "id": "B8dOVTR_uicX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35938cac89a64355afd3e9c0a0820529"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11032b328ba44545862cac11bd09d9fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c28060d60064054b50b4cf7d693365a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/39735 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eff5ebe2fd6e47c48efea6be25c2318a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4415 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a359f6143b941169fcc535c93a9bf96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c5ab3715a5843c9988d7331d2295059"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-12-24e0652093fe>:45: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  accuracy_metric = load_metric(\"accuracy\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6048b8d7bb994a5c8d1a30db9e360990"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for accuracy contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/accuracy.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:482: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1550' max='1550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1550/1550 1:53:44, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.290400</td>\n",
              "      <td>0.353249</td>\n",
              "      <td>0.832616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.261400</td>\n",
              "      <td>0.447899</td>\n",
              "      <td>0.829898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.203900</td>\n",
              "      <td>0.395889</td>\n",
              "      <td>0.853907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.172500</td>\n",
              "      <td>0.406878</td>\n",
              "      <td>0.859117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.129900</td>\n",
              "      <td>0.443165</td>\n",
              "      <td>0.861608</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='552' max='552' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [552/552 01:17]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning Rate: 1e-05, Accuracy: 0.861608154020385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:482: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1550' max='1550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1550/1550 1:53:37, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.172800</td>\n",
              "      <td>0.476981</td>\n",
              "      <td>0.836920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.134900</td>\n",
              "      <td>0.486621</td>\n",
              "      <td>0.857758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.061400</td>\n",
              "      <td>0.671406</td>\n",
              "      <td>0.852548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.062400</td>\n",
              "      <td>0.587283</td>\n",
              "      <td>0.873160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.027100</td>\n",
              "      <td>0.638738</td>\n",
              "      <td>0.883126</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='552' max='552' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [552/552 01:17]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning Rate: 3e-05, Accuracy: 0.8831257078142696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:482: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1550' max='1550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1550/1550 1:53:19, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.075500</td>\n",
              "      <td>0.441339</td>\n",
              "      <td>0.890600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.065700</td>\n",
              "      <td>0.439725</td>\n",
              "      <td>0.896716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.023200</td>\n",
              "      <td>0.698267</td>\n",
              "      <td>0.873613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.031000</td>\n",
              "      <td>0.730243</td>\n",
              "      <td>0.879728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.009300</td>\n",
              "      <td>0.837968</td>\n",
              "      <td>0.881993</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='552' max='552' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [552/552 01:17]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning Rate: 5e-05, Accuracy: 0.8967157417893544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:482: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1550' max='1550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1550/1550 1:53:07, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.117200</td>\n",
              "      <td>0.465437</td>\n",
              "      <td>0.872027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.094700</td>\n",
              "      <td>0.583748</td>\n",
              "      <td>0.865232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.048600</td>\n",
              "      <td>0.371200</td>\n",
              "      <td>0.914609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.016000</td>\n",
              "      <td>0.510500</td>\n",
              "      <td>0.910306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.002600</td>\n",
              "      <td>0.641578</td>\n",
              "      <td>0.897395</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='552' max='552' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [552/552 01:17]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning Rate: 0.0001, Accuracy: 0.9146092865232163\n",
            "Best Learning Rate: 0.0001, Best Accuracy: 0.9146092865232163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52ae4d6f-9060-48e0-a06e-abef8501e8df",
      "metadata": {
        "id": "52ae4d6f-9060-48e0-a06e-abef8501e8df",
        "outputId": "30c45c9e-6cd2-45bf-db56-727ae503034a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.81      0.86     75379\n",
            "           1       0.86      0.94      0.90     95473\n",
            "\n",
            "    accuracy                           0.88    170852\n",
            "   macro avg       0.88      0.87      0.88    170852\n",
            "weighted avg       0.88      0.88      0.88    170852\n",
            "\n",
            "[[60861 14518]\n",
            " [ 6079 89394]]\n",
            "Accuracy: 0.8794453679207735\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define and train the Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Random Forest Results:\")# Random Forest\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdcfe2f4-cf35-4127-9a30-9e1e35e81de9",
      "metadata": {
        "id": "cdcfe2f4-cf35-4127-9a30-9e1e35e81de9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import XLNetTokenizer, XLNetForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import DataCollatorWithPadding\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your dataset (assuming it is already loaded as df)\n",
        "# df = pd.read_csv('your_file.csv')  # Uncomment if you need to load the dataset\n",
        "\n",
        "# Ensure all text in 'cleaned_text' column is of type string\n",
        "df['cleaned_text'] = df['cleaned_text'].astype(str)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.1, random_state=42, stratify=df['label'])\n",
        "\n",
        "# Convert to Hugging Face Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
        "\n",
        "# Define max_length\n",
        "MAX_LENGTH = 512\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['cleaned_text'], truncation=True, padding=True, max_length=MAX_LENGTH)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Data collator to dynamically pad the input sequences\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Load the pretrained XLNet model\n",
        "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=2)\n",
        "model.to(device)  # Move the model to the device (GPU/CPU)\n",
        "\n",
        "# Define training arguments with progress tracking and GPU/CPU usage\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy='epoch',  # Already set to 'epoch'\n",
        "    save_strategy='epoch',        # Align save strategy\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    save_total_limit=3,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    logging_first_step=True,\n",
        "    report_to=\"tensorboard\",\n",
        "    fp16=True,\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "results = trainer.evaluate()\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81417da3-bb46-4f63-b455-13bd881fdefb",
      "metadata": {
        "id": "81417da3-bb46-4f63-b455-13bd881fdefb"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV\n",
        "params = {'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 10, 20]}\n",
        "\n",
        "dt = GridSearchCV(DecisionTreeClassifier(), params, cv=5)\n",
        "dt.fit(X_train, y_train)\n",
        "evaluate_model(dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "259664db-5dd9-4e0a-96b2-f9c7261388aa",
      "metadata": {
        "id": "259664db-5dd9-4e0a-96b2-f9c7261388aa",
        "outputId": "7094c4af-6569-4284-e159-e215d44af891"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Boosting Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.58      0.70     75379\n",
            "           1       0.74      0.94      0.83     95473\n",
            "\n",
            "    accuracy                           0.78    170852\n",
            "   macro avg       0.81      0.76      0.76    170852\n",
            "weighted avg       0.80      0.78      0.77    170852\n",
            "\n",
            "[[43742 31637]\n",
            " [ 5866 89607]]\n",
            "Accuracy: 0.7804942289232786\n"
          ]
        }
      ],
      "source": [
        "# Gradient Boosting\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Define and train the Gradient Boosting model\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Gradient Boosting Results:\")\n",
        "print(classification_report(y_test, y_pred_gb))\n",
        "print(confusion_matrix(y_test, y_pred_gb))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_gb)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfbde7d4-d0e2-47bb-a16e-a048e771b2e3",
      "metadata": {
        "id": "bfbde7d4-d0e2-47bb-a16e-a048e771b2e3",
        "outputId": "f2315bed-d000-4511-db3e-ac5018a02d62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.68      0.70     75379\n",
            "           1       0.76      0.80      0.78     95473\n",
            "\n",
            "    accuracy                           0.75    170852\n",
            "   macro avg       0.74      0.74      0.74    170852\n",
            "weighted avg       0.75      0.75      0.75    170852\n",
            "\n",
            "[[50887 24492]\n",
            " [18758 76715]]\n",
            "Accuracy: 0.746856928803877\n"
          ]
        }
      ],
      "source": [
        "# Naive Bayes\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Define and train the Naive Bayes model\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Naive Bayes Results:\")\n",
        "print(classification_report(y_test, y_pred_nb))\n",
        "print(confusion_matrix(y_test, y_pred_nb))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_nb)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "767377cc-d044-4ac1-ad11-204eb83b41ec",
      "metadata": {
        "id": "767377cc-d044-4ac1-ad11-204eb83b41ec",
        "outputId": "493497af-34f1-442e-f906-b130cfa059f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k-NN Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.89      0.79     75379\n",
            "           1       0.89      0.72      0.79     95473\n",
            "\n",
            "    accuracy                           0.79    170852\n",
            "   macro avg       0.80      0.80      0.79    170852\n",
            "weighted avg       0.81      0.79      0.79    170852\n",
            "\n",
            "[[67064  8315]\n",
            " [27029 68444]]\n",
            "Accuracy: 0.7931308969166296\n"
          ]
        }
      ],
      "source": [
        "# knn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Define and train the k-NN model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_knn = knn_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"k-NN Results:\")\n",
        "print(classification_report(y_test, y_pred_knn))\n",
        "print(confusion_matrix(y_test, y_pred_knn))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_knn)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23906249-37b6-4564-8e42-fa080d29410e",
      "metadata": {
        "id": "23906249-37b6-4564-8e42-fa080d29410e"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Define and train the XGBoost model\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"XGBoost Results:\")\n",
        "print(classification_report(y_test, y_pred_xgb))\n",
        "print(confusion_matrix(y_test, y_pred_xgb))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_xgb)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79cce252-8a18-480e-b4e3-c323a1f03609",
      "metadata": {
        "id": "79cce252-8a18-480e-b4e3-c323a1f03609"
      },
      "outputs": [],
      "source": [
        "# SAME AS TENSORFLOW\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Define and train the Neural Network model\n",
        "mlp_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
        "mlp_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_mlp = mlp_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Neural Network Results:\")\n",
        "print(classification_report(y_test, y_pred_mlp))\n",
        "print(confusion_matrix(y_test, y_pred_mlp))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_mlp)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1187b7f6-4eba-490c-bf58-0a97fbd3639b",
      "metadata": {
        "id": "1187b7f6-4eba-490c-bf58-0a97fbd3639b"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Define and train the AdaBoost model\n",
        "ada_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "ada_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_ada = ada_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"AdaBoost Results:\")\n",
        "print(classification_report(y_test, y_pred_ada))\n",
        "print(confusion_matrix(y_test, y_pred_ada))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_ada)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49dd707d-048a-42e4-a2b4-55a547508ab0",
      "metadata": {
        "id": "49dd707d-048a-42e4-a2b4-55a547508ab0"
      },
      "outputs": [],
      "source": [
        "#  do not rUN\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Define and train the SVM model\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"SVM Results:\")\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "print(confusion_matrix(y_test, y_pred_svm))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "960bc742-60d0-4165-86ca-0d68c977f64c",
      "metadata": {
        "id": "960bc742-60d0-4165-86ca-0d68c977f64c",
        "outputId": "59ea9c58-1c0c-4df6-8088-fa691ce25846"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8051 - loss: 0.3844 - val_accuracy: 0.8695 - val_loss: 0.2707\n",
            "Epoch 2/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8880 - loss: 0.2465 - val_accuracy: 0.8829 - val_loss: 0.2502\n",
            "Epoch 3/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.1992 - val_accuracy: 0.8874 - val_loss: 0.2439\n",
            "Epoch 4/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9296 - loss: 0.1686 - val_accuracy: 0.8893 - val_loss: 0.2485\n",
            "Epoch 5/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9391 - loss: 0.1465 - val_accuracy: 0.8930 - val_loss: 0.2502\n",
            "Epoch 6/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9483 - loss: 0.1280 - val_accuracy: 0.8939 - val_loss: 0.2533\n",
            "Epoch 7/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9551 - loss: 0.1128 - val_accuracy: 0.8933 - val_loss: 0.2735\n",
            "Epoch 8/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9598 - loss: 0.1017 - val_accuracy: 0.8931 - val_loss: 0.2816\n",
            "Epoch 9/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9629 - loss: 0.0943 - val_accuracy: 0.8945 - val_loss: 0.2846\n",
            "Epoch 10/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9652 - loss: 0.0886 - val_accuracy: 0.8948 - val_loss: 0.2926\n",
            "Epoch 11/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9676 - loss: 0.0826 - val_accuracy: 0.8943 - val_loss: 0.2959\n",
            "Epoch 12/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9696 - loss: 0.0780 - val_accuracy: 0.8949 - val_loss: 0.3068\n",
            "Epoch 13/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0752 - val_accuracy: 0.8948 - val_loss: 0.3210\n",
            "Epoch 14/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9722 - loss: 0.0710 - val_accuracy: 0.8957 - val_loss: 0.3283\n",
            "Epoch 15/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9733 - loss: 0.0686 - val_accuracy: 0.8946 - val_loss: 0.3544\n",
            "Epoch 16/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9745 - loss: 0.0663 - val_accuracy: 0.8945 - val_loss: 0.3437\n",
            "Epoch 17/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9759 - loss: 0.0624 - val_accuracy: 0.8934 - val_loss: 0.3582\n",
            "Epoch 18/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9759 - loss: 0.0620 - val_accuracy: 0.8938 - val_loss: 0.3811\n",
            "Epoch 19/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9775 - loss: 0.0579 - val_accuracy: 0.8943 - val_loss: 0.3776\n",
            "Epoch 20/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9769 - loss: 0.0585 - val_accuracy: 0.8945 - val_loss: 0.3839\n",
            "Epoch 21/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9780 - loss: 0.0559 - val_accuracy: 0.8957 - val_loss: 0.3826\n",
            "Epoch 22/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9788 - loss: 0.0544 - val_accuracy: 0.8947 - val_loss: 0.4033\n",
            "Epoch 23/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9790 - loss: 0.0538 - val_accuracy: 0.8936 - val_loss: 0.4347\n",
            "Epoch 24/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9801 - loss: 0.0508 - val_accuracy: 0.8931 - val_loss: 0.4348\n",
            "Epoch 25/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9796 - loss: 0.0517 - val_accuracy: 0.8937 - val_loss: 0.4031\n",
            "Epoch 26/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9801 - loss: 0.0509 - val_accuracy: 0.8919 - val_loss: 0.4401\n",
            "Epoch 27/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9808 - loss: 0.0495 - val_accuracy: 0.8911 - val_loss: 0.4587\n",
            "Epoch 28/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9809 - loss: 0.0495 - val_accuracy: 0.8925 - val_loss: 0.4562\n",
            "Epoch 29/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0482 - val_accuracy: 0.8919 - val_loss: 0.4499\n",
            "Epoch 30/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.0474 - val_accuracy: 0.8929 - val_loss: 0.4466\n",
            "Epoch 31/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.0468 - val_accuracy: 0.8906 - val_loss: 0.5082\n",
            "Epoch 32/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0448 - val_accuracy: 0.8903 - val_loss: 0.5197\n",
            "Epoch 33/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.0459 - val_accuracy: 0.8897 - val_loss: 0.4932\n",
            "Epoch 34/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.0449 - val_accuracy: 0.8890 - val_loss: 0.5043\n",
            "Epoch 35/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.0446 - val_accuracy: 0.8899 - val_loss: 0.5209\n",
            "Epoch 36/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.0439 - val_accuracy: 0.8910 - val_loss: 0.5314\n",
            "Epoch 37/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0438 - val_accuracy: 0.8897 - val_loss: 0.5433\n",
            "Epoch 38/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9835 - loss: 0.0431 - val_accuracy: 0.8889 - val_loss: 0.5243\n",
            "Epoch 39/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0418 - val_accuracy: 0.8888 - val_loss: 0.5477\n",
            "Epoch 40/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9835 - loss: 0.0419 - val_accuracy: 0.8874 - val_loss: 0.5996\n",
            "Epoch 41/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9838 - loss: 0.0415 - val_accuracy: 0.8865 - val_loss: 0.6256\n",
            "Epoch 42/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0410 - val_accuracy: 0.8888 - val_loss: 0.5574\n",
            "Epoch 43/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0403 - val_accuracy: 0.8889 - val_loss: 0.5898\n",
            "Epoch 44/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0405 - val_accuracy: 0.8861 - val_loss: 0.6012\n",
            "Epoch 45/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.0413 - val_accuracy: 0.8871 - val_loss: 0.6526\n",
            "Epoch 46/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0411 - val_accuracy: 0.8863 - val_loss: 0.6615\n",
            "Epoch 47/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9852 - loss: 0.0387 - val_accuracy: 0.8878 - val_loss: 0.6347\n",
            "Epoch 48/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.0405 - val_accuracy: 0.8862 - val_loss: 0.7057\n",
            "Epoch 49/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9857 - loss: 0.0388 - val_accuracy: 0.8845 - val_loss: 0.6744\n",
            "Epoch 50/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.0397 - val_accuracy: 0.8828 - val_loss: 0.7391\n",
            "Epoch 51/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.0389 - val_accuracy: 0.8848 - val_loss: 0.6690\n",
            "Epoch 52/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.0381 - val_accuracy: 0.8822 - val_loss: 0.7138\n",
            "Epoch 53/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9857 - loss: 0.0384 - val_accuracy: 0.8830 - val_loss: 0.6723\n",
            "Epoch 54/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 0.0381 - val_accuracy: 0.8844 - val_loss: 0.7332\n",
            "Epoch 55/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9857 - loss: 0.0381 - val_accuracy: 0.8827 - val_loss: 0.7548\n",
            "Epoch 56/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.0374 - val_accuracy: 0.8829 - val_loss: 0.7820\n",
            "Epoch 57/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9864 - loss: 0.0369 - val_accuracy: 0.8812 - val_loss: 0.8202\n",
            "Epoch 58/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9858 - loss: 0.0372 - val_accuracy: 0.8799 - val_loss: 0.8388\n",
            "Epoch 59/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0374 - val_accuracy: 0.8804 - val_loss: 0.8642\n",
            "Epoch 60/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0359 - val_accuracy: 0.8803 - val_loss: 0.8617\n",
            "Epoch 61/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0373 - val_accuracy: 0.8827 - val_loss: 0.8763\n",
            "Epoch 62/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9864 - loss: 0.0368 - val_accuracy: 0.8815 - val_loss: 0.8914\n",
            "Epoch 63/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0351 - val_accuracy: 0.8794 - val_loss: 0.8803\n",
            "Epoch 64/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0369 - val_accuracy: 0.8791 - val_loss: 0.9008\n",
            "Epoch 65/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9870 - loss: 0.0352 - val_accuracy: 0.8782 - val_loss: 0.9135\n",
            "Epoch 66/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9866 - loss: 0.0365 - val_accuracy: 0.8803 - val_loss: 0.8985\n",
            "Epoch 67/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0350 - val_accuracy: 0.8767 - val_loss: 0.9923\n",
            "Epoch 68/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9871 - loss: 0.0356 - val_accuracy: 0.8775 - val_loss: 0.9303\n",
            "Epoch 69/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9870 - loss: 0.0354 - val_accuracy: 0.8778 - val_loss: 0.9369\n",
            "Epoch 70/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9872 - loss: 0.0350 - val_accuracy: 0.8773 - val_loss: 0.9881\n",
            "Epoch 71/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0351 - val_accuracy: 0.8778 - val_loss: 1.0364\n",
            "Epoch 72/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0342 - val_accuracy: 0.8778 - val_loss: 1.0471\n",
            "Epoch 73/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9878 - loss: 0.0340 - val_accuracy: 0.8742 - val_loss: 1.1332\n",
            "Epoch 74/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0340 - val_accuracy: 0.8724 - val_loss: 1.1371\n",
            "Epoch 75/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0330 - val_accuracy: 0.8767 - val_loss: 1.1375\n",
            "Epoch 76/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0344 - val_accuracy: 0.8758 - val_loss: 1.0468\n",
            "Epoch 77/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9874 - loss: 0.0347 - val_accuracy: 0.8759 - val_loss: 1.1008\n",
            "Epoch 78/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9879 - loss: 0.0338 - val_accuracy: 0.8746 - val_loss: 1.1163\n",
            "Epoch 79/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0347 - val_accuracy: 0.8718 - val_loss: 1.1387\n",
            "Epoch 80/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9870 - loss: 0.0366 - val_accuracy: 0.8727 - val_loss: 1.1805\n",
            "Epoch 81/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9876 - loss: 0.0350 - val_accuracy: 0.8756 - val_loss: 1.1551\n",
            "Epoch 82/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0339 - val_accuracy: 0.8734 - val_loss: 1.3178\n",
            "Epoch 83/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9882 - loss: 0.0338 - val_accuracy: 0.8715 - val_loss: 1.3315\n",
            "Epoch 84/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0335 - val_accuracy: 0.8746 - val_loss: 1.2823\n",
            "Epoch 85/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9880 - loss: 0.0333 - val_accuracy: 0.8724 - val_loss: 1.2695\n",
            "Epoch 86/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9883 - loss: 0.0333 - val_accuracy: 0.8753 - val_loss: 1.2399\n",
            "Epoch 87/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0330 - val_accuracy: 0.8751 - val_loss: 1.2063\n",
            "Epoch 88/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0349 - val_accuracy: 0.8734 - val_loss: 1.2908\n",
            "Epoch 89/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9880 - loss: 0.0330 - val_accuracy: 0.8728 - val_loss: 1.2827\n",
            "Epoch 90/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0323 - val_accuracy: 0.8731 - val_loss: 1.2982\n",
            "Epoch 91/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9882 - loss: 0.0337 - val_accuracy: 0.8719 - val_loss: 1.3554\n",
            "Epoch 92/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9889 - loss: 0.0310 - val_accuracy: 0.8693 - val_loss: 1.4553\n",
            "Epoch 93/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9880 - loss: 0.0344 - val_accuracy: 0.8673 - val_loss: 1.4282\n",
            "Epoch 94/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9882 - loss: 0.0339 - val_accuracy: 0.8712 - val_loss: 1.4154\n",
            "Epoch 95/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9886 - loss: 0.0333 - val_accuracy: 0.8708 - val_loss: 1.4856\n",
            "Epoch 96/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9882 - loss: 0.0328 - val_accuracy: 0.8730 - val_loss: 1.3235\n",
            "Epoch 97/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.0326 - val_accuracy: 0.8684 - val_loss: 1.4900\n",
            "Epoch 98/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9886 - loss: 0.0317 - val_accuracy: 0.8697 - val_loss: 1.5096\n",
            "Epoch 99/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0321 - val_accuracy: 0.8667 - val_loss: 1.5551\n",
            "Epoch 100/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9886 - loss: 0.0324 - val_accuracy: 0.8680 - val_loss: 1.5665\n",
            "Epoch 101/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0338 - val_accuracy: 0.8701 - val_loss: 1.5914\n",
            "Epoch 102/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9889 - loss: 0.0323 - val_accuracy: 0.8711 - val_loss: 1.5115\n",
            "Epoch 103/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9886 - loss: 0.0328 - val_accuracy: 0.8687 - val_loss: 1.5660\n",
            "Epoch 104/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0327 - val_accuracy: 0.8661 - val_loss: 1.7035\n",
            "Epoch 105/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9890 - loss: 0.0322 - val_accuracy: 0.8693 - val_loss: 1.5589\n",
            "Epoch 106/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9890 - loss: 0.0312 - val_accuracy: 0.8659 - val_loss: 1.6771\n",
            "Epoch 107/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0314 - val_accuracy: 0.8676 - val_loss: 1.6618\n",
            "Epoch 108/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0331 - val_accuracy: 0.8646 - val_loss: 1.7934\n",
            "Epoch 109/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9886 - loss: 0.0327 - val_accuracy: 0.8657 - val_loss: 1.7589\n",
            "Epoch 110/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0320 - val_accuracy: 0.8651 - val_loss: 1.7781\n",
            "Epoch 111/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0330 - val_accuracy: 0.8656 - val_loss: 1.7846\n",
            "Epoch 112/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0317 - val_accuracy: 0.8610 - val_loss: 1.8990\n",
            "Epoch 113/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0327 - val_accuracy: 0.8659 - val_loss: 1.7888\n",
            "Epoch 114/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0326 - val_accuracy: 0.8665 - val_loss: 1.7988\n",
            "Epoch 115/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0327 - val_accuracy: 0.8637 - val_loss: 1.8680\n",
            "Epoch 116/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9889 - loss: 0.0314 - val_accuracy: 0.8626 - val_loss: 1.9620\n",
            "Epoch 117/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0330 - val_accuracy: 0.8594 - val_loss: 1.9457\n",
            "Epoch 118/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0318 - val_accuracy: 0.8622 - val_loss: 2.0680\n",
            "Epoch 119/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9890 - loss: 0.0323 - val_accuracy: 0.8646 - val_loss: 1.9293\n",
            "Epoch 120/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0321 - val_accuracy: 0.8607 - val_loss: 2.0490\n",
            "Epoch 121/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0318 - val_accuracy: 0.8619 - val_loss: 2.0256\n",
            "Epoch 122/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9893 - loss: 0.0313 - val_accuracy: 0.8642 - val_loss: 1.9989\n",
            "Epoch 123/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0305 - val_accuracy: 0.8615 - val_loss: 2.1907\n",
            "Epoch 124/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9897 - loss: 0.0311 - val_accuracy: 0.8618 - val_loss: 2.1466\n",
            "Epoch 125/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9895 - loss: 0.0306 - val_accuracy: 0.8612 - val_loss: 2.1782\n",
            "Epoch 126/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0311 - val_accuracy: 0.8612 - val_loss: 2.1918\n",
            "Epoch 127/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9898 - loss: 0.0304 - val_accuracy: 0.8601 - val_loss: 2.0907\n",
            "Epoch 128/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9893 - loss: 0.0310 - val_accuracy: 0.8596 - val_loss: 2.2045\n",
            "Epoch 129/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9893 - loss: 0.0318 - val_accuracy: 0.8635 - val_loss: 2.0222\n",
            "Epoch 130/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0318 - val_accuracy: 0.8618 - val_loss: 2.0023\n",
            "Epoch 131/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9889 - loss: 0.0328 - val_accuracy: 0.8578 - val_loss: 2.1685\n",
            "Epoch 132/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9898 - loss: 0.0293 - val_accuracy: 0.8604 - val_loss: 2.1519\n",
            "Epoch 133/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0315 - val_accuracy: 0.8577 - val_loss: 2.2937\n",
            "Epoch 134/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9895 - loss: 0.0312 - val_accuracy: 0.8569 - val_loss: 2.2540\n",
            "Epoch 135/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9898 - loss: 0.0303 - val_accuracy: 0.8578 - val_loss: 2.3381\n",
            "Epoch 136/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0322 - val_accuracy: 0.8526 - val_loss: 2.3876\n",
            "Epoch 137/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0293 - val_accuracy: 0.8563 - val_loss: 2.4208\n",
            "Epoch 138/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9895 - loss: 0.0313 - val_accuracy: 0.8531 - val_loss: 2.5017\n",
            "Epoch 139/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0311 - val_accuracy: 0.8591 - val_loss: 2.2558\n",
            "Epoch 140/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0304 - val_accuracy: 0.8587 - val_loss: 2.1492\n",
            "Epoch 141/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0306 - val_accuracy: 0.8549 - val_loss: 2.5261\n",
            "Epoch 142/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9905 - loss: 0.0293 - val_accuracy: 0.8552 - val_loss: 2.5619\n",
            "Epoch 143/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9898 - loss: 0.0308 - val_accuracy: 0.8588 - val_loss: 2.3733\n",
            "Epoch 144/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0316 - val_accuracy: 0.8562 - val_loss: 2.4895\n",
            "Epoch 145/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0304 - val_accuracy: 0.8588 - val_loss: 2.5548\n",
            "Epoch 146/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9903 - loss: 0.0299 - val_accuracy: 0.8564 - val_loss: 2.5310\n",
            "Epoch 147/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.0312 - val_accuracy: 0.8538 - val_loss: 2.7213\n",
            "Epoch 148/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0313 - val_accuracy: 0.8556 - val_loss: 2.5599\n",
            "Epoch 149/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.0308 - val_accuracy: 0.8593 - val_loss: 2.5729\n",
            "Epoch 150/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9898 - loss: 0.0312 - val_accuracy: 0.8572 - val_loss: 2.5791\n",
            "Epoch 151/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0299 - val_accuracy: 0.8556 - val_loss: 2.6873\n",
            "Epoch 152/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.0302 - val_accuracy: 0.8565 - val_loss: 2.6227\n",
            "Epoch 153/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0304 - val_accuracy: 0.8584 - val_loss: 2.6404\n",
            "Epoch 154/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0311 - val_accuracy: 0.8572 - val_loss: 2.6951\n",
            "Epoch 155/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9898 - loss: 0.0313 - val_accuracy: 0.8570 - val_loss: 2.6132\n",
            "Epoch 156/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0298 - val_accuracy: 0.8547 - val_loss: 2.7690\n",
            "Epoch 157/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.0314 - val_accuracy: 0.8597 - val_loss: 2.3462\n",
            "Epoch 158/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9902 - loss: 0.0305 - val_accuracy: 0.8538 - val_loss: 2.7524\n",
            "Epoch 159/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9903 - loss: 0.0302 - val_accuracy: 0.8560 - val_loss: 2.8256\n",
            "Epoch 160/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0305 - val_accuracy: 0.8550 - val_loss: 2.6841\n",
            "Epoch 161/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9907 - loss: 0.0296 - val_accuracy: 0.8527 - val_loss: 2.6821\n",
            "Epoch 162/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9905 - loss: 0.0302 - val_accuracy: 0.8537 - val_loss: 2.7659\n",
            "Epoch 163/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9902 - loss: 0.0308 - val_accuracy: 0.8551 - val_loss: 2.7304\n",
            "Epoch 164/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0302 - val_accuracy: 0.8527 - val_loss: 2.9243\n",
            "Epoch 165/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9902 - loss: 0.0299 - val_accuracy: 0.8560 - val_loss: 2.7551\n",
            "Epoch 166/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0294 - val_accuracy: 0.8507 - val_loss: 2.9431\n",
            "Epoch 167/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0300 - val_accuracy: 0.8532 - val_loss: 2.9573\n",
            "Epoch 168/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9898 - loss: 0.0313 - val_accuracy: 0.8543 - val_loss: 2.8480\n",
            "Epoch 169/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0301 - val_accuracy: 0.8532 - val_loss: 2.7944\n",
            "Epoch 170/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0299 - val_accuracy: 0.8508 - val_loss: 2.9357\n",
            "Epoch 171/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9905 - loss: 0.0302 - val_accuracy: 0.8515 - val_loss: 2.9465\n",
            "Epoch 172/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9903 - loss: 0.0301 - val_accuracy: 0.8524 - val_loss: 3.0500\n",
            "Epoch 173/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0311 - val_accuracy: 0.8522 - val_loss: 3.0558\n",
            "Epoch 174/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9905 - loss: 0.0286 - val_accuracy: 0.8528 - val_loss: 3.1194\n",
            "Epoch 175/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9905 - loss: 0.0296 - val_accuracy: 0.8541 - val_loss: 3.1756\n",
            "Epoch 176/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9907 - loss: 0.0294 - val_accuracy: 0.8514 - val_loss: 3.3223\n",
            "Epoch 177/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9902 - loss: 0.0303 - val_accuracy: 0.8549 - val_loss: 3.0771\n",
            "Epoch 178/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0314 - val_accuracy: 0.8544 - val_loss: 3.0276\n",
            "Epoch 179/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9906 - loss: 0.0291 - val_accuracy: 0.8512 - val_loss: 3.1490\n",
            "Epoch 180/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0299 - val_accuracy: 0.8539 - val_loss: 3.0921\n",
            "Epoch 181/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0283 - val_accuracy: 0.8471 - val_loss: 3.4511\n",
            "Epoch 182/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9902 - loss: 0.0307 - val_accuracy: 0.8519 - val_loss: 3.1516\n",
            "Epoch 183/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0297 - val_accuracy: 0.8535 - val_loss: 2.9218\n",
            "Epoch 184/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9906 - loss: 0.0295 - val_accuracy: 0.8505 - val_loss: 3.3807\n",
            "Epoch 185/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9907 - loss: 0.0293 - val_accuracy: 0.8541 - val_loss: 3.1003\n",
            "Epoch 186/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9905 - loss: 0.0302 - val_accuracy: 0.8532 - val_loss: 3.1191\n",
            "Epoch 187/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0290 - val_accuracy: 0.8540 - val_loss: 3.1441\n",
            "Epoch 188/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0304 - val_accuracy: 0.8500 - val_loss: 3.1777\n",
            "Epoch 189/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9903 - loss: 0.0307 - val_accuracy: 0.8485 - val_loss: 3.3567\n",
            "Epoch 190/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0289 - val_accuracy: 0.8505 - val_loss: 3.1364\n",
            "Epoch 191/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0299 - val_accuracy: 0.8530 - val_loss: 3.0855\n",
            "Epoch 192/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0290 - val_accuracy: 0.8503 - val_loss: 3.5243\n",
            "Epoch 193/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0293 - val_accuracy: 0.8514 - val_loss: 3.3920\n",
            "Epoch 194/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9907 - loss: 0.0300 - val_accuracy: 0.8520 - val_loss: 3.3870\n",
            "Epoch 195/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9912 - loss: 0.0289 - val_accuracy: 0.8489 - val_loss: 3.5134\n",
            "Epoch 196/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0295 - val_accuracy: 0.8501 - val_loss: 3.3687\n",
            "Epoch 197/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0285 - val_accuracy: 0.8497 - val_loss: 3.4233\n",
            "Epoch 198/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0288 - val_accuracy: 0.8522 - val_loss: 3.1606\n",
            "Epoch 199/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9905 - loss: 0.0296 - val_accuracy: 0.8489 - val_loss: 3.5468\n",
            "Epoch 200/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0295 - val_accuracy: 0.8485 - val_loss: 3.5466\n",
            "Epoch 201/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0298 - val_accuracy: 0.8490 - val_loss: 3.3673\n",
            "Epoch 202/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0293 - val_accuracy: 0.8511 - val_loss: 3.1756\n",
            "Epoch 203/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9905 - loss: 0.0305 - val_accuracy: 0.8496 - val_loss: 3.5605\n",
            "Epoch 204/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9912 - loss: 0.0280 - val_accuracy: 0.8503 - val_loss: 3.8796\n",
            "Epoch 205/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0300 - val_accuracy: 0.8491 - val_loss: 3.6875\n",
            "Epoch 206/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0288 - val_accuracy: 0.8466 - val_loss: 3.7813\n",
            "Epoch 207/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0291 - val_accuracy: 0.8501 - val_loss: 3.6434\n",
            "Epoch 208/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0287 - val_accuracy: 0.8481 - val_loss: 4.0333\n",
            "Epoch 209/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0299 - val_accuracy: 0.8484 - val_loss: 3.8193\n",
            "Epoch 210/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9903 - loss: 0.0313 - val_accuracy: 0.8479 - val_loss: 3.8536\n",
            "Epoch 211/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0296 - val_accuracy: 0.8462 - val_loss: 3.9847\n",
            "Epoch 212/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.0291 - val_accuracy: 0.8477 - val_loss: 3.5703\n",
            "Epoch 213/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0299 - val_accuracy: 0.8529 - val_loss: 3.5148\n",
            "Epoch 214/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0294 - val_accuracy: 0.8473 - val_loss: 3.4375\n",
            "Epoch 215/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.0287 - val_accuracy: 0.8460 - val_loss: 3.7102\n",
            "Epoch 216/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0276 - val_accuracy: 0.8472 - val_loss: 3.7008\n",
            "Epoch 217/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0291 - val_accuracy: 0.8475 - val_loss: 3.6668\n",
            "Epoch 218/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0299 - val_accuracy: 0.8484 - val_loss: 3.6824\n",
            "Epoch 219/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.0281 - val_accuracy: 0.8458 - val_loss: 3.9979\n",
            "Epoch 220/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0290 - val_accuracy: 0.8475 - val_loss: 3.8965\n",
            "Epoch 221/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.0284 - val_accuracy: 0.8495 - val_loss: 3.8889\n",
            "Epoch 222/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0292 - val_accuracy: 0.8479 - val_loss: 3.8035\n",
            "Epoch 223/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0284 - val_accuracy: 0.8493 - val_loss: 3.8482\n",
            "Epoch 224/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0274 - val_accuracy: 0.8476 - val_loss: 4.0438\n",
            "Epoch 225/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0273 - val_accuracy: 0.8490 - val_loss: 3.7763\n",
            "Epoch 226/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9912 - loss: 0.0290 - val_accuracy: 0.8462 - val_loss: 3.8265\n",
            "Epoch 227/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0290 - val_accuracy: 0.8490 - val_loss: 3.6765\n",
            "Epoch 228/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0278 - val_accuracy: 0.8396 - val_loss: 4.3869\n",
            "Epoch 229/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0300 - val_accuracy: 0.8498 - val_loss: 3.7353\n",
            "Epoch 230/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.0284 - val_accuracy: 0.8455 - val_loss: 4.2016\n",
            "Epoch 231/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0284 - val_accuracy: 0.8480 - val_loss: 4.1527\n",
            "Epoch 232/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0283 - val_accuracy: 0.8452 - val_loss: 4.0954\n",
            "Epoch 233/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0291 - val_accuracy: 0.8480 - val_loss: 4.2171\n",
            "Epoch 234/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.0292 - val_accuracy: 0.8488 - val_loss: 4.0812\n",
            "Epoch 235/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0284 - val_accuracy: 0.8498 - val_loss: 4.1656\n",
            "Epoch 236/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0282 - val_accuracy: 0.8499 - val_loss: 4.0973\n",
            "Epoch 237/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.0294 - val_accuracy: 0.8502 - val_loss: 4.0924\n",
            "Epoch 238/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0281 - val_accuracy: 0.8502 - val_loss: 3.8378\n",
            "Epoch 239/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0301 - val_accuracy: 0.8491 - val_loss: 4.1513\n",
            "Epoch 240/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0280 - val_accuracy: 0.8490 - val_loss: 4.3313\n",
            "Epoch 241/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0290 - val_accuracy: 0.8474 - val_loss: 4.1080\n",
            "Epoch 242/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9907 - loss: 0.0307 - val_accuracy: 0.8477 - val_loss: 4.1899\n",
            "Epoch 243/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0277 - val_accuracy: 0.8486 - val_loss: 4.6335\n",
            "Epoch 244/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9912 - loss: 0.0289 - val_accuracy: 0.8461 - val_loss: 4.6048\n",
            "Epoch 245/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0301 - val_accuracy: 0.8499 - val_loss: 4.2570\n",
            "Epoch 246/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9912 - loss: 0.0286 - val_accuracy: 0.8485 - val_loss: 4.1190\n",
            "Epoch 247/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0286 - val_accuracy: 0.8450 - val_loss: 4.6149\n",
            "Epoch 248/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0274 - val_accuracy: 0.8474 - val_loss: 4.3578\n",
            "Epoch 249/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0281 - val_accuracy: 0.8473 - val_loss: 4.3908\n",
            "Epoch 250/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0293 - val_accuracy: 0.8496 - val_loss: 4.0032\n",
            "Epoch 251/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0288 - val_accuracy: 0.8479 - val_loss: 4.1298\n",
            "Epoch 252/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9912 - loss: 0.0294 - val_accuracy: 0.8467 - val_loss: 4.5812\n",
            "Epoch 253/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.0301 - val_accuracy: 0.8465 - val_loss: 4.5206\n",
            "Epoch 254/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0274 - val_accuracy: 0.8467 - val_loss: 4.6525\n",
            "Epoch 255/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0282 - val_accuracy: 0.8475 - val_loss: 4.5864\n",
            "Epoch 256/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0289 - val_accuracy: 0.8486 - val_loss: 4.4242\n",
            "Epoch 257/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0290 - val_accuracy: 0.8502 - val_loss: 4.2787\n",
            "Epoch 258/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0273 - val_accuracy: 0.8498 - val_loss: 4.4284\n",
            "Epoch 259/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0282 - val_accuracy: 0.8474 - val_loss: 4.3316\n",
            "Epoch 260/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.0293 - val_accuracy: 0.8470 - val_loss: 4.5109\n",
            "Epoch 261/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0288 - val_accuracy: 0.8457 - val_loss: 4.8253\n",
            "Epoch 262/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0290 - val_accuracy: 0.8462 - val_loss: 4.4964\n",
            "Epoch 263/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0270 - val_accuracy: 0.8476 - val_loss: 4.4834\n",
            "Epoch 264/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0292 - val_accuracy: 0.8398 - val_loss: 4.8997\n",
            "Epoch 265/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0279 - val_accuracy: 0.8452 - val_loss: 4.6930\n",
            "Epoch 266/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0275 - val_accuracy: 0.8444 - val_loss: 5.0704\n",
            "Epoch 267/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0285 - val_accuracy: 0.8435 - val_loss: 4.7953\n",
            "Epoch 268/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0277 - val_accuracy: 0.8469 - val_loss: 4.6457\n",
            "Epoch 269/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0283 - val_accuracy: 0.8416 - val_loss: 5.3245\n",
            "Epoch 270/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0282 - val_accuracy: 0.8438 - val_loss: 5.2317\n",
            "Epoch 271/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0276 - val_accuracy: 0.8433 - val_loss: 5.3082\n",
            "Epoch 272/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0291 - val_accuracy: 0.8424 - val_loss: 5.3979\n",
            "Epoch 273/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0291 - val_accuracy: 0.8480 - val_loss: 4.5545\n",
            "Epoch 274/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9912 - loss: 0.0288 - val_accuracy: 0.8467 - val_loss: 4.8689\n",
            "Epoch 275/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0297 - val_accuracy: 0.8441 - val_loss: 4.9337\n",
            "Epoch 276/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0290 - val_accuracy: 0.8456 - val_loss: 4.8893\n",
            "Epoch 277/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0277 - val_accuracy: 0.8457 - val_loss: 5.0850\n",
            "Epoch 278/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0271 - val_accuracy: 0.8441 - val_loss: 5.0660\n",
            "Epoch 279/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0285 - val_accuracy: 0.8436 - val_loss: 5.1594\n",
            "Epoch 280/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0279 - val_accuracy: 0.8452 - val_loss: 5.8361\n",
            "Epoch 281/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0282 - val_accuracy: 0.8449 - val_loss: 5.2036\n",
            "Epoch 282/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0277 - val_accuracy: 0.8469 - val_loss: 4.8760\n",
            "Epoch 283/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0295 - val_accuracy: 0.8459 - val_loss: 5.0931\n",
            "Epoch 284/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0283 - val_accuracy: 0.8452 - val_loss: 4.9925\n",
            "Epoch 285/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0285 - val_accuracy: 0.8473 - val_loss: 5.0321\n",
            "Epoch 286/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0290 - val_accuracy: 0.8479 - val_loss: 4.7695\n",
            "Epoch 287/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0265 - val_accuracy: 0.8463 - val_loss: 5.1878\n",
            "Epoch 288/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0277 - val_accuracy: 0.8456 - val_loss: 5.2357\n",
            "Epoch 289/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0276 - val_accuracy: 0.8460 - val_loss: 5.3511\n",
            "Epoch 290/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0286 - val_accuracy: 0.8482 - val_loss: 4.5461\n",
            "Epoch 291/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0271 - val_accuracy: 0.8459 - val_loss: 4.9613\n",
            "Epoch 292/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0275 - val_accuracy: 0.8423 - val_loss: 5.4497\n",
            "Epoch 293/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0279 - val_accuracy: 0.8436 - val_loss: 5.4793\n",
            "Epoch 294/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0281 - val_accuracy: 0.8419 - val_loss: 5.6617\n",
            "Epoch 295/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0282 - val_accuracy: 0.8407 - val_loss: 6.1449\n",
            "Epoch 296/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0279 - val_accuracy: 0.8437 - val_loss: 5.5081\n",
            "Epoch 297/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0279 - val_accuracy: 0.8481 - val_loss: 5.0523\n",
            "Epoch 298/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0284 - val_accuracy: 0.8466 - val_loss: 5.4804\n",
            "Epoch 299/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0273 - val_accuracy: 0.8421 - val_loss: 5.6786\n",
            "Epoch 300/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.0300 - val_accuracy: 0.8445 - val_loss: 5.6772\n",
            "Epoch 301/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0278 - val_accuracy: 0.8460 - val_loss: 5.5079\n",
            "Epoch 302/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0283 - val_accuracy: 0.8465 - val_loss: 5.1613\n",
            "Epoch 303/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0285 - val_accuracy: 0.8470 - val_loss: 5.0194\n",
            "Epoch 304/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0293 - val_accuracy: 0.8455 - val_loss: 5.3194\n",
            "Epoch 305/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0280 - val_accuracy: 0.8465 - val_loss: 5.4909\n",
            "Epoch 306/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0271 - val_accuracy: 0.8433 - val_loss: 5.5519\n",
            "Epoch 307/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0275 - val_accuracy: 0.8444 - val_loss: 5.8472\n",
            "Epoch 308/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0277 - val_accuracy: 0.8399 - val_loss: 6.2488\n",
            "Epoch 309/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0261 - val_accuracy: 0.8421 - val_loss: 6.1798\n",
            "Epoch 310/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0274 - val_accuracy: 0.8459 - val_loss: 5.5975\n",
            "Epoch 311/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0281 - val_accuracy: 0.8418 - val_loss: 6.5894\n",
            "Epoch 312/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0287 - val_accuracy: 0.8447 - val_loss: 5.6798\n",
            "Epoch 313/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0265 - val_accuracy: 0.8402 - val_loss: 6.2879\n",
            "Epoch 314/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0275 - val_accuracy: 0.8421 - val_loss: 5.7652\n",
            "Epoch 315/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0283 - val_accuracy: 0.8439 - val_loss: 6.0540\n",
            "Epoch 316/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0290 - val_accuracy: 0.8480 - val_loss: 4.9548\n",
            "Epoch 317/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0271 - val_accuracy: 0.8433 - val_loss: 5.5603\n",
            "Epoch 318/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0290 - val_accuracy: 0.8469 - val_loss: 5.4214\n",
            "Epoch 319/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0278 - val_accuracy: 0.8422 - val_loss: 5.9800\n",
            "Epoch 320/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0283 - val_accuracy: 0.8400 - val_loss: 5.9256\n",
            "Epoch 321/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0274 - val_accuracy: 0.8471 - val_loss: 5.5507\n",
            "Epoch 322/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0261 - val_accuracy: 0.8432 - val_loss: 6.2188\n",
            "Epoch 323/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0267 - val_accuracy: 0.8452 - val_loss: 5.7790\n",
            "Epoch 324/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0294 - val_accuracy: 0.8455 - val_loss: 5.8382\n",
            "Epoch 325/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0278 - val_accuracy: 0.8461 - val_loss: 5.9036\n",
            "Epoch 326/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0276 - val_accuracy: 0.8427 - val_loss: 5.9244\n",
            "Epoch 327/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0284 - val_accuracy: 0.8428 - val_loss: 5.7906\n",
            "Epoch 328/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0277 - val_accuracy: 0.8416 - val_loss: 5.9472\n",
            "Epoch 329/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0297 - val_accuracy: 0.8358 - val_loss: 6.2036\n",
            "Epoch 330/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0278 - val_accuracy: 0.8417 - val_loss: 6.1570\n",
            "Epoch 331/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0291 - val_accuracy: 0.8422 - val_loss: 6.6095\n",
            "Epoch 332/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0276 - val_accuracy: 0.8394 - val_loss: 6.4557\n",
            "Epoch 333/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0286 - val_accuracy: 0.8420 - val_loss: 5.8362\n",
            "Epoch 334/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0278 - val_accuracy: 0.8443 - val_loss: 6.1708\n",
            "Epoch 335/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0277 - val_accuracy: 0.8456 - val_loss: 6.1957\n",
            "Epoch 336/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0280 - val_accuracy: 0.8431 - val_loss: 6.2771\n",
            "Epoch 337/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0271 - val_accuracy: 0.8449 - val_loss: 5.4613\n",
            "Epoch 338/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0276 - val_accuracy: 0.8412 - val_loss: 6.2424\n",
            "Epoch 339/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0276 - val_accuracy: 0.8425 - val_loss: 6.0954\n",
            "Epoch 340/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0282 - val_accuracy: 0.8421 - val_loss: 5.9563\n",
            "Epoch 341/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0282 - val_accuracy: 0.8411 - val_loss: 6.1058\n",
            "Epoch 342/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0290 - val_accuracy: 0.8415 - val_loss: 6.4084\n",
            "Epoch 343/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0287 - val_accuracy: 0.8453 - val_loss: 5.9190\n",
            "Epoch 344/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0279 - val_accuracy: 0.8438 - val_loss: 6.2866\n",
            "Epoch 345/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0276 - val_accuracy: 0.8442 - val_loss: 6.4211\n",
            "Epoch 346/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0265 - val_accuracy: 0.8400 - val_loss: 7.1565\n",
            "Epoch 347/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0275 - val_accuracy: 0.8408 - val_loss: 6.4935\n",
            "Epoch 348/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0278 - val_accuracy: 0.8441 - val_loss: 6.2154\n",
            "Epoch 349/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0267 - val_accuracy: 0.8436 - val_loss: 6.2019\n",
            "Epoch 350/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0280 - val_accuracy: 0.8441 - val_loss: 5.5990\n",
            "Epoch 351/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0273 - val_accuracy: 0.8445 - val_loss: 5.3764\n",
            "Epoch 352/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0271 - val_accuracy: 0.8416 - val_loss: 5.9744\n",
            "Epoch 353/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0282 - val_accuracy: 0.8405 - val_loss: 6.8392\n",
            "Epoch 354/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0262 - val_accuracy: 0.8407 - val_loss: 6.6121\n",
            "Epoch 355/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0278 - val_accuracy: 0.8444 - val_loss: 6.2351\n",
            "Epoch 356/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0301 - val_accuracy: 0.8436 - val_loss: 6.1712\n",
            "Epoch 357/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0267 - val_accuracy: 0.8418 - val_loss: 6.5848\n",
            "Epoch 358/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0272 - val_accuracy: 0.8460 - val_loss: 6.2691\n",
            "Epoch 359/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0280 - val_accuracy: 0.8458 - val_loss: 6.4349\n",
            "Epoch 360/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0279 - val_accuracy: 0.8413 - val_loss: 7.0940\n",
            "Epoch 361/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0266 - val_accuracy: 0.8419 - val_loss: 6.7662\n",
            "Epoch 362/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0275 - val_accuracy: 0.8429 - val_loss: 7.1739\n",
            "Epoch 363/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0273 - val_accuracy: 0.8413 - val_loss: 7.3257\n",
            "Epoch 364/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0278 - val_accuracy: 0.8405 - val_loss: 7.2096\n",
            "Epoch 365/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0284 - val_accuracy: 0.8457 - val_loss: 6.8720\n",
            "Epoch 366/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0289 - val_accuracy: 0.8398 - val_loss: 6.7062\n",
            "Epoch 367/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0270 - val_accuracy: 0.8439 - val_loss: 6.6741\n",
            "Epoch 368/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0266 - val_accuracy: 0.8441 - val_loss: 6.1883\n",
            "Epoch 369/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0282 - val_accuracy: 0.8433 - val_loss: 6.9149\n",
            "Epoch 370/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0270 - val_accuracy: 0.8420 - val_loss: 6.6909\n",
            "Epoch 371/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0289 - val_accuracy: 0.8412 - val_loss: 6.9380\n",
            "Epoch 372/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0279 - val_accuracy: 0.8427 - val_loss: 6.6301\n",
            "Epoch 373/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0268 - val_accuracy: 0.8438 - val_loss: 6.5239\n",
            "Epoch 374/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0290 - val_accuracy: 0.8402 - val_loss: 6.8666\n",
            "Epoch 375/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0282 - val_accuracy: 0.8421 - val_loss: 6.8615\n",
            "Epoch 376/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0265 - val_accuracy: 0.8420 - val_loss: 6.6085\n",
            "Epoch 377/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0263 - val_accuracy: 0.8414 - val_loss: 6.2329\n",
            "Epoch 378/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0275 - val_accuracy: 0.8426 - val_loss: 6.8841\n",
            "Epoch 379/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0271 - val_accuracy: 0.8354 - val_loss: 7.0461\n",
            "Epoch 380/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0283 - val_accuracy: 0.8425 - val_loss: 6.9252\n",
            "Epoch 381/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0281 - val_accuracy: 0.8410 - val_loss: 7.3379\n",
            "Epoch 382/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0276 - val_accuracy: 0.8438 - val_loss: 6.8293\n",
            "Epoch 383/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0297 - val_accuracy: 0.8417 - val_loss: 6.8967\n",
            "Epoch 384/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0268 - val_accuracy: 0.8438 - val_loss: 6.7692\n",
            "Epoch 385/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0284 - val_accuracy: 0.8377 - val_loss: 7.3988\n",
            "Epoch 386/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0285 - val_accuracy: 0.8399 - val_loss: 7.5333\n",
            "Epoch 387/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0289 - val_accuracy: 0.8406 - val_loss: 7.6616\n",
            "Epoch 388/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0280 - val_accuracy: 0.8395 - val_loss: 7.5510\n",
            "Epoch 389/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0289 - val_accuracy: 0.8427 - val_loss: 7.3147\n",
            "Epoch 390/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0268 - val_accuracy: 0.8449 - val_loss: 6.8447\n",
            "Epoch 391/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0277 - val_accuracy: 0.8418 - val_loss: 6.7599\n",
            "Epoch 392/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0277 - val_accuracy: 0.8478 - val_loss: 5.7849\n",
            "Epoch 393/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0282 - val_accuracy: 0.8447 - val_loss: 6.7197\n",
            "Epoch 394/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0266 - val_accuracy: 0.8464 - val_loss: 6.3812\n",
            "Epoch 395/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0284 - val_accuracy: 0.8431 - val_loss: 6.9666\n",
            "Epoch 396/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0291 - val_accuracy: 0.8427 - val_loss: 7.0097\n",
            "Epoch 397/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0268 - val_accuracy: 0.8427 - val_loss: 7.1203\n",
            "Epoch 398/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0276 - val_accuracy: 0.8412 - val_loss: 7.7384\n",
            "Epoch 399/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0283 - val_accuracy: 0.8416 - val_loss: 7.6176\n",
            "Epoch 400/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0286 - val_accuracy: 0.8464 - val_loss: 6.3995\n",
            "Epoch 401/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0303 - val_accuracy: 0.8403 - val_loss: 7.4577\n",
            "Epoch 402/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0280 - val_accuracy: 0.8394 - val_loss: 7.7878\n",
            "Epoch 403/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0258 - val_accuracy: 0.8429 - val_loss: 6.7901\n",
            "Epoch 404/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0272 - val_accuracy: 0.8406 - val_loss: 6.9531\n",
            "Epoch 405/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0265 - val_accuracy: 0.8421 - val_loss: 7.0797\n",
            "Epoch 406/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0271 - val_accuracy: 0.8424 - val_loss: 6.8749\n",
            "Epoch 407/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0284 - val_accuracy: 0.8417 - val_loss: 7.1887\n",
            "Epoch 408/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0285 - val_accuracy: 0.8368 - val_loss: 8.1204\n",
            "Epoch 409/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0278 - val_accuracy: 0.8421 - val_loss: 7.0201\n",
            "Epoch 410/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0275 - val_accuracy: 0.8411 - val_loss: 7.1666\n",
            "Epoch 411/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0283 - val_accuracy: 0.8398 - val_loss: 6.9946\n",
            "Epoch 412/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0282 - val_accuracy: 0.8416 - val_loss: 6.8479\n",
            "Epoch 413/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0266 - val_accuracy: 0.8361 - val_loss: 7.8218\n",
            "Epoch 414/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0292 - val_accuracy: 0.8417 - val_loss: 7.2748\n",
            "Epoch 415/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0297 - val_accuracy: 0.8406 - val_loss: 7.7970\n",
            "Epoch 416/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0268 - val_accuracy: 0.8418 - val_loss: 7.4862\n",
            "Epoch 417/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0289 - val_accuracy: 0.8424 - val_loss: 6.6372\n",
            "Epoch 418/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0282 - val_accuracy: 0.8415 - val_loss: 7.8674\n",
            "Epoch 419/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0290 - val_accuracy: 0.8411 - val_loss: 7.5363\n",
            "Epoch 420/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0280 - val_accuracy: 0.8406 - val_loss: 7.5139\n",
            "Epoch 421/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0267 - val_accuracy: 0.8418 - val_loss: 7.1556\n",
            "Epoch 422/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0264 - val_accuracy: 0.8396 - val_loss: 7.2887\n",
            "Epoch 423/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0272 - val_accuracy: 0.8398 - val_loss: 7.3742\n",
            "Epoch 424/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0282 - val_accuracy: 0.8438 - val_loss: 6.7060\n",
            "Epoch 425/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0280 - val_accuracy: 0.8407 - val_loss: 7.5863\n",
            "Epoch 426/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0269 - val_accuracy: 0.8406 - val_loss: 7.8842\n",
            "Epoch 427/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0266 - val_accuracy: 0.8408 - val_loss: 7.6033\n",
            "Epoch 428/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0270 - val_accuracy: 0.8401 - val_loss: 7.7778\n",
            "Epoch 429/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0259 - val_accuracy: 0.8424 - val_loss: 7.3561\n",
            "Epoch 430/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0278 - val_accuracy: 0.8414 - val_loss: 7.6734\n",
            "Epoch 431/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0272 - val_accuracy: 0.8395 - val_loss: 8.1005\n",
            "Epoch 432/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0277 - val_accuracy: 0.8411 - val_loss: 7.4331\n",
            "Epoch 433/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0269 - val_accuracy: 0.8452 - val_loss: 7.4221\n",
            "Epoch 434/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0273 - val_accuracy: 0.8379 - val_loss: 8.7863\n",
            "Epoch 435/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0266 - val_accuracy: 0.8411 - val_loss: 8.2272\n",
            "Epoch 436/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0257 - val_accuracy: 0.8441 - val_loss: 6.7993\n",
            "Epoch 437/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0281 - val_accuracy: 0.8394 - val_loss: 7.9384\n",
            "Epoch 438/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0247 - val_accuracy: 0.8405 - val_loss: 7.9637\n",
            "Epoch 439/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0269 - val_accuracy: 0.8401 - val_loss: 7.6936\n",
            "Epoch 440/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0269 - val_accuracy: 0.8377 - val_loss: 7.8506\n",
            "Epoch 441/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0260 - val_accuracy: 0.8387 - val_loss: 7.9102\n",
            "Epoch 442/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0269 - val_accuracy: 0.8429 - val_loss: 7.6781\n",
            "Epoch 443/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0279 - val_accuracy: 0.8414 - val_loss: 8.0202\n",
            "Epoch 444/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0264 - val_accuracy: 0.8406 - val_loss: 8.0689\n",
            "Epoch 445/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0282 - val_accuracy: 0.8414 - val_loss: 8.0410\n",
            "Epoch 446/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0274 - val_accuracy: 0.8395 - val_loss: 7.5338\n",
            "Epoch 447/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0269 - val_accuracy: 0.8448 - val_loss: 6.7947\n",
            "Epoch 448/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0275 - val_accuracy: 0.8411 - val_loss: 7.5831\n",
            "Epoch 449/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0264 - val_accuracy: 0.8416 - val_loss: 7.6509\n",
            "Epoch 450/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0263 - val_accuracy: 0.8435 - val_loss: 7.6437\n",
            "Epoch 451/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0261 - val_accuracy: 0.8409 - val_loss: 7.9281\n",
            "Epoch 452/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0260 - val_accuracy: 0.8394 - val_loss: 7.6057\n",
            "Epoch 453/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0285 - val_accuracy: 0.8393 - val_loss: 8.1695\n",
            "Epoch 454/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0277 - val_accuracy: 0.8369 - val_loss: 9.0665\n",
            "Epoch 455/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0269 - val_accuracy: 0.8388 - val_loss: 8.0815\n",
            "Epoch 456/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0274 - val_accuracy: 0.8410 - val_loss: 8.2173\n",
            "Epoch 457/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0264 - val_accuracy: 0.8393 - val_loss: 8.1753\n",
            "Epoch 458/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0278 - val_accuracy: 0.8407 - val_loss: 8.7069\n",
            "Epoch 459/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0265 - val_accuracy: 0.8407 - val_loss: 7.7383\n",
            "Epoch 460/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0276 - val_accuracy: 0.8399 - val_loss: 7.8993\n",
            "Epoch 461/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0277 - val_accuracy: 0.8433 - val_loss: 7.3390\n",
            "Epoch 462/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0274 - val_accuracy: 0.8382 - val_loss: 8.2159\n",
            "Epoch 463/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0271 - val_accuracy: 0.8413 - val_loss: 7.5318\n",
            "Epoch 464/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0256 - val_accuracy: 0.8397 - val_loss: 8.3786\n",
            "Epoch 465/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0283 - val_accuracy: 0.8419 - val_loss: 7.7214\n",
            "Epoch 466/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0291 - val_accuracy: 0.8389 - val_loss: 8.0493\n",
            "Epoch 467/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0284 - val_accuracy: 0.8410 - val_loss: 8.1312\n",
            "Epoch 468/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0271 - val_accuracy: 0.8404 - val_loss: 7.6363\n",
            "Epoch 469/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0274 - val_accuracy: 0.8405 - val_loss: 7.7701\n",
            "Epoch 470/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0268 - val_accuracy: 0.8413 - val_loss: 8.2266\n",
            "Epoch 471/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0260 - val_accuracy: 0.8404 - val_loss: 8.5189\n",
            "Epoch 472/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0277 - val_accuracy: 0.8408 - val_loss: 8.4400\n",
            "Epoch 473/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0271 - val_accuracy: 0.8407 - val_loss: 8.5497\n",
            "Epoch 474/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0272 - val_accuracy: 0.8408 - val_loss: 8.9076\n",
            "Epoch 475/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0262 - val_accuracy: 0.8413 - val_loss: 8.0497\n",
            "Epoch 476/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0266 - val_accuracy: 0.8397 - val_loss: 8.3807\n",
            "Epoch 477/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0272 - val_accuracy: 0.8399 - val_loss: 7.5237\n",
            "Epoch 478/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0263 - val_accuracy: 0.8391 - val_loss: 8.0892\n",
            "Epoch 479/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0263 - val_accuracy: 0.8383 - val_loss: 7.7666\n",
            "Epoch 480/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0277 - val_accuracy: 0.8407 - val_loss: 7.8511\n",
            "Epoch 481/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0272 - val_accuracy: 0.8385 - val_loss: 8.9666\n",
            "Epoch 482/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0268 - val_accuracy: 0.8413 - val_loss: 7.8100\n",
            "Epoch 483/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0271 - val_accuracy: 0.8422 - val_loss: 8.4283\n",
            "Epoch 484/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0265 - val_accuracy: 0.8413 - val_loss: 8.2535\n",
            "Epoch 485/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0266 - val_accuracy: 0.8391 - val_loss: 8.2737\n",
            "Epoch 486/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0287 - val_accuracy: 0.8421 - val_loss: 7.1834\n",
            "Epoch 487/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0268 - val_accuracy: 0.8413 - val_loss: 8.1927\n",
            "Epoch 488/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0295 - val_accuracy: 0.8429 - val_loss: 7.7050\n",
            "Epoch 489/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0272 - val_accuracy: 0.8412 - val_loss: 8.3589\n",
            "Epoch 490/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0262 - val_accuracy: 0.8424 - val_loss: 8.0775\n",
            "Epoch 491/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0266 - val_accuracy: 0.8420 - val_loss: 8.2526\n",
            "Epoch 492/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0267 - val_accuracy: 0.8389 - val_loss: 8.9658\n",
            "Epoch 493/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0272 - val_accuracy: 0.8407 - val_loss: 8.3119\n",
            "Epoch 494/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0288 - val_accuracy: 0.8382 - val_loss: 8.9794\n",
            "Epoch 495/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0272 - val_accuracy: 0.8380 - val_loss: 8.5889\n",
            "Epoch 496/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0271 - val_accuracy: 0.8394 - val_loss: 9.3432\n",
            "Epoch 497/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0276 - val_accuracy: 0.8396 - val_loss: 9.0019\n",
            "Epoch 498/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0272 - val_accuracy: 0.8380 - val_loss: 9.1050\n",
            "Epoch 499/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0277 - val_accuracy: 0.8385 - val_loss: 9.0006\n",
            "Epoch 500/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0264 - val_accuracy: 0.8418 - val_loss: 7.9856\n",
            "Epoch 501/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0263 - val_accuracy: 0.8418 - val_loss: 9.4049\n",
            "Epoch 502/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0272 - val_accuracy: 0.8397 - val_loss: 8.3731\n",
            "Epoch 503/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0275 - val_accuracy: 0.8371 - val_loss: 8.9031\n",
            "Epoch 504/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0262 - val_accuracy: 0.8404 - val_loss: 8.5687\n",
            "Epoch 505/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0262 - val_accuracy: 0.8399 - val_loss: 9.5887\n",
            "Epoch 506/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0263 - val_accuracy: 0.8363 - val_loss: 10.2972\n",
            "Epoch 507/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0263 - val_accuracy: 0.8393 - val_loss: 8.9690\n",
            "Epoch 508/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0283 - val_accuracy: 0.8383 - val_loss: 9.5717\n",
            "Epoch 509/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0284 - val_accuracy: 0.8387 - val_loss: 9.7195\n",
            "Epoch 510/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0269 - val_accuracy: 0.8411 - val_loss: 8.9828\n",
            "Epoch 511/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0288 - val_accuracy: 0.8404 - val_loss: 9.0899\n",
            "Epoch 512/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0276 - val_accuracy: 0.8392 - val_loss: 8.7355\n",
            "Epoch 513/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0274 - val_accuracy: 0.8403 - val_loss: 8.7366\n",
            "Epoch 514/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0263 - val_accuracy: 0.8418 - val_loss: 9.2416\n",
            "Epoch 515/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0261 - val_accuracy: 0.8377 - val_loss: 9.5657\n",
            "Epoch 516/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0287 - val_accuracy: 0.8412 - val_loss: 8.8244\n",
            "Epoch 517/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0281 - val_accuracy: 0.8399 - val_loss: 8.7527\n",
            "Epoch 518/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0259 - val_accuracy: 0.8413 - val_loss: 9.7952\n",
            "Epoch 519/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0276 - val_accuracy: 0.8387 - val_loss: 10.4337\n",
            "Epoch 520/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0284 - val_accuracy: 0.8394 - val_loss: 10.0841\n",
            "Epoch 521/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0277 - val_accuracy: 0.8403 - val_loss: 9.3273\n",
            "Epoch 522/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0278 - val_accuracy: 0.8366 - val_loss: 10.3804\n",
            "Epoch 523/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0269 - val_accuracy: 0.8420 - val_loss: 9.4311\n",
            "Epoch 524/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0271 - val_accuracy: 0.8381 - val_loss: 9.6046\n",
            "Epoch 525/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0278 - val_accuracy: 0.8386 - val_loss: 9.4312\n",
            "Epoch 526/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0270 - val_accuracy: 0.8386 - val_loss: 10.1721\n",
            "Epoch 527/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0259 - val_accuracy: 0.8400 - val_loss: 9.8228\n",
            "Epoch 528/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0268 - val_accuracy: 0.8391 - val_loss: 9.1899\n",
            "Epoch 529/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0269 - val_accuracy: 0.8383 - val_loss: 10.0850\n",
            "Epoch 530/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0266 - val_accuracy: 0.8396 - val_loss: 9.1409\n",
            "Epoch 531/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0265 - val_accuracy: 0.8409 - val_loss: 10.1891\n",
            "Epoch 532/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0262 - val_accuracy: 0.8400 - val_loss: 10.3113\n",
            "Epoch 533/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0275 - val_accuracy: 0.8407 - val_loss: 9.3194\n",
            "Epoch 534/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0261 - val_accuracy: 0.8419 - val_loss: 9.2463\n",
            "Epoch 535/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0282 - val_accuracy: 0.8380 - val_loss: 10.4006\n",
            "Epoch 536/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0267 - val_accuracy: 0.8398 - val_loss: 10.1478\n",
            "Epoch 537/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0270 - val_accuracy: 0.8392 - val_loss: 9.7925\n",
            "Epoch 538/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0256 - val_accuracy: 0.8368 - val_loss: 9.2138\n",
            "Epoch 539/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0273 - val_accuracy: 0.8380 - val_loss: 9.8117\n",
            "Epoch 540/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0274 - val_accuracy: 0.8408 - val_loss: 9.2774\n",
            "Epoch 541/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0270 - val_accuracy: 0.8416 - val_loss: 9.8840\n",
            "Epoch 542/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0278 - val_accuracy: 0.8401 - val_loss: 10.4949\n",
            "Epoch 543/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0268 - val_accuracy: 0.8405 - val_loss: 9.9146\n",
            "Epoch 544/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0258 - val_accuracy: 0.8398 - val_loss: 9.0630\n",
            "Epoch 545/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0270 - val_accuracy: 0.8386 - val_loss: 9.9317\n",
            "Epoch 546/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0276 - val_accuracy: 0.8430 - val_loss: 8.4629\n",
            "Epoch 547/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0261 - val_accuracy: 0.8395 - val_loss: 9.7705\n",
            "Epoch 548/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0270 - val_accuracy: 0.8404 - val_loss: 9.6030\n",
            "Epoch 549/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0275 - val_accuracy: 0.8378 - val_loss: 10.0064\n",
            "Epoch 550/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0267 - val_accuracy: 0.8383 - val_loss: 9.8562\n",
            "Epoch 551/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0266 - val_accuracy: 0.8408 - val_loss: 9.6844\n",
            "Epoch 552/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0270 - val_accuracy: 0.8407 - val_loss: 9.2422\n",
            "Epoch 553/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0280 - val_accuracy: 0.8382 - val_loss: 9.7127\n",
            "Epoch 554/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0265 - val_accuracy: 0.8412 - val_loss: 9.0107\n",
            "Epoch 555/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0267 - val_accuracy: 0.8394 - val_loss: 9.0504\n",
            "Epoch 556/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0263 - val_accuracy: 0.8384 - val_loss: 9.5315\n",
            "Epoch 557/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0280 - val_accuracy: 0.8410 - val_loss: 9.1036\n",
            "Epoch 558/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0285 - val_accuracy: 0.8433 - val_loss: 8.9639\n",
            "Epoch 559/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0262 - val_accuracy: 0.8407 - val_loss: 9.5089\n",
            "Epoch 560/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0283 - val_accuracy: 0.8369 - val_loss: 9.5926\n",
            "Epoch 561/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0276 - val_accuracy: 0.8384 - val_loss: 9.2399\n",
            "Epoch 562/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0258 - val_accuracy: 0.8381 - val_loss: 9.3822\n",
            "Epoch 563/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0266 - val_accuracy: 0.8403 - val_loss: 9.0178\n",
            "Epoch 564/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0276 - val_accuracy: 0.8393 - val_loss: 8.6496\n",
            "Epoch 565/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0282 - val_accuracy: 0.8387 - val_loss: 8.7413\n",
            "Epoch 566/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0286 - val_accuracy: 0.8381 - val_loss: 9.7125\n",
            "Epoch 567/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0272 - val_accuracy: 0.8368 - val_loss: 9.6026\n",
            "Epoch 568/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0263 - val_accuracy: 0.8358 - val_loss: 10.4786\n",
            "Epoch 569/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0276 - val_accuracy: 0.8399 - val_loss: 8.9738\n",
            "Epoch 570/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0277 - val_accuracy: 0.8378 - val_loss: 10.3229\n",
            "Epoch 571/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0269 - val_accuracy: 0.8401 - val_loss: 9.6157\n",
            "Epoch 572/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0278 - val_accuracy: 0.8386 - val_loss: 9.3199\n",
            "Epoch 573/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0269 - val_accuracy: 0.8385 - val_loss: 9.3706\n",
            "Epoch 574/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0293 - val_accuracy: 0.8379 - val_loss: 10.1523\n",
            "Epoch 575/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0264 - val_accuracy: 0.8366 - val_loss: 11.4329\n",
            "Epoch 576/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0258 - val_accuracy: 0.8402 - val_loss: 10.4775\n",
            "Epoch 577/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0272 - val_accuracy: 0.8379 - val_loss: 11.0071\n",
            "Epoch 578/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0274 - val_accuracy: 0.8359 - val_loss: 11.3256\n",
            "Epoch 579/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0257 - val_accuracy: 0.8385 - val_loss: 11.0433\n",
            "Epoch 580/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0269 - val_accuracy: 0.8379 - val_loss: 11.0668\n",
            "Epoch 581/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0263 - val_accuracy: 0.8392 - val_loss: 10.7950\n",
            "Epoch 582/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0264 - val_accuracy: 0.8391 - val_loss: 11.1766\n",
            "Epoch 583/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0270 - val_accuracy: 0.8381 - val_loss: 11.1504\n",
            "Epoch 584/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0281 - val_accuracy: 0.8398 - val_loss: 11.4117\n",
            "Epoch 585/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0278 - val_accuracy: 0.8387 - val_loss: 10.5982\n",
            "Epoch 586/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0269 - val_accuracy: 0.8386 - val_loss: 10.8393\n",
            "Epoch 587/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0265 - val_accuracy: 0.8390 - val_loss: 11.3615\n",
            "Epoch 588/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0268 - val_accuracy: 0.8400 - val_loss: 11.0549\n",
            "Epoch 589/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0278 - val_accuracy: 0.8377 - val_loss: 11.6084\n",
            "Epoch 590/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0282 - val_accuracy: 0.8384 - val_loss: 11.2946\n",
            "Epoch 591/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0267 - val_accuracy: 0.8415 - val_loss: 9.8916\n",
            "Epoch 592/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0281 - val_accuracy: 0.8379 - val_loss: 10.9872\n",
            "Epoch 593/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0273 - val_accuracy: 0.8393 - val_loss: 9.8950\n",
            "Epoch 594/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0266 - val_accuracy: 0.8393 - val_loss: 9.7955\n",
            "Epoch 595/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0273 - val_accuracy: 0.8397 - val_loss: 10.7807\n",
            "Epoch 596/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0270 - val_accuracy: 0.8397 - val_loss: 10.2077\n",
            "Epoch 597/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0242 - val_accuracy: 0.8358 - val_loss: 11.6356\n",
            "Epoch 598/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0264 - val_accuracy: 0.8424 - val_loss: 9.7760\n",
            "Epoch 599/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0263 - val_accuracy: 0.8366 - val_loss: 11.6036\n",
            "Epoch 600/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0242 - val_accuracy: 0.8411 - val_loss: 12.0439\n",
            "Epoch 601/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0285 - val_accuracy: 0.8394 - val_loss: 10.7984\n",
            "Epoch 602/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9934 - loss: 0.0260 - val_accuracy: 0.8392 - val_loss: 10.6233\n",
            "Epoch 603/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0258 - val_accuracy: 0.8387 - val_loss: 11.2421\n",
            "Epoch 604/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0266 - val_accuracy: 0.8365 - val_loss: 10.5393\n",
            "Epoch 605/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0263 - val_accuracy: 0.8391 - val_loss: 9.7223\n",
            "Epoch 606/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0269 - val_accuracy: 0.8374 - val_loss: 10.7309\n",
            "Epoch 607/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0262 - val_accuracy: 0.8373 - val_loss: 10.9290\n",
            "Epoch 608/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0296 - val_accuracy: 0.8389 - val_loss: 10.6187\n",
            "Epoch 609/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0270 - val_accuracy: 0.8388 - val_loss: 10.5152\n",
            "Epoch 610/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0266 - val_accuracy: 0.8391 - val_loss: 9.6915\n",
            "Epoch 611/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0267 - val_accuracy: 0.8395 - val_loss: 9.7691\n",
            "Epoch 612/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0272 - val_accuracy: 0.8359 - val_loss: 10.5879\n",
            "Epoch 613/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0258 - val_accuracy: 0.8381 - val_loss: 11.4501\n",
            "Epoch 614/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0279 - val_accuracy: 0.8375 - val_loss: 11.2163\n",
            "Epoch 615/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0259 - val_accuracy: 0.8401 - val_loss: 10.7493\n",
            "Epoch 616/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0257 - val_accuracy: 0.8393 - val_loss: 10.5973\n",
            "Epoch 617/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0259 - val_accuracy: 0.8411 - val_loss: 10.6891\n",
            "Epoch 618/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0270 - val_accuracy: 0.8393 - val_loss: 10.4215\n",
            "Epoch 619/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0270 - val_accuracy: 0.8411 - val_loss: 10.7019\n",
            "Epoch 620/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0284 - val_accuracy: 0.8406 - val_loss: 10.1517\n",
            "Epoch 621/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0261 - val_accuracy: 0.8418 - val_loss: 9.7721\n",
            "Epoch 622/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0270 - val_accuracy: 0.8391 - val_loss: 11.1195\n",
            "Epoch 623/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0284 - val_accuracy: 0.8395 - val_loss: 10.4625\n",
            "Epoch 624/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0275 - val_accuracy: 0.8401 - val_loss: 11.1454\n",
            "Epoch 625/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0265 - val_accuracy: 0.8377 - val_loss: 12.0894\n",
            "Epoch 626/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0277 - val_accuracy: 0.8345 - val_loss: 11.6295\n",
            "Epoch 627/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0277 - val_accuracy: 0.8386 - val_loss: 11.1983\n",
            "Epoch 628/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0273 - val_accuracy: 0.8381 - val_loss: 10.6694\n",
            "Epoch 629/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0268 - val_accuracy: 0.8415 - val_loss: 10.6340\n",
            "Epoch 630/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0277 - val_accuracy: 0.8371 - val_loss: 11.5999\n",
            "Epoch 631/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0276 - val_accuracy: 0.8396 - val_loss: 10.7573\n",
            "Epoch 632/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0261 - val_accuracy: 0.8368 - val_loss: 11.1204\n",
            "Epoch 633/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0288 - val_accuracy: 0.8406 - val_loss: 10.8018\n",
            "Epoch 634/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0273 - val_accuracy: 0.8342 - val_loss: 11.8706\n",
            "Epoch 635/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0279 - val_accuracy: 0.8391 - val_loss: 10.7391\n",
            "Epoch 636/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0269 - val_accuracy: 0.8365 - val_loss: 10.8254\n",
            "Epoch 637/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0284 - val_accuracy: 0.8391 - val_loss: 11.1487\n",
            "Epoch 638/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0283 - val_accuracy: 0.8385 - val_loss: 11.3164\n",
            "Epoch 639/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0277 - val_accuracy: 0.8395 - val_loss: 10.2092\n",
            "Epoch 640/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0270 - val_accuracy: 0.8402 - val_loss: 11.1499\n",
            "Epoch 641/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0261 - val_accuracy: 0.8369 - val_loss: 11.6990\n",
            "Epoch 642/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0272 - val_accuracy: 0.8368 - val_loss: 12.4976\n",
            "Epoch 643/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0278 - val_accuracy: 0.8378 - val_loss: 12.0479\n",
            "Epoch 644/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0254 - val_accuracy: 0.8395 - val_loss: 12.1370\n",
            "Epoch 645/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0272 - val_accuracy: 0.8375 - val_loss: 12.3107\n",
            "Epoch 646/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0251 - val_accuracy: 0.8408 - val_loss: 11.5426\n",
            "Epoch 647/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0274 - val_accuracy: 0.8392 - val_loss: 11.7330\n",
            "Epoch 648/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0266 - val_accuracy: 0.8398 - val_loss: 10.8957\n",
            "Epoch 649/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0263 - val_accuracy: 0.8390 - val_loss: 11.5978\n",
            "Epoch 650/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0269 - val_accuracy: 0.8370 - val_loss: 11.6185\n",
            "Epoch 651/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9933 - loss: 0.0252 - val_accuracy: 0.8383 - val_loss: 11.1364\n",
            "Epoch 652/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0261 - val_accuracy: 0.8400 - val_loss: 11.6050\n",
            "Epoch 653/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0274 - val_accuracy: 0.8400 - val_loss: 11.6729\n",
            "Epoch 654/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9933 - loss: 0.0250 - val_accuracy: 0.8368 - val_loss: 11.9413\n",
            "Epoch 655/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0288 - val_accuracy: 0.8379 - val_loss: 12.6775\n",
            "Epoch 656/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0288 - val_accuracy: 0.8375 - val_loss: 11.6558\n",
            "Epoch 657/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0273 - val_accuracy: 0.8411 - val_loss: 10.5596\n",
            "Epoch 658/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9934 - loss: 0.0259 - val_accuracy: 0.8396 - val_loss: 10.2696\n",
            "Epoch 659/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0267 - val_accuracy: 0.8400 - val_loss: 11.0704\n",
            "Epoch 660/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0272 - val_accuracy: 0.8366 - val_loss: 12.1952\n",
            "Epoch 661/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0270 - val_accuracy: 0.8370 - val_loss: 12.3160\n",
            "Epoch 662/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0267 - val_accuracy: 0.8371 - val_loss: 11.9421\n",
            "Epoch 663/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0268 - val_accuracy: 0.8371 - val_loss: 12.5359\n",
            "Epoch 664/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0259 - val_accuracy: 0.8402 - val_loss: 11.3756\n",
            "Epoch 665/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0275 - val_accuracy: 0.8389 - val_loss: 12.3355\n",
            "Epoch 666/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0268 - val_accuracy: 0.8370 - val_loss: 13.2940\n",
            "Epoch 667/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0284 - val_accuracy: 0.8373 - val_loss: 11.9004\n",
            "Epoch 668/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0269 - val_accuracy: 0.8386 - val_loss: 12.2358\n",
            "Epoch 669/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0267 - val_accuracy: 0.8386 - val_loss: 12.4608\n",
            "Epoch 670/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9935 - loss: 0.0255 - val_accuracy: 0.8391 - val_loss: 13.3119\n",
            "Epoch 671/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0263 - val_accuracy: 0.8356 - val_loss: 14.8554\n",
            "Epoch 672/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0274 - val_accuracy: 0.8367 - val_loss: 13.5463\n",
            "Epoch 673/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0266 - val_accuracy: 0.8374 - val_loss: 13.0401\n",
            "Epoch 674/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0278 - val_accuracy: 0.8375 - val_loss: 12.1961\n",
            "Epoch 675/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0286 - val_accuracy: 0.8376 - val_loss: 12.8525\n",
            "Epoch 676/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0277 - val_accuracy: 0.8378 - val_loss: 13.6094\n",
            "Epoch 677/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9935 - loss: 0.0248 - val_accuracy: 0.8387 - val_loss: 12.8925\n",
            "Epoch 678/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0283 - val_accuracy: 0.8346 - val_loss: 12.9173\n",
            "Epoch 679/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0272 - val_accuracy: 0.8374 - val_loss: 13.3921\n",
            "Epoch 680/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0269 - val_accuracy: 0.8364 - val_loss: 12.4485\n",
            "Epoch 681/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0270 - val_accuracy: 0.8388 - val_loss: 11.6608\n",
            "Epoch 682/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0271 - val_accuracy: 0.8386 - val_loss: 12.5413\n",
            "Epoch 683/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0272 - val_accuracy: 0.8404 - val_loss: 12.4179\n",
            "Epoch 684/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0268 - val_accuracy: 0.8390 - val_loss: 13.0048\n",
            "Epoch 685/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0257 - val_accuracy: 0.8381 - val_loss: 13.4522\n",
            "Epoch 686/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0278 - val_accuracy: 0.8368 - val_loss: 12.7074\n",
            "Epoch 687/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0257 - val_accuracy: 0.8405 - val_loss: 11.5406\n",
            "Epoch 688/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0262 - val_accuracy: 0.8386 - val_loss: 12.6771\n",
            "Epoch 689/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0271 - val_accuracy: 0.8387 - val_loss: 12.8980\n",
            "Epoch 690/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0279 - val_accuracy: 0.8370 - val_loss: 13.4028\n",
            "Epoch 691/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0258 - val_accuracy: 0.8392 - val_loss: 11.2908\n",
            "Epoch 692/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0265 - val_accuracy: 0.8405 - val_loss: 10.5082\n",
            "Epoch 693/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0298 - val_accuracy: 0.8377 - val_loss: 12.1101\n",
            "Epoch 694/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0260 - val_accuracy: 0.8381 - val_loss: 12.1497\n",
            "Epoch 695/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0275 - val_accuracy: 0.8374 - val_loss: 12.7461\n",
            "Epoch 696/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0267 - val_accuracy: 0.8385 - val_loss: 12.8843\n",
            "Epoch 697/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0269 - val_accuracy: 0.8398 - val_loss: 12.9264\n",
            "Epoch 698/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0273 - val_accuracy: 0.8389 - val_loss: 12.5973\n",
            "Epoch 699/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0269 - val_accuracy: 0.8390 - val_loss: 12.2424\n",
            "Epoch 700/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0254 - val_accuracy: 0.8364 - val_loss: 11.9846\n",
            "Epoch 701/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0265 - val_accuracy: 0.8359 - val_loss: 12.3427\n",
            "Epoch 702/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0285 - val_accuracy: 0.8394 - val_loss: 12.2764\n",
            "Epoch 703/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0264 - val_accuracy: 0.8383 - val_loss: 12.9269\n",
            "Epoch 704/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0277 - val_accuracy: 0.8411 - val_loss: 12.0145\n",
            "Epoch 705/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0264 - val_accuracy: 0.8369 - val_loss: 14.0375\n",
            "Epoch 706/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0272 - val_accuracy: 0.8395 - val_loss: 13.3610\n",
            "Epoch 707/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0266 - val_accuracy: 0.8370 - val_loss: 14.4352\n",
            "Epoch 708/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0267 - val_accuracy: 0.8340 - val_loss: 13.6550\n",
            "Epoch 709/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0269 - val_accuracy: 0.8378 - val_loss: 13.2606\n",
            "Epoch 710/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0266 - val_accuracy: 0.8374 - val_loss: 13.3944\n",
            "Epoch 711/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0260 - val_accuracy: 0.8351 - val_loss: 14.1691\n",
            "Epoch 712/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0279 - val_accuracy: 0.8374 - val_loss: 14.6707\n",
            "Epoch 713/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0271 - val_accuracy: 0.8374 - val_loss: 14.1172\n",
            "Epoch 714/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0261 - val_accuracy: 0.8351 - val_loss: 15.3364\n",
            "Epoch 715/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0270 - val_accuracy: 0.8370 - val_loss: 15.2853\n",
            "Epoch 716/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0287 - val_accuracy: 0.8400 - val_loss: 15.1380\n",
            "Epoch 717/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0305 - val_accuracy: 0.8378 - val_loss: 13.9123\n",
            "Epoch 718/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0272 - val_accuracy: 0.8404 - val_loss: 15.1291\n",
            "Epoch 719/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0265 - val_accuracy: 0.8392 - val_loss: 13.8726\n",
            "Epoch 720/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0262 - val_accuracy: 0.8399 - val_loss: 14.2244\n",
            "Epoch 721/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0274 - val_accuracy: 0.8398 - val_loss: 13.7865\n",
            "Epoch 722/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0268 - val_accuracy: 0.8402 - val_loss: 13.6093\n",
            "Epoch 723/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0302 - val_accuracy: 0.8424 - val_loss: 12.3210\n",
            "Epoch 724/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0277 - val_accuracy: 0.8396 - val_loss: 12.7297\n",
            "Epoch 725/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0270 - val_accuracy: 0.8352 - val_loss: 13.9999\n",
            "Epoch 726/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0286 - val_accuracy: 0.8369 - val_loss: 13.6067\n",
            "Epoch 727/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0268 - val_accuracy: 0.8382 - val_loss: 13.5061\n",
            "Epoch 728/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0265 - val_accuracy: 0.8389 - val_loss: 12.8354\n",
            "Epoch 729/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0262 - val_accuracy: 0.8410 - val_loss: 12.7238\n",
            "Epoch 730/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0273 - val_accuracy: 0.8375 - val_loss: 13.3617\n",
            "Epoch 731/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0276 - val_accuracy: 0.8352 - val_loss: 15.0088\n",
            "Epoch 732/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0275 - val_accuracy: 0.8395 - val_loss: 12.3185\n",
            "Epoch 733/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9933 - loss: 0.0254 - val_accuracy: 0.8397 - val_loss: 12.8980\n",
            "Epoch 734/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0288 - val_accuracy: 0.8393 - val_loss: 12.2237\n",
            "Epoch 735/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0274 - val_accuracy: 0.8401 - val_loss: 13.9612\n",
            "Epoch 736/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0289 - val_accuracy: 0.8363 - val_loss: 12.7516\n",
            "Epoch 737/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0273 - val_accuracy: 0.8400 - val_loss: 13.0917\n",
            "Epoch 738/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0272 - val_accuracy: 0.8363 - val_loss: 14.0388\n",
            "Epoch 739/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0278 - val_accuracy: 0.8375 - val_loss: 13.8190\n",
            "Epoch 740/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0253 - val_accuracy: 0.8388 - val_loss: 14.1767\n",
            "Epoch 741/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0272 - val_accuracy: 0.8355 - val_loss: 14.7545\n",
            "Epoch 742/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0271 - val_accuracy: 0.8405 - val_loss: 14.7563\n",
            "Epoch 743/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0296 - val_accuracy: 0.8343 - val_loss: 14.6815\n",
            "Epoch 744/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0263 - val_accuracy: 0.8374 - val_loss: 14.2698\n",
            "Epoch 745/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0285 - val_accuracy: 0.8377 - val_loss: 14.2516\n",
            "Epoch 746/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0270 - val_accuracy: 0.8380 - val_loss: 14.7127\n",
            "Epoch 747/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0269 - val_accuracy: 0.8371 - val_loss: 15.5839\n",
            "Epoch 748/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0279 - val_accuracy: 0.8399 - val_loss: 15.3097\n",
            "Epoch 749/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0267 - val_accuracy: 0.8366 - val_loss: 15.9279\n",
            "Epoch 750/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0266 - val_accuracy: 0.8377 - val_loss: 16.0702\n",
            "Epoch 751/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0286 - val_accuracy: 0.8403 - val_loss: 13.9510\n",
            "Epoch 752/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0252 - val_accuracy: 0.8398 - val_loss: 14.9043\n",
            "Epoch 753/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0261 - val_accuracy: 0.8406 - val_loss: 14.3130\n",
            "Epoch 754/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0267 - val_accuracy: 0.8409 - val_loss: 13.5511\n",
            "Epoch 755/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0280 - val_accuracy: 0.8400 - val_loss: 14.9827\n",
            "Epoch 756/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0280 - val_accuracy: 0.8381 - val_loss: 15.0779\n",
            "Epoch 757/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0272 - val_accuracy: 0.8413 - val_loss: 14.6924\n",
            "Epoch 758/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0277 - val_accuracy: 0.8374 - val_loss: 15.0658\n",
            "Epoch 759/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0278 - val_accuracy: 0.8412 - val_loss: 14.3316\n",
            "Epoch 760/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0283 - val_accuracy: 0.8427 - val_loss: 13.0243\n",
            "Epoch 761/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0301 - val_accuracy: 0.8362 - val_loss: 14.3753\n",
            "Epoch 762/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0265 - val_accuracy: 0.8406 - val_loss: 13.1829\n",
            "Epoch 763/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9933 - loss: 0.0267 - val_accuracy: 0.8394 - val_loss: 13.3817\n",
            "Epoch 764/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0265 - val_accuracy: 0.8389 - val_loss: 13.6936\n",
            "Epoch 765/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0295 - val_accuracy: 0.8374 - val_loss: 15.2291\n",
            "Epoch 766/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0287 - val_accuracy: 0.8397 - val_loss: 14.2011\n",
            "Epoch 767/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0279 - val_accuracy: 0.8396 - val_loss: 13.2624\n",
            "Epoch 768/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0262 - val_accuracy: 0.8377 - val_loss: 13.6582\n",
            "Epoch 769/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0273 - val_accuracy: 0.8383 - val_loss: 13.8683\n",
            "Epoch 770/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0291 - val_accuracy: 0.8378 - val_loss: 13.4176\n",
            "Epoch 771/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9933 - loss: 0.0257 - val_accuracy: 0.8362 - val_loss: 15.0491\n",
            "Epoch 772/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0283 - val_accuracy: 0.8402 - val_loss: 13.3654\n",
            "Epoch 773/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0281 - val_accuracy: 0.8382 - val_loss: 14.2023\n",
            "Epoch 774/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0279 - val_accuracy: 0.8404 - val_loss: 12.9955\n",
            "Epoch 775/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0270 - val_accuracy: 0.8404 - val_loss: 13.8397\n",
            "Epoch 776/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0277 - val_accuracy: 0.8393 - val_loss: 14.0901\n",
            "Epoch 777/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0263 - val_accuracy: 0.8350 - val_loss: 17.2418\n",
            "Epoch 778/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0276 - val_accuracy: 0.8413 - val_loss: 13.7587\n",
            "Epoch 779/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0287 - val_accuracy: 0.8388 - val_loss: 13.8052\n",
            "Epoch 780/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0274 - val_accuracy: 0.8384 - val_loss: 13.8926\n",
            "Epoch 781/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0262 - val_accuracy: 0.8390 - val_loss: 14.0931\n",
            "Epoch 782/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9934 - loss: 0.0254 - val_accuracy: 0.8380 - val_loss: 14.2724\n",
            "Epoch 783/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0284 - val_accuracy: 0.8379 - val_loss: 13.9075\n",
            "Epoch 784/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0284 - val_accuracy: 0.8406 - val_loss: 13.6149\n",
            "Epoch 785/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0278 - val_accuracy: 0.8392 - val_loss: 13.4067\n",
            "Epoch 786/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0276 - val_accuracy: 0.8380 - val_loss: 14.1792\n",
            "Epoch 787/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0271 - val_accuracy: 0.8387 - val_loss: 13.1076\n",
            "Epoch 788/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0278 - val_accuracy: 0.8370 - val_loss: 13.4652\n",
            "Epoch 789/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0282 - val_accuracy: 0.8386 - val_loss: 14.2885\n",
            "Epoch 790/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0271 - val_accuracy: 0.8373 - val_loss: 15.0472\n",
            "Epoch 791/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0278 - val_accuracy: 0.8375 - val_loss: 14.0377\n",
            "Epoch 792/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0273 - val_accuracy: 0.8397 - val_loss: 15.1268\n",
            "Epoch 793/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0287 - val_accuracy: 0.8377 - val_loss: 15.6775\n",
            "Epoch 794/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0267 - val_accuracy: 0.8386 - val_loss: 14.7433\n",
            "Epoch 795/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0266 - val_accuracy: 0.8390 - val_loss: 13.7564\n",
            "Epoch 796/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0271 - val_accuracy: 0.8378 - val_loss: 13.7771\n",
            "Epoch 797/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0265 - val_accuracy: 0.8399 - val_loss: 12.8507\n",
            "Epoch 798/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0285 - val_accuracy: 0.8394 - val_loss: 14.3373\n",
            "Epoch 799/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0268 - val_accuracy: 0.8431 - val_loss: 13.7137\n",
            "Epoch 800/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0265 - val_accuracy: 0.8369 - val_loss: 15.4110\n",
            "Epoch 801/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0272 - val_accuracy: 0.8387 - val_loss: 15.3525\n",
            "Epoch 802/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0285 - val_accuracy: 0.8395 - val_loss: 13.9267\n",
            "Epoch 803/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0278 - val_accuracy: 0.8430 - val_loss: 13.1731\n",
            "Epoch 804/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0299 - val_accuracy: 0.8412 - val_loss: 14.1331\n",
            "Epoch 805/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0268 - val_accuracy: 0.8370 - val_loss: 14.6636\n",
            "Epoch 806/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0277 - val_accuracy: 0.8406 - val_loss: 13.9701\n",
            "Epoch 807/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0285 - val_accuracy: 0.8408 - val_loss: 13.8611\n",
            "Epoch 808/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0274 - val_accuracy: 0.8389 - val_loss: 15.1335\n",
            "Epoch 809/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0277 - val_accuracy: 0.8382 - val_loss: 15.5692\n",
            "Epoch 810/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0285 - val_accuracy: 0.8395 - val_loss: 14.5082\n",
            "Epoch 811/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0290 - val_accuracy: 0.8424 - val_loss: 14.2275\n",
            "Epoch 812/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0270 - val_accuracy: 0.8382 - val_loss: 14.3912\n",
            "Epoch 813/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9934 - loss: 0.0240 - val_accuracy: 0.8386 - val_loss: 14.2889\n",
            "Epoch 814/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0272 - val_accuracy: 0.8396 - val_loss: 15.5472\n",
            "Epoch 815/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0272 - val_accuracy: 0.8395 - val_loss: 15.3760\n",
            "Epoch 816/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0281 - val_accuracy: 0.8393 - val_loss: 15.0679\n",
            "Epoch 817/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0288 - val_accuracy: 0.8420 - val_loss: 14.3529\n",
            "Epoch 818/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0300 - val_accuracy: 0.8390 - val_loss: 14.4640\n",
            "Epoch 819/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0300 - val_accuracy: 0.8386 - val_loss: 14.5203\n",
            "Epoch 820/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0293 - val_accuracy: 0.8409 - val_loss: 14.1020\n",
            "Epoch 821/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9934 - loss: 0.0254 - val_accuracy: 0.8410 - val_loss: 14.2895\n",
            "Epoch 822/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0279 - val_accuracy: 0.8424 - val_loss: 13.5743\n",
            "Epoch 823/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0261 - val_accuracy: 0.8400 - val_loss: 14.9492\n",
            "Epoch 824/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0283 - val_accuracy: 0.8413 - val_loss: 14.3416\n",
            "Epoch 825/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0274 - val_accuracy: 0.8397 - val_loss: 15.4169\n",
            "Epoch 826/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0277 - val_accuracy: 0.8409 - val_loss: 14.1655\n",
            "Epoch 827/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0284 - val_accuracy: 0.8405 - val_loss: 15.1314\n",
            "Epoch 828/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0303 - val_accuracy: 0.8404 - val_loss: 15.2289\n",
            "Epoch 829/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0284 - val_accuracy: 0.8404 - val_loss: 14.8225\n",
            "Epoch 830/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0288 - val_accuracy: 0.8403 - val_loss: 15.5963\n",
            "Epoch 831/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0309 - val_accuracy: 0.8439 - val_loss: 13.2700\n",
            "Epoch 832/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0288 - val_accuracy: 0.8393 - val_loss: 15.3410\n",
            "Epoch 833/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0263 - val_accuracy: 0.8386 - val_loss: 14.0547\n",
            "Epoch 834/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0278 - val_accuracy: 0.8398 - val_loss: 14.0153\n",
            "Epoch 835/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0270 - val_accuracy: 0.8400 - val_loss: 14.5487\n",
            "Epoch 836/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0282 - val_accuracy: 0.8380 - val_loss: 14.7557\n",
            "Epoch 837/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0266 - val_accuracy: 0.8379 - val_loss: 16.0838\n",
            "Epoch 838/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0291 - val_accuracy: 0.8385 - val_loss: 15.3134\n",
            "Epoch 839/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0260 - val_accuracy: 0.8397 - val_loss: 14.4673\n",
            "Epoch 840/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0293 - val_accuracy: 0.8377 - val_loss: 15.5566\n",
            "Epoch 841/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0276 - val_accuracy: 0.8411 - val_loss: 14.6685\n",
            "Epoch 842/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0277 - val_accuracy: 0.8383 - val_loss: 14.8543\n",
            "Epoch 843/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0286 - val_accuracy: 0.8392 - val_loss: 14.3441\n",
            "Epoch 844/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0295 - val_accuracy: 0.8391 - val_loss: 14.3080\n",
            "Epoch 845/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0270 - val_accuracy: 0.8412 - val_loss: 13.8331\n",
            "Epoch 846/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0259 - val_accuracy: 0.8420 - val_loss: 14.6147\n",
            "Epoch 847/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0270 - val_accuracy: 0.8403 - val_loss: 14.8787\n",
            "Epoch 848/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0254 - val_accuracy: 0.8395 - val_loss: 14.2132\n",
            "Epoch 849/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0283 - val_accuracy: 0.8415 - val_loss: 14.8351\n",
            "Epoch 850/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0290 - val_accuracy: 0.8410 - val_loss: 15.7074\n",
            "Epoch 851/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0271 - val_accuracy: 0.8405 - val_loss: 14.6010\n",
            "Epoch 852/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0260 - val_accuracy: 0.8408 - val_loss: 15.5850\n",
            "Epoch 853/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0261 - val_accuracy: 0.8399 - val_loss: 15.8660\n",
            "Epoch 854/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0270 - val_accuracy: 0.8414 - val_loss: 15.3309\n",
            "Epoch 855/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0282 - val_accuracy: 0.8401 - val_loss: 14.2893\n",
            "Epoch 856/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0271 - val_accuracy: 0.8421 - val_loss: 14.9341\n",
            "Epoch 857/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0286 - val_accuracy: 0.8414 - val_loss: 16.3198\n",
            "Epoch 858/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0307 - val_accuracy: 0.8381 - val_loss: 16.5888\n",
            "Epoch 859/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0279 - val_accuracy: 0.8427 - val_loss: 15.2597\n",
            "Epoch 860/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0281 - val_accuracy: 0.8404 - val_loss: 14.5716\n",
            "Epoch 861/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0277 - val_accuracy: 0.8390 - val_loss: 16.1987\n",
            "Epoch 862/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0314 - val_accuracy: 0.8403 - val_loss: 14.8610\n",
            "Epoch 863/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0253 - val_accuracy: 0.8386 - val_loss: 17.7194\n",
            "Epoch 864/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0284 - val_accuracy: 0.8429 - val_loss: 15.7540\n",
            "Epoch 865/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0266 - val_accuracy: 0.8397 - val_loss: 17.3394\n",
            "Epoch 866/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0285 - val_accuracy: 0.8390 - val_loss: 17.7896\n",
            "Epoch 867/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0279 - val_accuracy: 0.8403 - val_loss: 15.9393\n",
            "Epoch 868/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0276 - val_accuracy: 0.8392 - val_loss: 15.8110\n",
            "Epoch 869/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0281 - val_accuracy: 0.8412 - val_loss: 14.8058\n",
            "Epoch 870/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0279 - val_accuracy: 0.8401 - val_loss: 14.1229\n",
            "Epoch 871/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0283 - val_accuracy: 0.8417 - val_loss: 13.2417\n",
            "Epoch 872/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0283 - val_accuracy: 0.8397 - val_loss: 16.7259\n",
            "Epoch 873/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0264 - val_accuracy: 0.8372 - val_loss: 16.4127\n",
            "Epoch 874/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0270 - val_accuracy: 0.8407 - val_loss: 16.0172\n",
            "Epoch 875/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0280 - val_accuracy: 0.8410 - val_loss: 15.6645\n",
            "Epoch 876/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0278 - val_accuracy: 0.8420 - val_loss: 16.0682\n",
            "Epoch 877/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0296 - val_accuracy: 0.8424 - val_loss: 14.9876\n",
            "Epoch 878/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0266 - val_accuracy: 0.8404 - val_loss: 16.0187\n",
            "Epoch 879/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0276 - val_accuracy: 0.8407 - val_loss: 16.7332\n",
            "Epoch 880/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0288 - val_accuracy: 0.8402 - val_loss: 16.0808\n",
            "Epoch 881/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0264 - val_accuracy: 0.8410 - val_loss: 16.7262\n",
            "Epoch 882/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0276 - val_accuracy: 0.8375 - val_loss: 18.7096\n",
            "Epoch 883/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0274 - val_accuracy: 0.8433 - val_loss: 17.3507\n",
            "Epoch 884/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0276 - val_accuracy: 0.8421 - val_loss: 17.1293\n",
            "Epoch 885/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0262 - val_accuracy: 0.8407 - val_loss: 16.5290\n",
            "Epoch 886/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0261 - val_accuracy: 0.8409 - val_loss: 17.1515\n",
            "Epoch 887/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0266 - val_accuracy: 0.8403 - val_loss: 16.3563\n",
            "Epoch 888/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0290 - val_accuracy: 0.8429 - val_loss: 15.7753\n",
            "Epoch 889/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0286 - val_accuracy: 0.8392 - val_loss: 16.4773\n",
            "Epoch 890/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0278 - val_accuracy: 0.8416 - val_loss: 15.9190\n",
            "Epoch 891/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0296 - val_accuracy: 0.8414 - val_loss: 15.5678\n",
            "Epoch 892/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0281 - val_accuracy: 0.8395 - val_loss: 15.9405\n",
            "Epoch 893/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0277 - val_accuracy: 0.8416 - val_loss: 14.8507\n",
            "Epoch 894/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0265 - val_accuracy: 0.8425 - val_loss: 15.1427\n",
            "Epoch 895/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0274 - val_accuracy: 0.8403 - val_loss: 15.6307\n",
            "Epoch 896/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0284 - val_accuracy: 0.8400 - val_loss: 15.7379\n",
            "Epoch 897/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0270 - val_accuracy: 0.8385 - val_loss: 17.3904\n",
            "Epoch 898/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0281 - val_accuracy: 0.8392 - val_loss: 17.5174\n",
            "Epoch 899/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0285 - val_accuracy: 0.8415 - val_loss: 16.1025\n",
            "Epoch 900/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0254 - val_accuracy: 0.8409 - val_loss: 16.2797\n",
            "Epoch 901/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0272 - val_accuracy: 0.8414 - val_loss: 15.8662\n",
            "Epoch 902/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0270 - val_accuracy: 0.8384 - val_loss: 16.4183\n",
            "Epoch 903/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0266 - val_accuracy: 0.8403 - val_loss: 16.6107\n",
            "Epoch 904/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0274 - val_accuracy: 0.8400 - val_loss: 15.8438\n",
            "Epoch 905/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0288 - val_accuracy: 0.8427 - val_loss: 14.6826\n",
            "Epoch 906/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0285 - val_accuracy: 0.8432 - val_loss: 15.2576\n",
            "Epoch 907/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0283 - val_accuracy: 0.8419 - val_loss: 14.7315\n",
            "Epoch 908/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0311 - val_accuracy: 0.8406 - val_loss: 15.9294\n",
            "Epoch 909/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0270 - val_accuracy: 0.8410 - val_loss: 16.8295\n",
            "Epoch 910/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0270 - val_accuracy: 0.8448 - val_loss: 14.6676\n",
            "Epoch 911/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0258 - val_accuracy: 0.8423 - val_loss: 16.3089\n",
            "Epoch 912/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0268 - val_accuracy: 0.8405 - val_loss: 15.8622\n",
            "Epoch 913/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0282 - val_accuracy: 0.8423 - val_loss: 16.2115\n",
            "Epoch 914/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0288 - val_accuracy: 0.8410 - val_loss: 16.0204\n",
            "Epoch 915/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0293 - val_accuracy: 0.8423 - val_loss: 15.7743\n",
            "Epoch 916/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0282 - val_accuracy: 0.8397 - val_loss: 18.2381\n",
            "Epoch 917/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0281 - val_accuracy: 0.8444 - val_loss: 16.0217\n",
            "Epoch 918/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0271 - val_accuracy: 0.8413 - val_loss: 18.3475\n",
            "Epoch 919/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0281 - val_accuracy: 0.8423 - val_loss: 17.6246\n",
            "Epoch 920/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9935 - loss: 0.0251 - val_accuracy: 0.8426 - val_loss: 16.0414\n",
            "Epoch 921/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0274 - val_accuracy: 0.8383 - val_loss: 18.3584\n",
            "Epoch 922/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0272 - val_accuracy: 0.8394 - val_loss: 18.3853\n",
            "Epoch 923/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0276 - val_accuracy: 0.8440 - val_loss: 15.3433\n",
            "Epoch 924/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0289 - val_accuracy: 0.8408 - val_loss: 16.9747\n",
            "Epoch 925/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0255 - val_accuracy: 0.8400 - val_loss: 17.2101\n",
            "Epoch 926/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0266 - val_accuracy: 0.8398 - val_loss: 17.4050\n",
            "Epoch 927/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0281 - val_accuracy: 0.8440 - val_loss: 15.5801\n",
            "Epoch 928/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0272 - val_accuracy: 0.8417 - val_loss: 16.3759\n",
            "Epoch 929/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0280 - val_accuracy: 0.8421 - val_loss: 16.0104\n",
            "Epoch 930/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0323 - val_accuracy: 0.8393 - val_loss: 16.6478\n",
            "Epoch 931/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0288 - val_accuracy: 0.8382 - val_loss: 15.8886\n",
            "Epoch 932/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0277 - val_accuracy: 0.8436 - val_loss: 15.5827\n",
            "Epoch 933/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0288 - val_accuracy: 0.8426 - val_loss: 16.3091\n",
            "Epoch 934/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0292 - val_accuracy: 0.8406 - val_loss: 16.6474\n",
            "Epoch 935/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0261 - val_accuracy: 0.8400 - val_loss: 17.4869\n",
            "Epoch 936/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0288 - val_accuracy: 0.8408 - val_loss: 17.1691\n",
            "Epoch 937/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0292 - val_accuracy: 0.8411 - val_loss: 16.1350\n",
            "Epoch 938/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0318 - val_accuracy: 0.8430 - val_loss: 14.7086\n",
            "Epoch 939/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0284 - val_accuracy: 0.8424 - val_loss: 14.3376\n",
            "Epoch 940/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0290 - val_accuracy: 0.8395 - val_loss: 15.1319\n",
            "Epoch 941/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0286 - val_accuracy: 0.8414 - val_loss: 15.6744\n",
            "Epoch 942/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0292 - val_accuracy: 0.8416 - val_loss: 13.7319\n",
            "Epoch 943/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0259 - val_accuracy: 0.8426 - val_loss: 14.8135\n",
            "Epoch 944/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0290 - val_accuracy: 0.8413 - val_loss: 14.2943\n",
            "Epoch 945/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0281 - val_accuracy: 0.8425 - val_loss: 14.5889\n",
            "Epoch 946/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0304 - val_accuracy: 0.8400 - val_loss: 16.2738\n",
            "Epoch 947/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0272 - val_accuracy: 0.8415 - val_loss: 15.0356\n",
            "Epoch 948/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0274 - val_accuracy: 0.8415 - val_loss: 15.4881\n",
            "Epoch 949/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0275 - val_accuracy: 0.8436 - val_loss: 15.5905\n",
            "Epoch 950/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0283 - val_accuracy: 0.8420 - val_loss: 16.2920\n",
            "Epoch 951/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0273 - val_accuracy: 0.8439 - val_loss: 15.1579\n",
            "Epoch 952/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0271 - val_accuracy: 0.8386 - val_loss: 17.6262\n",
            "Epoch 953/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0252 - val_accuracy: 0.8421 - val_loss: 16.5776\n",
            "Epoch 954/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0271 - val_accuracy: 0.8419 - val_loss: 16.4109\n",
            "Epoch 955/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0272 - val_accuracy: 0.8423 - val_loss: 17.2208\n",
            "Epoch 956/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0288 - val_accuracy: 0.8392 - val_loss: 17.3334\n",
            "Epoch 957/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0263 - val_accuracy: 0.8401 - val_loss: 17.0804\n",
            "Epoch 958/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0264 - val_accuracy: 0.8432 - val_loss: 16.8057\n",
            "Epoch 959/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0264 - val_accuracy: 0.8425 - val_loss: 16.6920\n",
            "Epoch 960/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0282 - val_accuracy: 0.8425 - val_loss: 16.4020\n",
            "Epoch 961/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0286 - val_accuracy: 0.8407 - val_loss: 17.6936\n",
            "Epoch 962/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0268 - val_accuracy: 0.8415 - val_loss: 17.2196\n",
            "Epoch 963/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0262 - val_accuracy: 0.8416 - val_loss: 16.2148\n",
            "Epoch 964/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0301 - val_accuracy: 0.8426 - val_loss: 16.0479\n",
            "Epoch 965/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0278 - val_accuracy: 0.8395 - val_loss: 16.3534\n",
            "Epoch 966/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0281 - val_accuracy: 0.8427 - val_loss: 15.1803\n",
            "Epoch 967/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0295 - val_accuracy: 0.8447 - val_loss: 15.5758\n",
            "Epoch 968/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0257 - val_accuracy: 0.8401 - val_loss: 15.0469\n",
            "Epoch 969/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0295 - val_accuracy: 0.8454 - val_loss: 14.0432\n",
            "Epoch 970/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0283 - val_accuracy: 0.8388 - val_loss: 17.4912\n",
            "Epoch 971/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0263 - val_accuracy: 0.8413 - val_loss: 15.3980\n",
            "Epoch 972/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0282 - val_accuracy: 0.8410 - val_loss: 16.5925\n",
            "Epoch 973/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0285 - val_accuracy: 0.8407 - val_loss: 16.0481\n",
            "Epoch 974/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0302 - val_accuracy: 0.8404 - val_loss: 16.8684\n",
            "Epoch 975/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0265 - val_accuracy: 0.8422 - val_loss: 17.0894\n",
            "Epoch 976/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0281 - val_accuracy: 0.8400 - val_loss: 18.5988\n",
            "Epoch 977/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0273 - val_accuracy: 0.8418 - val_loss: 17.0747\n",
            "Epoch 978/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0286 - val_accuracy: 0.8399 - val_loss: 17.3377\n",
            "Epoch 979/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0287 - val_accuracy: 0.8406 - val_loss: 16.7188\n",
            "Epoch 980/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0268 - val_accuracy: 0.8405 - val_loss: 15.3147\n",
            "Epoch 981/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0278 - val_accuracy: 0.8399 - val_loss: 17.4013\n",
            "Epoch 982/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0308 - val_accuracy: 0.8423 - val_loss: 16.0638\n",
            "Epoch 983/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0303 - val_accuracy: 0.8396 - val_loss: 17.1995\n",
            "Epoch 984/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0255 - val_accuracy: 0.8434 - val_loss: 15.2397\n",
            "Epoch 985/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0311 - val_accuracy: 0.8388 - val_loss: 16.8616\n",
            "Epoch 986/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0296 - val_accuracy: 0.8435 - val_loss: 16.7163\n",
            "Epoch 987/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0317 - val_accuracy: 0.8418 - val_loss: 16.3018\n",
            "Epoch 988/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0287 - val_accuracy: 0.8422 - val_loss: 17.2249\n",
            "Epoch 989/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0276 - val_accuracy: 0.8443 - val_loss: 17.0494\n",
            "Epoch 990/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0284 - val_accuracy: 0.8411 - val_loss: 16.7231\n",
            "Epoch 991/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0272 - val_accuracy: 0.8426 - val_loss: 16.5069\n",
            "Epoch 992/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0310 - val_accuracy: 0.8411 - val_loss: 16.3386\n",
            "Epoch 993/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0277 - val_accuracy: 0.8416 - val_loss: 14.2066\n",
            "Epoch 994/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0266 - val_accuracy: 0.8448 - val_loss: 15.1446\n",
            "Epoch 995/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0291 - val_accuracy: 0.8397 - val_loss: 17.6798\n",
            "Epoch 996/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0260 - val_accuracy: 0.8437 - val_loss: 15.8868\n",
            "Epoch 997/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0291 - val_accuracy: 0.8430 - val_loss: 16.1980\n",
            "Epoch 998/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0261 - val_accuracy: 0.8414 - val_loss: 14.8729\n",
            "Epoch 999/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0274 - val_accuracy: 0.8412 - val_loss: 16.2114\n",
            "Epoch 1000/1000\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0296 - val_accuracy: 0.8391 - val_loss: 16.7902\n",
            "Best Epoch: 21\n",
            "Metrics for Best Epoch 21:\n",
            "val_loss: 0.382633775472641\n",
            "val_accuracy: 0.8957072496414185\n",
            "train_loss: 0.05859700217843056\n",
            "train_accuracy: 0.9769566059112549\n",
            "\u001b[1m2208/2208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.8403 - loss: 17.1168\n",
            "Test Accuracy: 0.8395996689796448\n",
            "\u001b[1m2208/2208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 678us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.71      0.82     35120\n",
            "           1       0.77      0.96      0.86     35522\n",
            "\n",
            "    accuracy                           0.84     70642\n",
            "   macro avg       0.86      0.84      0.84     70642\n",
            "weighted avg       0.86      0.84      0.84     70642\n",
            "\n",
            "[[25077 10043]\n",
            " [ 1288 34234]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Assuming X is your TF-IDF array and y is the corresponding labels\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "y_encoded = to_categorical(y_encoded)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a simple neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=y_encoded.shape[1], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model and store the history\n",
        "history = model.fit(X_train, y_train, epochs=1000, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Find the best performing epoch\n",
        "best_epoch = np.argmax(history.history['val_accuracy'])\n",
        "print(f\"Best Epoch: {best_epoch + 1}\")\n",
        "\n",
        "# Print out all metrics for the best performing epoch\n",
        "best_metrics = {\n",
        "    \"val_loss\": history.history['val_loss'][best_epoch],\n",
        "    \"val_accuracy\": history.history['val_accuracy'][best_epoch],\n",
        "    \"train_loss\": history.history['loss'][best_epoch],\n",
        "    \"train_accuracy\": history.history['accuracy'][best_epoch]\n",
        "}\n",
        "\n",
        "print(f\"Metrics for Best Epoch {best_epoch + 1}:\")\n",
        "for key, value in best_metrics.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(classification_report(y_test_classes, y_pred_classes))\n",
        "print(confusion_matrix(y_test_classes, y_pred_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a4b62e0",
      "metadata": {
        "id": "0a4b62e0",
        "outputId": "6ffb0ec4-8e77-43b4-d827-3c2de947fa0e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.8050 - loss: 0.3846 - val_accuracy: 0.8723 - val_loss: 0.2697\n",
            "Epoch 2/10\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8875 - loss: 0.2478 - val_accuracy: 0.8814 - val_loss: 0.2511\n",
            "Epoch 3/10\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2012 - val_accuracy: 0.8844 - val_loss: 0.2514\n",
            "Epoch 4/10\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9290 - loss: 0.1698 - val_accuracy: 0.8906 - val_loss: 0.2446\n",
            "Epoch 5/10\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9401 - loss: 0.1453 - val_accuracy: 0.8928 - val_loss: 0.2516\n",
            "Epoch 6/10\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9483 - loss: 0.1287 - val_accuracy: 0.8936 - val_loss: 0.2576\n",
            "Epoch 7/10\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9550 - loss: 0.1126 - val_accuracy: 0.8940 - val_loss: 0.2637\n",
            "Epoch 8/10\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9588 - loss: 0.1026 - val_accuracy: 0.8940 - val_loss: 0.2750\n",
            "Epoch 9/10\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9630 - loss: 0.0948 - val_accuracy: 0.8933 - val_loss: 0.2866\n",
            "Epoch 10/10\n",
            "\u001b[1m3533/3533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9653 - loss: 0.0878 - val_accuracy: 0.8947 - val_loss: 0.2917\n",
            "\u001b[1m2208/2208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 725us/step - accuracy: 0.8920 - loss: 0.2942\n",
            "Accuracy: 0.8922737240791321\n",
            "\u001b[1m2208/2208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 787us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.87      0.89     35120\n",
            "           1       0.88      0.92      0.90     35522\n",
            "\n",
            "    accuracy                           0.89     70642\n",
            "   macro avg       0.89      0.89      0.89     70642\n",
            "weighted avg       0.89      0.89      0.89     70642\n",
            "\n",
            "[[30481  4639]\n",
            " [ 2971 32551]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Assuming X is your TF-IDF array and y is the corresponding labels\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "y_encoded = to_categorical(y_encoded)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a simple neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=y_encoded.shape[1], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(classification_report(y_test_classes, y_pred_classes))\n",
        "print(confusion_matrix(y_test_classes, y_pred_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70167c12-0af9-4d87-9c1f-c30e31f79956",
      "metadata": {
        "id": "70167c12-0af9-4d87-9c1f-c30e31f79956"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "params = {'hidden_layer_sizes': [(100,), (50,50)], 'activation': ['relu', 'tanh'], 'solver': ['adam', 'sgd']}\n",
        "mlp = GridSearchCV(MLPClassifier(max_iter=500), params, cv=5)\n",
        "mlp.fit(X_train, y_train)\n",
        "evaluate_model(mlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82a491b5-6f68-4b7b-9908-a23e8eef2e9d",
      "metadata": {
        "id": "82a491b5-6f68-4b7b-9908-a23e8eef2e9d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Assuming X is your TF-IDF array and y is the corresponding labels\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "y_encoded = to_categorical(y_encoded)\n",
        "\n",
        "# Check the number of classes\n",
        "num_classes = y_encoded.shape[1]\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a simple neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=num_classes, activation='softmax'))  # Ensure correct number of classes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert predictions to class labels\n",
        "y_test_classes = np.argmax(y_test, axis=1)  # Convert true labels to class labels\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(classification_report(y_test_classes, y_pred_classes))\n",
        "print(confusion_matrix(y_test_classes, y_pred_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea1bd699-1857-49c5-a1d0-9142246905f3",
      "metadata": {
        "id": "ea1bd699-1857-49c5-a1d0-9142246905f3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "# Example RNN model for sequence data (like TF-IDF as sequences)\n",
        "model = Sequential([\n",
        "    LSTM(128, input_shape=(X_train.shape[1], 1)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "evaluate_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b59d3a8-969b-4512-8e70-ba0b98977982",
      "metadata": {
        "id": "2b59d3a8-969b-4512-8e70-ba0b98977982"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential  # Ensure this import is included"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd063c7d-2ad6-4bf6-9cee-5fe43e2e27d0",
      "metadata": {
        "id": "dd063c7d-2ad6-4bf6-9cee-5fe43e2e27d0"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "params = {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1]}\n",
        "ada = GridSearchCV(AdaBoostClassifier(), params, cv=5)\n",
        "ada.fit(X_train, y_train)\n",
        "evaluate_model(ada)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7360a8f",
      "metadata": {
        "id": "a7360a8f"
      },
      "source": [
        "# UNABLE TO ALLOCATE MEMORY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca482642-90f7-41ad-9e45-441f854d9994",
      "metadata": {
        "id": "ca482642-90f7-41ad-9e45-441f854d9994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "8fd77453-e365-4b6b-a991-19ee8f1288b9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-186838f46462>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m  \u001b[0;31m# Labels should be a 1D array with either 0 or 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "y = df['label'].values  # Labels should be a 1D array with either 0 or 1\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define the Bagging Classifier with appropriate parameters for large datasets\n",
        "bagging = BaggingClassifier(n_estimators=50, max_samples=0.5, max_features=0.8, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Fit the model using only half of the dataset\n",
        "bagging.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the reduced test set\n",
        "y_pred_half = bagging.predict(X_test)\n",
        "\n",
        "# Print accuracy\n",
        "accuracy = bagging.score(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eae9d4e0",
      "metadata": {
        "id": "eae9d4e0"
      },
      "outputs": [],
      "source": [
        "print(y[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0b4fc5d-e082-4500-9d80-b503d7f48ed4",
      "metadata": {
        "id": "e0b4fc5d-e082-4500-9d80-b503d7f48ed4"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "word2vec_model = KeyedVectors.load_word2vec_format(r'C:\\Users\\brotz\\Downloads\\dataset\\GoogleNews-vectors-negative300.bin', binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f05e02b9-9b6e-469c-90be-f384eba6da97",
      "metadata": {
        "id": "f05e02b9-9b6e-469c-90be-f384eba6da97"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initialize an empty dictionary to store the GloVe embeddings\n",
        "glove_embeddings = {}\n",
        "\n",
        "# Path to the GloVe file\n",
        "glove_file_path = r'C:\\Users\\brotz\\Downloads\\dataset\\glove.840B.300d.txt'\n",
        "\n",
        "# Open the GloVe file\n",
        "with open(glove_file_path, \"r\", encoding=\"utf8\") as f:\n",
        "    # Iterate over each line in the file\n",
        "    for line in f:\n",
        "        # Split the line into words and vectors\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        try:\n",
        "            # Convert the remaining values into a numpy array of floats\n",
        "            vector = np.asarray(values[1:], dtype=\"float32\")\n",
        "            # Add the word and its vector to the dictionary\n",
        "            glove_embeddings[word] = vector\n",
        "        except ValueError as e:\n",
        "            # If there's an error, print the problematic line and skip it\n",
        "            print(f\"Skipping line due to error: {e}\")\n",
        "            print(f\"Problematic line: {line}\")\n",
        "            continue\n",
        "\n",
        "# Example usage: Get the vector for the word 'king'\n",
        "king_vector = glove_embeddings.get('king')\n",
        "\n",
        "# Print the vector for 'king'\n",
        "print(\"Vector for 'king':\", king_vector)\n",
        "\n",
        "# Check the total number of words loaded\n",
        "print(f\"Total number of words loaded: {len(glove_embeddings)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e91cd91-5a6a-4cd7-a8d4-81213671c98c",
      "metadata": {
        "id": "8e91cd91-5a6a-4cd7-a8d4-81213671c98c",
        "outputId": "a39f9c70-558d-4ed6-a43a-9cbd0293147e",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\brotz\\AppData\\Local\\Temp\\ipykernel_129784\\1868560175.py:3: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
            "  fasttext_model = FastText.load_fasttext_format(r'C:\\Users\\brotz\\Downloads\\dataset\\cc.en.300.bin')\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import FastText\n",
        "\n",
        "fasttext_model = FastText.load_fasttext_format(r'C:\\Users\\brotz\\Downloads\\dataset\\cc.en.300.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da3419f5-d744-45ac-bfa5-9e4605567e76",
      "metadata": {
        "id": "da3419f5-d744-45ac-bfa5-9e4605567e76"
      },
      "outputs": [],
      "source": [
        "from gensim.models import FastText\n",
        "\n",
        "# Load the pre-trained FastText vectors\n",
        "fasttext_model = FastText.load_facebook_vectors(r'C:\\Users\\brotz\\Downloads\\dataset\\cc.en.300.bin')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48949acb-2d5d-4018-80d4-20b7b6f56791",
      "metadata": {
        "id": "48949acb-2d5d-4018-80d4-20b7b6f56791"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Load the GloVe model directly using Gensim\n",
        "glove_file_path = 'C:/Users/brotz/Downloads/dataset/glove.840B.300d.txt'\n",
        "glove_model = KeyedVectors.load_word2vec_format(glove_file_path, binary=False, no_header=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53a2bf15-4f09-4dfd-acdf-3baa1b9d93f6",
      "metadata": {
        "id": "53a2bf15-4f09-4dfd-acdf-3baa1b9d93f6"
      },
      "outputs": [],
      "source": [
        "# Example: Get the vector for the word 'king'\n",
        "print(glove_model['king'])\n",
        "\n",
        "# Check the total number of words loaded\n",
        "print(f\"Total number of words in vocabulary: {len(glove_model.key_to_index)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eaaa940-4697-4045-8f21-19192fb5f259",
      "metadata": {
        "id": "7eaaa940-4697-4045-8f21-19192fb5f259"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Function to compute Word2Vec embeddings\n",
        "def get_word2vec_embedding(text):\n",
        "    vectors = [word2vec_model[word] for word in text if word in word2vec_model]\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(word2vec_model.vector_size)  # Return a zero vector if none of the words are in the model\n",
        "\n",
        "# Function to compute GloVe embeddings\n",
        "def get_glove_embedding(text):\n",
        "    vectors = [model_glove[word] for word in text if word in model_glove]\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(300)  # Assuming GloVe vectors are 300-dimensional\n",
        "\n",
        "def get_fasttext_embedding(text):\n",
        "    vectors = [fasttext_model.get_vector(word) for word in text if word in fasttext_model.key_to_index]\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(fasttext_model.vector_size)  # Return a zero vector if none of the words are in the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aee2a79-cefa-4637-bd2f-6cc019530837",
      "metadata": {
        "id": "2aee2a79-cefa-4637-bd2f-6cc019530837"
      },
      "outputs": [],
      "source": [
        "# Applying the functions to the 'cleaned_text' column in the DataFrame\n",
        "merged_data_all['word2vec_embedding'] = merged_data_all['cleaned_text'].apply(get_word2vec_embedding)\n",
        "\n",
        "# Check the result\n",
        "print(merged_data_all.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3e85d1f-d036-4ac8-abac-b94297f239be",
      "metadata": {
        "id": "d3e85d1f-d036-4ac8-abac-b94297f239be"
      },
      "outputs": [],
      "source": [
        "merged_data_all['glove_embedding'] = merged_data_all['cleaned_text'].apply(get_glove_embedding)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04949d04-4aab-45f1-9bc0-26bf3d1bec02",
      "metadata": {
        "id": "04949d04-4aab-45f1-9bc0-26bf3d1bec02"
      },
      "outputs": [],
      "source": [
        "def get_fasttext_embedding(text):\n",
        "    vectors = [fasttext_model.wv.get_vector(word) for word in text if word in fasttext_model.wv]\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(fasttext_model.wv.vector_size)  # Return a zero vector if none of the words are in the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4c0f4ee-2f8b-4ac8-a533-0de184e6cc99",
      "metadata": {
        "id": "c4c0f4ee-2f8b-4ac8-a533-0de184e6cc99"
      },
      "outputs": [],
      "source": [
        "merged_data_all['fasttext_embedding'] = merged_data_all['cleaned_text'].apply(get_fasttext_embedding)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae6819f3-42e7-44e6-a35c-bdc37a0d4432",
      "metadata": {
        "id": "ae6819f3-42e7-44e6-a35c-bdc37a0d4432"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Function to compute Word2Vec embeddings\n",
        "def get_word2vec_embedding(text):\n",
        "    vectors = [word2vec_model[word] for word in text if word in word2vec_model]\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(word2vec_model.vector_size)  # Return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d557d8a8-9bc1-466c-8edc-f1c8cf033d8f",
      "metadata": {
        "id": "d557d8a8-9bc1-466c-8edc-f1c8cf033d8f",
        "outputId": "705c76da-e791-4e0f-9ab1-e996f61e44c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Word2Vec Embedding ---\n",
            "Accuracy: 0.5518460421885608\n",
            "ROC-AUC: 0.5908561082637679\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.14      0.22     75379\n",
            "           1       0.56      0.87      0.69     95473\n",
            "\n",
            "    accuracy                           0.55    170852\n",
            "   macro avg       0.52      0.51      0.45    170852\n",
            "weighted avg       0.52      0.55      0.48    170852\n",
            "\n",
            "\n",
            "\n",
            "--- GloVe Embedding ---\n",
            "Accuracy: 0.5551998220682228\n",
            "ROC-AUC: 0.5933668269638811\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.17      0.26     75379\n",
            "           1       0.57      0.86      0.68     95473\n",
            "\n",
            "    accuracy                           0.56    170852\n",
            "   macro avg       0.53      0.51      0.47    170852\n",
            "weighted avg       0.53      0.56      0.49    170852\n",
            "\n",
            "\n",
            "\n",
            "--- FastText Embedding ---\n",
            "Accuracy: 0.5566045466251492\n",
            "ROC-AUC: 0.6028148477020289\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.20      0.28     75379\n",
            "           1       0.57      0.84      0.68     95473\n",
            "\n",
            "    accuracy                           0.56    170852\n",
            "   macro avg       0.53      0.52      0.48    170852\n",
            "weighted avg       0.54      0.56      0.50    170852\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
        "\n",
        "# Assuming 'label' is the target column in your dataframe\n",
        "X_word2vec = np.stack(merged_data_all['word2vec_embedding'].values)\n",
        "X_glove = np.stack(merged_data_all['glove_embedding'].values)\n",
        "X_fasttext = np.stack(merged_data_all['fasttext_embedding'].values)\n",
        "y = merged_data_all['label'].values  # replace 'label' with the actual column name of your target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train_w2v, X_test_w2v, y_train, y_test = train_test_split(X_word2vec, y, test_size=0.2, random_state=42)\n",
        "X_train_glove, X_test_glove, _, _ = train_test_split(X_glove, y, test_size=0.2, random_state=42)\n",
        "X_train_fasttext, X_test_fasttext, _, _ = train_test_split(X_fasttext, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Function to train and evaluate the model\n",
        "def evaluate_model(X_train, X_test, y_train, y_test, model_name):\n",
        "    logreg.fit(X_train, y_train)\n",
        "    y_pred = logreg.predict(X_test)\n",
        "    y_pred_prob = logreg.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(f\"--- {model_name} ---\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"ROC-AUC:\", roc_auc_score(y_test, y_pred_prob))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Evaluate on each embedding type\n",
        "evaluate_model(X_train_w2v, X_test_w2v, y_train, y_test, \"Word2Vec Embedding\")\n",
        "evaluate_model(X_train_glove, X_test_glove, y_train, y_test, \"GloVe Embedding\")\n",
        "evaluate_model(X_train_fasttext, X_test_fasttext, y_train, y_test, \"FastText Embedding\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcdbcc2e-5904-4aae-96bb-d5f6ed492548",
      "metadata": {
        "id": "dcdbcc2e-5904-4aae-96bb-d5f6ed492548"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel, RobertaTokenizer, RobertaModel, GPT2Tokenizer, GPT2Model\n",
        "import torch\n",
        "\n",
        "# Load BERT model and tokenizer\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load RoBERTa model and tokenizer\n",
        "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "roberta_model = RobertaModel.from_pretrained('roberta-base')\n",
        "\n",
        "# Load GPT-2 model and tokenizer\n",
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "gpt2_model = GPT2Model.from_pretrained('gpt2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df1d74d6-b63b-4ce6-b2d5-83560494a279",
      "metadata": {
        "id": "df1d74d6-b63b-4ce6-b2d5-83560494a279"
      },
      "outputs": [],
      "source": [
        "set HF_HUB_DISABLE_SYMLINKS_WARNING=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37344115-23c2-4f04-8520-3e87c2433f47",
      "metadata": {
        "id": "37344115-23c2-4f04-8520-3e87c2433f47"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bc7f7c5-c6e6-47c8-8d08-5e5455dd94e4",
      "metadata": {
        "id": "2bc7f7c5-c6e6-47c8-8d08-5e5455dd94e4"
      },
      "outputs": [],
      "source": [
        "def extract_embeddings(text, tokenizer, model):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "def get_bert_embedding(text):\n",
        "    return extract_embeddings(text, bert_tokenizer, bert_model)\n",
        "\n",
        "def get_roberta_embedding(text):\n",
        "    return extract_embeddings(text, roberta_tokenizer, roberta_model)\n",
        "\n",
        "def get_gpt2_embedding(text):\n",
        "    return extract_embeddings(text, gpt2_tokenizer, gpt2_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c941b02a-cd7d-41c3-8e88-6ce7cbeb3365",
      "metadata": {
        "id": "c941b02a-cd7d-41c3-8e88-6ce7cbeb3365"
      },
      "outputs": [],
      "source": [
        "pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15a30e86-93c4-4b81-8c38-78b1bd39edef",
      "metadata": {
        "id": "15a30e86-93c4-4b81-8c38-78b1bd39edef"
      },
      "outputs": [],
      "source": [
        "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd2dc066-6c2b-4083-beeb-0280e55ba01a",
      "metadata": {
        "id": "cd2dc066-6c2b-4083-beeb-0280e55ba01a",
        "outputId": "10f5bdd9-ed53-451a-d5bf-bb919de32ef6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   8%|▊         | 135/1709 [17:31:00<259:13:34, 592.89s/it]"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Example for a small batch size (due to memory constraints)\n",
        "batch_size = 500\n",
        "bert_embeddings = []\n",
        "roberta_embeddings = []\n",
        "gpt2_embeddings = []\n",
        "\n",
        "# Wrap the loop with tqdm for a progress bar\n",
        "for i in tqdm(range(0, len(merged_data_all), batch_size), desc=\"Processing batches\"):\n",
        "    batch_texts = merged_data_all['cleaned_text'][i:i+batch_size]\n",
        "    bert_batch = [get_bert_embedding(text) for text in batch_texts]\n",
        "    roberta_batch = [get_roberta_embedding(text) for text in batch_texts]\n",
        "    gpt2_batch = [get_gpt2_embedding(text) for text in batch_texts]\n",
        "\n",
        "    bert_embeddings.extend(bert_batch)\n",
        "    roberta_embeddings.extend(roberta_batch)\n",
        "    gpt2_embeddings.extend(gpt2_batch)\n",
        "\n",
        "# Convert lists to DataFrame columns\n",
        "merged_data_all['bert_embedding'] = bert_embeddings\n",
        "merged_data_all['roberta_embedding'] = roberta_embeddings\n",
        "merged_data_all['gpt2_embedding'] = gpt2_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c402ed3c-cd74-4d12-9dcb-9c9eebd2fc97",
      "metadata": {
        "id": "c402ed3c-cd74-4d12-9dcb-9c9eebd2fc97"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Assuming you have a target variable 'label' in your DataFrame\n",
        "\n",
        "def evaluate_embeddings(embeddings, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(embeddings, y, test_size=0.2, random_state=42)\n",
        "    clf = LogisticRegression(max_iter=1000)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Evaluate BERT embeddings\n",
        "evaluate_embeddings(merged_data_all['bert_embedding'].tolist(), merged_data_all['label'])\n",
        "\n",
        "# Evaluate RoBERTa embeddings\n",
        "evaluate_embeddings(merged_data_all['roberta_embedding'].tolist(), merged_data_all['label'])\n",
        "\n",
        "# Evaluate GPT-2 embeddings\n",
        "evaluate_embeddings(merged_data_all['gpt2_embedding'].tolist(), merged_data_all['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5174742-fe1b-4179-9bc9-b68228849eb7",
      "metadata": {
        "id": "e5174742-fe1b-4179-9bc9-b68228849eb7"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "# Define the SGD Classifier with chosen parameters\n",
        "sgd = SGDClassifier(loss='hinge', alpha=0.0001, max_iter=1000, tol=1e-3, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "sgd.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = sgd.predict(X_test)\n",
        "\n",
        "# Print accuracy\n",
        "accuracy = sgd.score(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d653ee1b-84f5-44ac-8e01-0ec940de832e",
      "metadata": {
        "id": "d653ee1b-84f5-44ac-8e01-0ec940de832e"
      },
      "outputs": [],
      "source": [
        "# Using a simple custom implementation as an example\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "class ELMClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, n_hidden=100):\n",
        "        self.n_hidden = n_hidden\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.input_weights = np.random.randn(X.shape[1], self.n_hidden)\n",
        "        self.biases = np.random.randn(self.n_hidden)\n",
        "        self.hidden_output = np.tanh(np.dot(X, self.input_weights) + self.biases)\n",
        "        self.output_weights = np.dot(np.linalg.pinv(self.hidden_output), y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        hidden_output = np.tanh(np.dot(X, self.input_weights) + self.biases)\n",
        "        return np.dot(hidden_output, self.output_weights)\n",
        "\n",
        "elm = ELMClassifier(n_hidden=200)\n",
        "elm.fit(X_train, y_train)\n",
        "evaluate_model(elm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc572b61-5dfa-441e-9c9d-86a1d39a4e23",
      "metadata": {
        "id": "cc572b61-5dfa-441e-9c9d-86a1d39a4e23"
      },
      "outputs": [],
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_train, y_train)\n",
        "evaluate_model(lda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b5def99-209f-408d-ad5a-c61693e5d7eb",
      "metadata": {
        "id": "8b5def99-209f-408d-ad5a-c61693e5d7eb"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
        "\n",
        "# Assuming X and y are your features and target variables\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# Set up the hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 6, 10],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "    'gamma': [0, 0.1, 0.3],\n",
        "    'reg_alpha': [0, 0.1, 1],\n",
        "    'reg_lambda': [1, 1.5, 2]\n",
        "}\n",
        "\n",
        "# Use GridSearchCV to tune hyperparameters\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid,\n",
        "                           scoring='roc_auc', cv=5, verbose=1, n_jobs=-1)\n",
        "\n",
        "# Fit the model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters from GridSearch\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Use the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"AUC-ROC: {roc_auc_score(y_test, y_pred):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40d8e72e-69ce-41f9-a823-0b3093ed82bd",
      "metadata": {
        "id": "40d8e72e-69ce-41f9-a823-0b3093ed82bd",
        "outputId": "d8cde197-1c73-4efd-9e6a-43a43e124d67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            " [[26311  8809]\n",
            " [ 7171 28351]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.75      0.77     35120\n",
            "           1       0.76      0.80      0.78     35522\n",
            "\n",
            "    accuracy                           0.77     70642\n",
            "   macro avg       0.77      0.77      0.77     70642\n",
            "weighted avg       0.77      0.77      0.77     70642\n",
            "\n",
            "Accuracy: 0.7738\n",
            "Precision: 0.7629\n",
            "Recall: 0.7981\n",
            "F1-Score: 0.7801\n",
            "AUC-ROC: 0.7736\n"
          ]
        }
      ],
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "qda = QuadraticDiscriminantAnalysis()\n",
        "qda.fit(X_train, y_train)\n",
        "evaluate_model(qda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e42c0a4-2468-4911-9b08-59d202e19873",
      "metadata": {
        "id": "3e42c0a4-2468-4911-9b08-59d202e19873"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming you have your dataset loaded as X and y\n",
        "# For demonstration purposes, let's assume X and y are your feature matrix and labels\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Perceptron model with desired parameters\n",
        "perceptron = Perceptron(max_iter=1000, penalty=None, alpha=0.0001)\n",
        "\n",
        "# Train the model\n",
        "perceptron.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = perceptron.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_test, y_test, y_pred):\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='binary')\n",
        "    recall = recall_score(y_test, y_pred, average='binary')\n",
        "    f1 = f1_score(y_test, y_pred, average='binary')\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Call the evaluation function\n",
        "evaluate_model(perceptron, X_test, y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c94e630f-9edc-4b1d-87a5-7c53a351250a",
      "metadata": {
        "id": "c94e630f-9edc-4b1d-87a5-7c53a351250a"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "voting = VotingClassifier(estimators=[\n",
        "    ('lr', LogisticRegression()),\n",
        "    ('svc', SVC(kernel='linear', probability=True)),\n",
        "    ('rf', RandomForestClassifier(n_estimators=100))\n",
        "], voting='soft')\n",
        "\n",
        "voting.fit(X_train, y_train)\n",
        "evaluate_model(voting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f49782f-bf4f-4d8f-be96-f6975ec10df8",
      "metadata": {
        "id": "6f49782f-bf4f-4d8f-be96-f6975ec10df8"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "stacking = StackingClassifier(estimators=[\n",
        "    ('lr', LogisticRegression()),\n",
        "    ('svc', SVC(kernel='linear'))\n",
        "], final_estimator=RandomForestClassifier(n_estimators=100))\n",
        "\n",
        "stacking.fit(X_train, y_train)\n",
        "evaluate_model(stacking)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b71d9f8-a0ec-4695-895b-7b5fd9e54d67",
      "metadata": {
        "id": "6b71d9f8-a0ec-4695-895b-7b5fd9e54d67"
      },
      "outputs": [],
      "source": [
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
        "\n",
        "# Assume X is a DataFrame\n",
        "model = BayesianModel([('A', 'B'), ('B', 'C')])  # Example structure\n",
        "model.fit(X, estimator=MaximumLikelihoodEstimator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "061f8526-9c0c-4607-a4e3-feff5e2b1225",
      "metadata": {
        "id": "061f8526-9c0c-4607-a4e3-feff5e2b1225"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "params = {'num_leaves': [31, 50], 'learning_rate': [0.05, 0.1], 'n_estimators': [50, 100]}\n",
        "lgbm = GridSearchCV(lgb.LGBMClassifier(), params, cv=5)\n",
        "lgbm.fit(X_train, y_train)\n",
        "evaluate_model(lgbm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62b95541-d49b-4c3c-97de-04b640cfeac2",
      "metadata": {
        "id": "62b95541-d49b-4c3c-97de-04b640cfeac2"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "\n",
        "params = {'iterations': [100, 200], 'learning_rate': [0.01, 0.1], 'depth': [4, 6, 10]}\n",
        "catboost = GridSearchCV(CatBoostClassifier(verbose=0), params, cv=5)\n",
        "catboost.fit(X_train, y_train)\n",
        "evaluate_model(catboost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5768e73-cfda-4209-90cf-e3765b1ec022",
      "metadata": {
        "id": "a5768e73-cfda-4209-90cf-e3765b1ec022"
      },
      "outputs": [],
      "source": [
        "from tpot import TPOTClassifier\n",
        "\n",
        "tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2)\n",
        "tpot.fit(X_train, y_train)\n",
        "evaluate_model(tpot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fba1bbf6-df86-4b49-bdc0-f0159bd74ac1",
      "metadata": {
        "id": "fba1bbf6-df86-4b49-bdc0-f0159bd74ac1"
      },
      "outputs": [],
      "source": [
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "\n",
        "params = {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]}\n",
        "balanced_rf = GridSearchCV(BalancedRandomForestClassifier(), params, cv=5)\n",
        "balanced_rf.fit(X_train, y_train)\n",
        "evaluate_model(balanced_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd725d79-aafc-49f7-82ba-57115a96cc99",
      "metadata": {
        "id": "dd725d79-aafc-49f7-82ba-57115a96cc99"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "smote_pipeline = Pipeline([\n",
        "    ('smote', SMOTE()),\n",
        "    ('lr', LogisticRegression())\n",
        "])\n",
        "\n",
        "smote_pipeline.fit(X_train, y_train)\n",
        "evaluate_model(smote_pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "323e7a1b-18c1-4899-8543-ee74ece328ab",
      "metadata": {
        "id": "323e7a1b-18c1-4899-8543-ee74ece328ab"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "ocsvm = OneClassSVM(gamma='auto')\n",
        "ocsvm.fit(X_train)\n",
        "evaluate_model(ocsvm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7f966a8-1fb2-4a95-a6c2-1d19e7dcb9a7",
      "metadata": {
        "id": "d7f966a8-1fb2-4a95-a6c2-1d19e7dcb9a7"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "params = {'C': [0.1, 1, 10]}\n",
        "svc_linear = GridSearchCV(SVC(kernel='linear'), params, cv=5)\n",
        "svc_linear.fit(X_train, y_train)\n",
        "evaluate_model(svc_linear)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e47a66c3-d9e6-4f11-99df-b24445675c80",
      "metadata": {
        "id": "e47a66c3-d9e6-4f11-99df-b24445675c80"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define base models\n",
        "base_learners = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
        "]\n",
        "\n",
        "# Define meta-learner (e.g., Logistic Regression)\n",
        "meta_learner = LogisticRegression()\n",
        "\n",
        "# Create stacking classifier\n",
        "stacking_model = StackingClassifier(estimators=base_learners, final_estimator=meta_learner, cv=5)\n",
        "\n",
        "# Train the model\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_stack = stacking_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(f\"Stacking Model Accuracy: {accuracy_score(y_test, y_pred_stack):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3fdbfcd-32d2-4b06-99ad-3fd0e8307a8e",
      "metadata": {
        "id": "b3fdbfcd-32d2-4b06-99ad-3fd0e8307a8e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define models\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train models\n",
        "rf_model.fit(X_train, y_train)\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "rf_pred = rf_model.predict_proba(X_test)[:, 1]\n",
        "gb_pred = gb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Average the predictions\n",
        "blended_pred = (rf_pred + gb_pred) / 2\n",
        "blended_pred = np.round(blended_pred)\n",
        "\n",
        "# Evaluate the model\n",
        "print(f\"Blended Model Accuracy: {accuracy_score(y_test, blended_pred):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67613b38-ddcd-4f1b-b023-65cc125b92e5",
      "metadata": {
        "id": "67613b38-ddcd-4f1b-b023-65cc125b92e5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Assuming X and y are your feature matrix and target vector\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to evaluate models\n",
        "def evaluate_model(model):\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_test, y_pred):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "074992b4-3e1e-4dae-b0e2-8f31e8441a93",
      "metadata": {
        "id": "074992b4-3e1e-4dae-b0e2-8f31e8441a93"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import Classifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the base model (e.g., a shallow decision tree)\n",
        "base_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "\n",
        "# Create a bagging classifier using the base model\n",
        "bagging_model = BaggingClassifier(base_estimator=base_model, n_estimators=100, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Train the model\n",
        "bagging_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_bagging = bagging_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(f\"Bagging Model Accuracy: {accuracy_score(y_test, y_pred_bagging):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "619cd258-2d59-45b4-b88b-0a28cd5df922",
      "metadata": {
        "id": "619cd258-2d59-45b4-b88b-0a28cd5df922"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {\n",
        "    'num_leaves': [31, 50],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [-1, 10, 20]\n",
        "}\n",
        "\n",
        "lgbm = GridSearchCV(lgb.LGBMClassifier(), params, cv=5, scoring='roc_auc')\n",
        "lgbm.fit(X_train, y_train)\n",
        "evaluate_model(lgbm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ca4cbdb-03a0-43a1-bfa4-cc10016625ce",
      "metadata": {
        "id": "4ca4cbdb-03a0-43a1-bfa4-cc10016625ce"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "\n",
        "params = {\n",
        "    'iterations': [100, 200],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'depth': [4, 6, 10]\n",
        "}\n",
        "\n",
        "catboost = GridSearchCV(CatBoostClassifier(verbose=0), params, cv=5, scoring='roc_auc')\n",
        "catboost.fit(X_train, y_train)\n",
        "evaluate_model(catboost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea1d0321-94ac-4104-9905-5126bbe24c0c",
      "metadata": {
        "id": "ea1d0321-94ac-4104-9905-5126bbe24c0c"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07c1bc524fd84f5aa80202f68dc24e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80d6679d2eef4e388f68ae5bdf4fec7b",
            "placeholder": "​",
            "style": "IPY_MODEL_9ed334a3727743b39d0bdeeb30ffe087",
            "value": "config.json: 100%"
          }
        },
        "1c6413db129149e5a2f644b240391b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b468f44e1f34f47b8ad3e60036bc211",
              "IPY_MODEL_be5ac41050b94bd989a3dd9535f6d43f",
              "IPY_MODEL_95e1d3e39ccc4a4d98803aa7247ee3f7"
            ],
            "layout": "IPY_MODEL_a77cf6ad00604f1a96f2b3fa8bb00e4b"
          }
        },
        "29472bd9db614cd9906722f822c9e564": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3179c5bfaabb4b2bb4731af9f7e36b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34315f95134e474b8da02e1d77c0d3f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3793226a04b1400abbe6c60787b41077": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d9608da2643435dba42011e07778e1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bb7ed1d5b6547c5b8afadddac6b45d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4da251e8e1834c18a6c400c688ffcd10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56d7d9603f974139855337ad10bec443": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b468f44e1f34f47b8ad3e60036bc211": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d9608da2643435dba42011e07778e1b",
            "placeholder": "​",
            "style": "IPY_MODEL_4da251e8e1834c18a6c400c688ffcd10",
            "value": "model.safetensors: 100%"
          }
        },
        "707b1a211d344f0c99755d0a9f3d2b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bab332da551d4af696e8c342414d61a0",
            "max": 480,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b6e7eb388fd477abfa8dd28666513b6",
            "value": 480
          }
        },
        "7b6e7eb388fd477abfa8dd28666513b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80d6679d2eef4e388f68ae5bdf4fec7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95e1d3e39ccc4a4d98803aa7247ee3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29472bd9db614cd9906722f822c9e564",
            "placeholder": "​",
            "style": "IPY_MODEL_3793226a04b1400abbe6c60787b41077",
            "value": " 331M/331M [00:01&lt;00:00, 381MB/s]"
          }
        },
        "9ed334a3727743b39d0bdeeb30ffe087": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a77cf6ad00604f1a96f2b3fa8bb00e4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bab332da551d4af696e8c342414d61a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be5ac41050b94bd989a3dd9535f6d43f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56d7d9603f974139855337ad10bec443",
            "max": 331055963,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34315f95134e474b8da02e1d77c0d3f8",
            "value": 331055963
          }
        },
        "cd03c56de1a9426890be497bc8ccfa8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8dc96676f604976bd45e6aaa23ab334": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07c1bc524fd84f5aa80202f68dc24e1c",
              "IPY_MODEL_707b1a211d344f0c99755d0a9f3d2b08",
              "IPY_MODEL_f720ec05054b4f5f8363599332a2d2ad"
            ],
            "layout": "IPY_MODEL_cd03c56de1a9426890be497bc8ccfa8a"
          }
        },
        "f720ec05054b4f5f8363599332a2d2ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bb7ed1d5b6547c5b8afadddac6b45d3",
            "placeholder": "​",
            "style": "IPY_MODEL_3179c5bfaabb4b2bb4731af9f7e36b0f",
            "value": " 480/480 [00:00&lt;00:00, 37.4kB/s]"
          }
        },
        "56d54a932b074238b9d335af9544720a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_300424c9062a4d63b4611fcc0f23bba0",
              "IPY_MODEL_2d829b285d7b4349bd979d24a4caefc1",
              "IPY_MODEL_47d5e46702d94a139669d3995b962730"
            ],
            "layout": "IPY_MODEL_8fa5b74b00aa4575b79bd1a382bd5e47"
          }
        },
        "300424c9062a4d63b4611fcc0f23bba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81a9028a3465402a9e1963f62f30b47e",
            "placeholder": "​",
            "style": "IPY_MODEL_d127678ac43747ffa61086ca8ef600cf",
            "value": "Map: 100%"
          }
        },
        "2d829b285d7b4349bd979d24a4caefc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac14de2e8f8f4c0984fa9ad73f01cb76",
            "max": 63576,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a71aa329cd664e1a8f0319b7f75fcc01",
            "value": 63576
          }
        },
        "47d5e46702d94a139669d3995b962730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e87bac90e3a74f1d93d21da3e13f9a6e",
            "placeholder": "​",
            "style": "IPY_MODEL_0fde597e90464d58a20dafd322964690",
            "value": " 63576/63576 [02:19&lt;00:00, 465.33 examples/s]"
          }
        },
        "8fa5b74b00aa4575b79bd1a382bd5e47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81a9028a3465402a9e1963f62f30b47e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d127678ac43747ffa61086ca8ef600cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac14de2e8f8f4c0984fa9ad73f01cb76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a71aa329cd664e1a8f0319b7f75fcc01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e87bac90e3a74f1d93d21da3e13f9a6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fde597e90464d58a20dafd322964690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e52161416ca4d988bfe0410d8c5dac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa8ba78d95f2451993dc42cdbbcae38f",
              "IPY_MODEL_4c2332fb6601484e8f8290aa9a5eade2",
              "IPY_MODEL_f3bf3ba764ee4e558a04da58d34eacbb"
            ],
            "layout": "IPY_MODEL_26f42b53a58e4830b788b5fc8ded6c95"
          }
        },
        "aa8ba78d95f2451993dc42cdbbcae38f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a31a7fc6ec644b4a7033c3a260e9c1d",
            "placeholder": "​",
            "style": "IPY_MODEL_3432b5d89d414095b3ef62c05ce1b792",
            "value": "Map: 100%"
          }
        },
        "4c2332fb6601484e8f8290aa9a5eade2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ede36b99f21404ca094b63df27b0fb1",
            "max": 7064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec0facd592954ddba8094ebb618a588f",
            "value": 7064
          }
        },
        "f3bf3ba764ee4e558a04da58d34eacbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cfe744029ac4baa83f32e826704cc06",
            "placeholder": "​",
            "style": "IPY_MODEL_1ef5c361847a46a5b867d0fd94fcc3a3",
            "value": " 7064/7064 [00:15&lt;00:00, 448.66 examples/s]"
          }
        },
        "26f42b53a58e4830b788b5fc8ded6c95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a31a7fc6ec644b4a7033c3a260e9c1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3432b5d89d414095b3ef62c05ce1b792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ede36b99f21404ca094b63df27b0fb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec0facd592954ddba8094ebb618a588f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7cfe744029ac4baa83f32e826704cc06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ef5c361847a46a5b867d0fd94fcc3a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35938cac89a64355afd3e9c0a0820529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aae76d1556274628b97a97c0976b7a45",
              "IPY_MODEL_fe373c3f404c4d9186a4733cedf2f422",
              "IPY_MODEL_f7f55e62e80647f6bbbe461de397313e"
            ],
            "layout": "IPY_MODEL_c37c3183828e4296a4033aef3aaea032"
          }
        },
        "aae76d1556274628b97a97c0976b7a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_135bbea15bdd4235ab7e439fd83d787c",
            "placeholder": "​",
            "style": "IPY_MODEL_6f0c1870662d41cfaa76750c11945c60",
            "value": "spiece.model: 100%"
          }
        },
        "fe373c3f404c4d9186a4733cedf2f422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7c4461556a84746b8ac8bc3b4943018",
            "max": 798011,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05e7c77cfd44449281afb4e599c89279",
            "value": 798011
          }
        },
        "f7f55e62e80647f6bbbe461de397313e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1993e7a3ad7f4b2d8b9529d7918a2d11",
            "placeholder": "​",
            "style": "IPY_MODEL_3467f41520574c9487fe1e863d2a5d0e",
            "value": " 798k/798k [00:00&lt;00:00, 25.1MB/s]"
          }
        },
        "c37c3183828e4296a4033aef3aaea032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "135bbea15bdd4235ab7e439fd83d787c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f0c1870662d41cfaa76750c11945c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7c4461556a84746b8ac8bc3b4943018": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05e7c77cfd44449281afb4e599c89279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1993e7a3ad7f4b2d8b9529d7918a2d11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3467f41520574c9487fe1e863d2a5d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11032b328ba44545862cac11bd09d9fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e5379af6a9a465ba9bffc68adb80d0e",
              "IPY_MODEL_b441ea8e286140578743ecf6b1e5b918",
              "IPY_MODEL_e7f64f3ef4f948209daf2e1eb5c9e513"
            ],
            "layout": "IPY_MODEL_69a7d39f43b64fa588cd5206c5501e70"
          }
        },
        "3e5379af6a9a465ba9bffc68adb80d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_190e41579f514eea93abfa952d0bdac5",
            "placeholder": "​",
            "style": "IPY_MODEL_55ebf9110b0a4ce29e70096e44d17b5e",
            "value": "tokenizer.json: 100%"
          }
        },
        "b441ea8e286140578743ecf6b1e5b918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58cfb3708bd748a098051af112dc5e74",
            "max": 1382015,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5c5d19de2aa400b8574c6cb005beb5c",
            "value": 1382015
          }
        },
        "e7f64f3ef4f948209daf2e1eb5c9e513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43a11ea696bc4a9585f416815ed8e23e",
            "placeholder": "​",
            "style": "IPY_MODEL_d3c601cd9e114ff880ab15b954a4d045",
            "value": " 1.38M/1.38M [00:00&lt;00:00, 1.65MB/s]"
          }
        },
        "69a7d39f43b64fa588cd5206c5501e70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "190e41579f514eea93abfa952d0bdac5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55ebf9110b0a4ce29e70096e44d17b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58cfb3708bd748a098051af112dc5e74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5c5d19de2aa400b8574c6cb005beb5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43a11ea696bc4a9585f416815ed8e23e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3c601cd9e114ff880ab15b954a4d045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c28060d60064054b50b4cf7d693365a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24b8b21be9354525bbb481346f6c8a74",
              "IPY_MODEL_8c70855b10234f1a8cfd0fea3533e51a",
              "IPY_MODEL_1edbd8a2d30f4a399762442b2d7eac20"
            ],
            "layout": "IPY_MODEL_3a686e0897894c5eba60e9fd77658d0a"
          }
        },
        "24b8b21be9354525bbb481346f6c8a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9664b04f10654ae1bbc8a3188ecc8576",
            "placeholder": "​",
            "style": "IPY_MODEL_4a798ab0be704fd8a7902a4038185fb5",
            "value": "config.json: 100%"
          }
        },
        "8c70855b10234f1a8cfd0fea3533e51a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43a2758ff46641bf8843a718dd6e8780",
            "max": 760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7212dfcdf3624b98a723a109f812b4f4",
            "value": 760
          }
        },
        "1edbd8a2d30f4a399762442b2d7eac20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a238904a196a4aa4bd2a578c8c792f74",
            "placeholder": "​",
            "style": "IPY_MODEL_dc78c7030e1f478cadc0c08846a6ecb7",
            "value": " 760/760 [00:00&lt;00:00, 64.6kB/s]"
          }
        },
        "3a686e0897894c5eba60e9fd77658d0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9664b04f10654ae1bbc8a3188ecc8576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a798ab0be704fd8a7902a4038185fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43a2758ff46641bf8843a718dd6e8780": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7212dfcdf3624b98a723a109f812b4f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a238904a196a4aa4bd2a578c8c792f74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc78c7030e1f478cadc0c08846a6ecb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eff5ebe2fd6e47c48efea6be25c2318a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6a2e82b4fa8412d987435bd227f4721",
              "IPY_MODEL_f42ee34da4404743b414065c6c80782a",
              "IPY_MODEL_2204baa514384f618c04968ad2c77521"
            ],
            "layout": "IPY_MODEL_03f03292546448938a8e02dd454e1b21"
          }
        },
        "e6a2e82b4fa8412d987435bd227f4721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c22a63d44e80444ab25ffaf382dcf9af",
            "placeholder": "​",
            "style": "IPY_MODEL_32a587a41aba4107a0a6ba27e6acd87a",
            "value": "Map: 100%"
          }
        },
        "f42ee34da4404743b414065c6c80782a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_977f2a9dec3b40faa5a8b0f4cccc8a7d",
            "max": 39735,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25c631e86cfe4ed88ae2ff1999da053f",
            "value": 39735
          }
        },
        "2204baa514384f618c04968ad2c77521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5eb78ac5fc6b449f87adda1f096f06a6",
            "placeholder": "​",
            "style": "IPY_MODEL_30e0037bfbad4c36946a35fcd6810331",
            "value": " 39735/39735 [01:26&lt;00:00, 448.87 examples/s]"
          }
        },
        "03f03292546448938a8e02dd454e1b21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c22a63d44e80444ab25ffaf382dcf9af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32a587a41aba4107a0a6ba27e6acd87a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "977f2a9dec3b40faa5a8b0f4cccc8a7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25c631e86cfe4ed88ae2ff1999da053f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5eb78ac5fc6b449f87adda1f096f06a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30e0037bfbad4c36946a35fcd6810331": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a359f6143b941169fcc535c93a9bf96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b504d24985e4d5485b8179b34d7e09c",
              "IPY_MODEL_db3d15ec8de64b939ca5a086e5c9f856",
              "IPY_MODEL_42a54b262c904e0584262ba799fd43f9"
            ],
            "layout": "IPY_MODEL_dbc70204c68943698c7cb9c24961a9db"
          }
        },
        "9b504d24985e4d5485b8179b34d7e09c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3748376194c4ce198e82b49b0c2948d",
            "placeholder": "​",
            "style": "IPY_MODEL_c51ce32380bb47f4af50e14a7ac277e2",
            "value": "Map: 100%"
          }
        },
        "db3d15ec8de64b939ca5a086e5c9f856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_909502e699604091b504249988ea6b40",
            "max": 4415,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76535d4f7f8e411386440e6707cc5287",
            "value": 4415
          }
        },
        "42a54b262c904e0584262ba799fd43f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9625a8c3c17d485586618cfc699e7961",
            "placeholder": "​",
            "style": "IPY_MODEL_50aa4ff23893498591d2b9c6df8e1607",
            "value": " 4415/4415 [00:09&lt;00:00, 449.41 examples/s]"
          }
        },
        "dbc70204c68943698c7cb9c24961a9db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3748376194c4ce198e82b49b0c2948d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c51ce32380bb47f4af50e14a7ac277e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "909502e699604091b504249988ea6b40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76535d4f7f8e411386440e6707cc5287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9625a8c3c17d485586618cfc699e7961": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50aa4ff23893498591d2b9c6df8e1607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c5ab3715a5843c9988d7331d2295059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45f0f0cd28844a74abf99ab3156e479d",
              "IPY_MODEL_3bbc466660a04695bf8a658f05a9d073",
              "IPY_MODEL_db7860b9419744ce89c2d958b10b0c67"
            ],
            "layout": "IPY_MODEL_1d517f263a9c42f595231728e3d0d831"
          }
        },
        "45f0f0cd28844a74abf99ab3156e479d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b3770c1c6934279ae153773122cdf81",
            "placeholder": "​",
            "style": "IPY_MODEL_a9f5771555e44a188ee8d59ff3028109",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "3bbc466660a04695bf8a658f05a9d073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7706b766e4bb4490873fbe42ffedbb2d",
            "max": 467042463,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31c05c6cad4148f7a1d78c40feeaad30",
            "value": 467042463
          }
        },
        "db7860b9419744ce89c2d958b10b0c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e1a30c1849b4cdd9fbe23968787d440",
            "placeholder": "​",
            "style": "IPY_MODEL_4c069415bd0e4455b61b4301f84e17a8",
            "value": " 467M/467M [00:01&lt;00:00, 425MB/s]"
          }
        },
        "1d517f263a9c42f595231728e3d0d831": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b3770c1c6934279ae153773122cdf81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9f5771555e44a188ee8d59ff3028109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7706b766e4bb4490873fbe42ffedbb2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31c05c6cad4148f7a1d78c40feeaad30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e1a30c1849b4cdd9fbe23968787d440": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c069415bd0e4455b61b4301f84e17a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6048b8d7bb994a5c8d1a30db9e360990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_169c34bebc374ba0affa1344329b5c3f",
              "IPY_MODEL_0268ee428d6f4c58a58a03669a1d3b87",
              "IPY_MODEL_2083781d01874c1d83d28c5e251bbb19"
            ],
            "layout": "IPY_MODEL_f0ef7bc4987f45aaaaaa98ce32863507"
          }
        },
        "169c34bebc374ba0affa1344329b5c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efa4cd5988e8452e92f680d74e1f3494",
            "placeholder": "​",
            "style": "IPY_MODEL_850ed8dcd81e46c59308ece90e75ce26",
            "value": "Downloading builder script: "
          }
        },
        "0268ee428d6f4c58a58a03669a1d3b87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c1d2f5f0b49423d9f0dc754af5c42e4",
            "max": 1652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55321cad3ca74037bfedbc4d8a4b9e4b",
            "value": 1652
          }
        },
        "2083781d01874c1d83d28c5e251bbb19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c0a05cd53f041bf8ca458113a2307bc",
            "placeholder": "​",
            "style": "IPY_MODEL_ffdac3cdfb5d4024a1c459b51358c3d2",
            "value": " 4.21k/? [00:00&lt;00:00, 296kB/s]"
          }
        },
        "f0ef7bc4987f45aaaaaa98ce32863507": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efa4cd5988e8452e92f680d74e1f3494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "850ed8dcd81e46c59308ece90e75ce26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c1d2f5f0b49423d9f0dc754af5c42e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55321cad3ca74037bfedbc4d8a4b9e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c0a05cd53f041bf8ca458113a2307bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffdac3cdfb5d4024a1c459b51358c3d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "051f6f95d0bc4075b15fd0fbe44f9f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9cfba44e99eb4d7eb368a2151516d17c",
              "IPY_MODEL_113a740b8a9d4b559235174ed7df3c17",
              "IPY_MODEL_7a754a0f3a0144d2a9c8c0d908df0144"
            ],
            "layout": "IPY_MODEL_279f06e1dc1f4d6798227e02cae5f7ad"
          }
        },
        "9cfba44e99eb4d7eb368a2151516d17c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b342b16693e24e8cbb103b59d47150b2",
            "placeholder": "​",
            "style": "IPY_MODEL_22b12b3e368946c6ae8617add152fe92",
            "value": "spiece.model: 100%"
          }
        },
        "113a740b8a9d4b559235174ed7df3c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bbec1ca26864c72ab932deeffb8414a",
            "max": 798011,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4833a3fc1aec47adadb9a873c64426bc",
            "value": 798011
          }
        },
        "7a754a0f3a0144d2a9c8c0d908df0144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7705600b1304affbc48dcd02f2deb61",
            "placeholder": "​",
            "style": "IPY_MODEL_771c3c680dd74b9aaadbd7b13c1af17d",
            "value": " 798k/798k [00:00&lt;00:00, 3.97MB/s]"
          }
        },
        "279f06e1dc1f4d6798227e02cae5f7ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b342b16693e24e8cbb103b59d47150b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22b12b3e368946c6ae8617add152fe92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bbec1ca26864c72ab932deeffb8414a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4833a3fc1aec47adadb9a873c64426bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7705600b1304affbc48dcd02f2deb61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "771c3c680dd74b9aaadbd7b13c1af17d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2f5ca2e5270474e9766bc108b561a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f9bbbdc6fec4b2b83637cf9bb6b8415",
              "IPY_MODEL_7d97be5ddf994d469506301d60fcbc80",
              "IPY_MODEL_3b9bc23f56e0445e8305b8e468307c1b"
            ],
            "layout": "IPY_MODEL_2a437e852bb74d4187869b3a5222a236"
          }
        },
        "8f9bbbdc6fec4b2b83637cf9bb6b8415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44f7472ac1c1446586068598630084d1",
            "placeholder": "​",
            "style": "IPY_MODEL_6606eaa648894695beb9128d4a9886a0",
            "value": "tokenizer.json: 100%"
          }
        },
        "7d97be5ddf994d469506301d60fcbc80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57dbb3ff589a4a7eaea293f4acf97bd2",
            "max": 1382015,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e81712f25802456c9af8c135ae183445",
            "value": 1382015
          }
        },
        "3b9bc23f56e0445e8305b8e468307c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cbe1ad975064104bb86649f391c815b",
            "placeholder": "​",
            "style": "IPY_MODEL_d4705b6e987b47ce8b587502c15ba2ff",
            "value": " 1.38M/1.38M [00:00&lt;00:00, 5.25MB/s]"
          }
        },
        "2a437e852bb74d4187869b3a5222a236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44f7472ac1c1446586068598630084d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6606eaa648894695beb9128d4a9886a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57dbb3ff589a4a7eaea293f4acf97bd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e81712f25802456c9af8c135ae183445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0cbe1ad975064104bb86649f391c815b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4705b6e987b47ce8b587502c15ba2ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c595fd8396fc4c628d11dd51f3878363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b194de094deb4ca2a656244d0d80027b",
              "IPY_MODEL_0b2b2e28ad00405eb9210a08ce9ace7e",
              "IPY_MODEL_f548d35d3b274f768408f4731d12c64f"
            ],
            "layout": "IPY_MODEL_43bc1a417b444cd7928ad7c6ae4e966b"
          }
        },
        "b194de094deb4ca2a656244d0d80027b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b3ebdbca6ed4b14b0ebc18b327953d9",
            "placeholder": "​",
            "style": "IPY_MODEL_0ccb0925ff7f42b08409e5bed03fc325",
            "value": "config.json: 100%"
          }
        },
        "0b2b2e28ad00405eb9210a08ce9ace7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75f4d9d1cdae4773bef551611b3c19ba",
            "max": 760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21f6cd67825a476e8689cf810e94ade5",
            "value": 760
          }
        },
        "f548d35d3b274f768408f4731d12c64f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd01d9ebd11042dba38866a5eb648969",
            "placeholder": "​",
            "style": "IPY_MODEL_d5674fe6307448c5b3f2e7ffbbc275b0",
            "value": " 760/760 [00:00&lt;00:00, 67.6kB/s]"
          }
        },
        "43bc1a417b444cd7928ad7c6ae4e966b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b3ebdbca6ed4b14b0ebc18b327953d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ccb0925ff7f42b08409e5bed03fc325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75f4d9d1cdae4773bef551611b3c19ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21f6cd67825a476e8689cf810e94ade5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd01d9ebd11042dba38866a5eb648969": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5674fe6307448c5b3f2e7ffbbc275b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b60f50c9a5024c1fa1b618057a5b0d0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbdd3d51845c4757a91a98f0abc635f3",
              "IPY_MODEL_d2a39df0acb64207bc9964a668eca6ac",
              "IPY_MODEL_ab7e9b5e06894389bf3dab2873f9e067"
            ],
            "layout": "IPY_MODEL_cef0b17c3b924cbfbeeef0f398782054"
          }
        },
        "dbdd3d51845c4757a91a98f0abc635f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b458ddd10907480898c4f12dd2c51f24",
            "placeholder": "​",
            "style": "IPY_MODEL_433c7550b5ee4536ae11e948751cc23a",
            "value": "Map: 100%"
          }
        },
        "d2a39df0acb64207bc9964a668eca6ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa01f398e02b4e2f9e5a60137a4f10e8",
            "max": 26490,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_443b95b167684d7cafde7d43eb49f2ea",
            "value": 26490
          }
        },
        "ab7e9b5e06894389bf3dab2873f9e067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d827f92f326347699e7b80a8d7efd85f",
            "placeholder": "​",
            "style": "IPY_MODEL_ef9cb782290e4e3e9e7e8e9df0030b7e",
            "value": " 26490/26490 [00:55&lt;00:00, 487.10 examples/s]"
          }
        },
        "cef0b17c3b924cbfbeeef0f398782054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b458ddd10907480898c4f12dd2c51f24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "433c7550b5ee4536ae11e948751cc23a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa01f398e02b4e2f9e5a60137a4f10e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "443b95b167684d7cafde7d43eb49f2ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d827f92f326347699e7b80a8d7efd85f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef9cb782290e4e3e9e7e8e9df0030b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "208dac8324d04d44922a1e9eb419ca32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06fd856dc6314ac38238ccc869c13de4",
              "IPY_MODEL_43b6a46304364c8c9a197c8c9587e74a",
              "IPY_MODEL_0f598a817cc74a80bd65804e3432532d"
            ],
            "layout": "IPY_MODEL_6c95770a33324be5926b988f00adadb8"
          }
        },
        "06fd856dc6314ac38238ccc869c13de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25f96651ce6145cbb83f572270a5055b",
            "placeholder": "​",
            "style": "IPY_MODEL_3b5e941e08b0412081db17818c593bd8",
            "value": "Map: 100%"
          }
        },
        "43b6a46304364c8c9a197c8c9587e74a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0f4d6c72f574928bdd21acf73715925",
            "max": 2944,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f905691ad7314f4b975990354b01e5b0",
            "value": 2944
          }
        },
        "0f598a817cc74a80bd65804e3432532d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78453f9ec04744d1b378977e9fa42457",
            "placeholder": "​",
            "style": "IPY_MODEL_e87ac7f82102475c86382bc1e0c3dd8e",
            "value": " 2944/2944 [00:06&lt;00:00, 438.56 examples/s]"
          }
        },
        "6c95770a33324be5926b988f00adadb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25f96651ce6145cbb83f572270a5055b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b5e941e08b0412081db17818c593bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0f4d6c72f574928bdd21acf73715925": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f905691ad7314f4b975990354b01e5b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78453f9ec04744d1b378977e9fa42457": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e87ac7f82102475c86382bc1e0c3dd8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0a2a5c238434843a26289a44e90cbcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a7be706443f4c609702a6dec907f3fc",
              "IPY_MODEL_058026b532ce4276849f821ec730f3ec",
              "IPY_MODEL_6b221024391e425ea8634f6fba4212fa"
            ],
            "layout": "IPY_MODEL_fe944585869a4f8fb2ba7e74f8e68c77"
          }
        },
        "0a7be706443f4c609702a6dec907f3fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a8d23c350ac454896ad857c1e8b4b47",
            "placeholder": "​",
            "style": "IPY_MODEL_b14fe64ce3e44f99abd2422d2d4cd244",
            "value": "config.json: 100%"
          }
        },
        "058026b532ce4276849f821ec730f3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca0f8990a86d4b6c8ae69393fd1c568b",
            "max": 761,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a38cad1c6cfe4f848a25e72bd739a2ab",
            "value": 761
          }
        },
        "6b221024391e425ea8634f6fba4212fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95f5e85270134e35adefedf15da40f97",
            "placeholder": "​",
            "style": "IPY_MODEL_37925af2c0dc489b91958ea70dabc064",
            "value": " 761/761 [00:00&lt;00:00, 62.3kB/s]"
          }
        },
        "fe944585869a4f8fb2ba7e74f8e68c77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a8d23c350ac454896ad857c1e8b4b47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b14fe64ce3e44f99abd2422d2d4cd244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca0f8990a86d4b6c8ae69393fd1c568b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a38cad1c6cfe4f848a25e72bd739a2ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95f5e85270134e35adefedf15da40f97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37925af2c0dc489b91958ea70dabc064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f361bb07700a43a7aad56ff6cf81b90a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae667cc02f9b4f55b0b0707456740626",
              "IPY_MODEL_d0cc41dcf2ae435998bf440e548c1093",
              "IPY_MODEL_eada422a68c2403795b0f3b3a3e7b76a"
            ],
            "layout": "IPY_MODEL_4da96d097d4b45f38dcb501d0449ee10"
          }
        },
        "ae667cc02f9b4f55b0b0707456740626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c87bd0b61434a07bce3adeb8e1d3a43",
            "placeholder": "​",
            "style": "IPY_MODEL_04b39d8d11614b5fa34bff17f7a8ea57",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "d0cc41dcf2ae435998bf440e548c1093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb3c8bc7ebc741259d0ef38d159a3226",
            "max": 1441285815,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_199888a38ae2457db9012d9965982ab3",
            "value": 1441285815
          }
        },
        "eada422a68c2403795b0f3b3a3e7b76a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3db1f12017948458275a601a0fee8d4",
            "placeholder": "​",
            "style": "IPY_MODEL_98fa3ed1d90748fc9f59f74120fa32a9",
            "value": " 1.44G/1.44G [00:53&lt;00:00, 36.0MB/s]"
          }
        },
        "4da96d097d4b45f38dcb501d0449ee10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c87bd0b61434a07bce3adeb8e1d3a43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04b39d8d11614b5fa34bff17f7a8ea57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb3c8bc7ebc741259d0ef38d159a3226": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "199888a38ae2457db9012d9965982ab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3db1f12017948458275a601a0fee8d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98fa3ed1d90748fc9f59f74120fa32a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19f6c2b80db841c8bde00dbcebc3aa3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_334caf88212c4836b5abb557ef593492",
              "IPY_MODEL_1d74c30a97244cf592f9914ac4a7c5f7",
              "IPY_MODEL_9cbb19e62a8e4a39a9d7340a78b8816f"
            ],
            "layout": "IPY_MODEL_717b7ba20cde401ead438cdb8c53568d"
          }
        },
        "334caf88212c4836b5abb557ef593492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_394a15a25b7b4dbfac7332d43d8bde43",
            "placeholder": "​",
            "style": "IPY_MODEL_be6f5958b0a84705a3990c1aa67a1865",
            "value": "Downloading builder script: "
          }
        },
        "1d74c30a97244cf592f9914ac4a7c5f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_806170a8becc499ea5617b5e7b12cfb2",
            "max": 1652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f78d595a3eb430387fc1d70d114b70f",
            "value": 1652
          }
        },
        "9cbb19e62a8e4a39a9d7340a78b8816f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_840ae742c7764be7a8ad8f5259434334",
            "placeholder": "​",
            "style": "IPY_MODEL_8f70b5641a984abba7bdf1e4055738a3",
            "value": " 4.21k/? [00:00&lt;00:00, 313kB/s]"
          }
        },
        "717b7ba20cde401ead438cdb8c53568d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "394a15a25b7b4dbfac7332d43d8bde43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be6f5958b0a84705a3990c1aa67a1865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "806170a8becc499ea5617b5e7b12cfb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f78d595a3eb430387fc1d70d114b70f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "840ae742c7764be7a8ad8f5259434334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f70b5641a984abba7bdf1e4055738a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}